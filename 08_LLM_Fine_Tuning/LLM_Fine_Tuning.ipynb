{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a1b2901134ea4c3785191bf38d6b6679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8df78d9bf884cffa52848504cd0a3a2",
              "IPY_MODEL_70ae8ca2e28e4fa4b37bf6e880dbf097",
              "IPY_MODEL_c71663ed1a944066bf89a2660ca8c247"
            ],
            "layout": "IPY_MODEL_9ce23f642f3645629d4f2e1cbd6b3ad8"
          }
        },
        "a8df78d9bf884cffa52848504cd0a3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a2786266be4d63893257d35edc385c",
            "placeholder": "​",
            "style": "IPY_MODEL_16eb9d8cc14048a792e9380095663e35",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "70ae8ca2e28e4fa4b37bf6e880dbf097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbe6beca15494398b5919b25b69971f4",
            "max": 5213,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11a6e751a0bd46a09d31eac9648db51a",
            "value": 5213
          }
        },
        "c71663ed1a944066bf89a2660ca8c247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ab65d25c47458f91b0ab27bce0d924",
            "placeholder": "​",
            "style": "IPY_MODEL_1e89c37033a34f98be7988fe28e9076d",
            "value": " 5.21k/5.21k [00:00&lt;00:00, 279kB/s]"
          }
        },
        "9ce23f642f3645629d4f2e1cbd6b3ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a2786266be4d63893257d35edc385c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16eb9d8cc14048a792e9380095663e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbe6beca15494398b5919b25b69971f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a6e751a0bd46a09d31eac9648db51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6ab65d25c47458f91b0ab27bce0d924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e89c37033a34f98be7988fe28e9076d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f78e8b2a7b849cbbeb9673e472f8953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad19aa3771224a5fa2e56b59d7779d98",
              "IPY_MODEL_ae7ec4c2bc6240ac911fb73df739a689",
              "IPY_MODEL_f7b5671a61cc4d44997f95f35b205603"
            ],
            "layout": "IPY_MODEL_0227b2723672494b852201a8c6e573f5"
          }
        },
        "ad19aa3771224a5fa2e56b59d7779d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf15ad859ccb4ed190d83721dd3fca36",
            "placeholder": "​",
            "style": "IPY_MODEL_c3e002c6ecee4fada2adb4f5705c0e6d",
            "value": "tokenizer.json: 100%"
          }
        },
        "ae7ec4c2bc6240ac911fb73df739a689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82f2a2f71988442cbef602fd6df3e186",
            "max": 2113738,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28c34f1c83334f708f8340b80945ae8d",
            "value": 2113738
          }
        },
        "f7b5671a61cc4d44997f95f35b205603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06c0fae86cfc4ce888b9720589bfa3ab",
            "placeholder": "​",
            "style": "IPY_MODEL_cbba15d7a4c44328a8e0583693778225",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 2.91MB/s]"
          }
        },
        "0227b2723672494b852201a8c6e573f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf15ad859ccb4ed190d83721dd3fca36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e002c6ecee4fada2adb4f5705c0e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82f2a2f71988442cbef602fd6df3e186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28c34f1c83334f708f8340b80945ae8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06c0fae86cfc4ce888b9720589bfa3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbba15d7a4c44328a8e0583693778225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a25b7d6c49740ecbf8d1a64388c72a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b42ce5008bb4431ca84daed4f4aaa26c",
              "IPY_MODEL_b676927beb994913a54a64ccb53b13e2",
              "IPY_MODEL_b1f7b839d419444bacbee8bf2a55890a"
            ],
            "layout": "IPY_MODEL_c5dbc4749cbb44cc9f406e767ce7a808"
          }
        },
        "b42ce5008bb4431ca84daed4f4aaa26c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22e53e18f9b64bbc8c43f4f8f537e83b",
            "placeholder": "​",
            "style": "IPY_MODEL_f56fd632b1e444ec84dd92aceb9fc94a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b676927beb994913a54a64ccb53b13e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b87399fe1e54ef8af2c8315cd168f0f",
            "max": 587,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38b4209ea4914b7b816a1d5bfd04307d",
            "value": 587
          }
        },
        "b1f7b839d419444bacbee8bf2a55890a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2eb27d01422445e8735a60ddb29ba93",
            "placeholder": "​",
            "style": "IPY_MODEL_c8ec8ea2591646cea9b265814aad8665",
            "value": " 587/587 [00:00&lt;00:00, 53.4kB/s]"
          }
        },
        "c5dbc4749cbb44cc9f406e767ce7a808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e53e18f9b64bbc8c43f4f8f537e83b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56fd632b1e444ec84dd92aceb9fc94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b87399fe1e54ef8af2c8315cd168f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b4209ea4914b7b816a1d5bfd04307d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2eb27d01422445e8735a60ddb29ba93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8ec8ea2591646cea9b265814aad8665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69064717665b457db70b9b757d61f32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10f9a807e6b74b47ba0f667e2ec606c8",
              "IPY_MODEL_01511cb332a740e48279a32532517af9",
              "IPY_MODEL_ee505afac8384d179628663e1a0a9408"
            ],
            "layout": "IPY_MODEL_7742f54a84e640bf85e9a6da28e8f36b"
          }
        },
        "10f9a807e6b74b47ba0f667e2ec606c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2ccd1f6833b4376b851b77ce3fe7dd1",
            "placeholder": "​",
            "style": "IPY_MODEL_7ebc57604dbb475199e7b2646cb12da0",
            "value": "config.json: 100%"
          }
        },
        "01511cb332a740e48279a32532517af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_100956e6948247298cac138300fa853d",
            "max": 599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81c1cc4e462f4dbf891b4fc4946b5e3c",
            "value": 599
          }
        },
        "ee505afac8384d179628663e1a0a9408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1117604d6a534009a229ed5d39f2815a",
            "placeholder": "​",
            "style": "IPY_MODEL_f1a8742198324fa0aa8f280edfa12f8d",
            "value": " 599/599 [00:00&lt;00:00, 48.8kB/s]"
          }
        },
        "7742f54a84e640bf85e9a6da28e8f36b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2ccd1f6833b4376b851b77ce3fe7dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ebc57604dbb475199e7b2646cb12da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "100956e6948247298cac138300fa853d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81c1cc4e462f4dbf891b4fc4946b5e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1117604d6a534009a229ed5d39f2815a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1a8742198324fa0aa8f280edfa12f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f08ecea54a0a4acb8d64d011ff34d072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_236d856e1f5b430b86638aec6c1e1945",
              "IPY_MODEL_1a7cf227e66e4844b8ecf751d01df105",
              "IPY_MODEL_452140429d974a74b50eacf264f1fc31"
            ],
            "layout": "IPY_MODEL_ed2cf7c08bb5449c932744d8ab45b404"
          }
        },
        "236d856e1f5b430b86638aec6c1e1945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab683c7acd9d4de3a070b79327132a63",
            "placeholder": "​",
            "style": "IPY_MODEL_43c2039cd0a449bcb74694edc53999c8",
            "value": "model.safetensors: 100%"
          }
        },
        "1a7cf227e66e4844b8ecf751d01df105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25eb3ed4333545b9994172057aa8f68a",
            "max": 5590927496,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d76a1d6dc9544efb807f3b15f0da9f11",
            "value": 5590927496
          }
        },
        "452140429d974a74b50eacf264f1fc31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14010514e6574f94837f0efd7172858b",
            "placeholder": "​",
            "style": "IPY_MODEL_0ead5b35c39b4816adbfeb22233e7d8a",
            "value": " 5.59G/5.59G [04:25&lt;00:00, 21.0MB/s]"
          }
        },
        "ed2cf7c08bb5449c932744d8ab45b404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab683c7acd9d4de3a070b79327132a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c2039cd0a449bcb74694edc53999c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25eb3ed4333545b9994172057aa8f68a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d76a1d6dc9544efb807f3b15f0da9f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14010514e6574f94837f0efd7172858b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ead5b35c39b4816adbfeb22233e7d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb1b7b7d613a407baffa0b9e18ffe898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98950d10fc6a4106806c99d5697a94a7",
              "IPY_MODEL_3f984f3a535a4a06948de59293fb85a5",
              "IPY_MODEL_40617703bbcd4cfd97f61bab28cb90ea"
            ],
            "layout": "IPY_MODEL_b78b90df5b0f4b128687114a6735fdc8"
          }
        },
        "98950d10fc6a4106806c99d5697a94a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d025c23bca884eef9191a4fb0fddff12",
            "placeholder": "​",
            "style": "IPY_MODEL_03b175b5c8cc4782ac1d4374f8b2e75c",
            "value": "generation_config.json: 100%"
          }
        },
        "3f984f3a535a4a06948de59293fb85a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5aaca12aef340818eca10967f5fda49",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1583442c1cbf4168ab7c93b297b3e65b",
            "value": 111
          }
        },
        "40617703bbcd4cfd97f61bab28cb90ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f5ad2e940744bcd833eb9c376c6730c",
            "placeholder": "​",
            "style": "IPY_MODEL_86a14c44b7d445849a9b30c18c17ef90",
            "value": " 111/111 [00:00&lt;00:00, 9.42kB/s]"
          }
        },
        "b78b90df5b0f4b128687114a6735fdc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d025c23bca884eef9191a4fb0fddff12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b175b5c8cc4782ac1d4374f8b2e75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5aaca12aef340818eca10967f5fda49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1583442c1cbf4168ab7c93b297b3e65b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f5ad2e940744bcd833eb9c376c6730c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86a14c44b7d445849a9b30c18c17ef90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6030b674d9e34afc8a1186668406a49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3ffe1011bee4f59844d6589a01ff453",
              "IPY_MODEL_b3b5af1f3c3e496cb6f745ddc15f6a4f",
              "IPY_MODEL_50120a8097294e169266afcfedfc01b1"
            ],
            "layout": "IPY_MODEL_18919ff56b74459fad626601de952f8a",
            "tabbable": null,
            "tooltip": null
          }
        },
        "b3ffe1011bee4f59844d6589a01ff453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4f61bfef631a4350aaa6a18fc70b205b",
            "placeholder": "​",
            "style": "IPY_MODEL_14742482fa3a4f7a8fc10a31eb7317da",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b3b5af1f3c3e496cb6f745ddc15f6a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_aef376ae5dc1489ab62ceac7de5832dd",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95ee75791b4441d9b7e0ab52790c89dc",
            "tabbable": null,
            "tooltip": null,
            "value": 19
          }
        },
        "50120a8097294e169266afcfedfc01b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cb0fc88027cf46268b6b079798661595",
            "placeholder": "​",
            "style": "IPY_MODEL_48e98fb20e8d4115b025f39a0e920df3",
            "tabbable": null,
            "tooltip": null,
            "value": " 19/19 [06:40&lt;00:00, 20.34s/it]"
          }
        },
        "18919ff56b74459fad626601de952f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f61bfef631a4350aaa6a18fc70b205b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14742482fa3a4f7a8fc10a31eb7317da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "aef376ae5dc1489ab62ceac7de5832dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95ee75791b4441d9b7e0ab52790c89dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb0fc88027cf46268b6b079798661595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e98fb20e8d4115b025f39a0e920df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "48a7e947be82487eb7324f35c4a4ffbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad3884aa753a4a35895779b54c7d82e9",
              "IPY_MODEL_4b9a29d258304be0baac0c984f2cdfdc",
              "IPY_MODEL_dd24de92f6d74e64a7ed3654e0a47a14"
            ],
            "layout": "IPY_MODEL_e5175593afd241878b3edfa6593554eb",
            "tabbable": null,
            "tooltip": null
          }
        },
        "ad3884aa753a4a35895779b54c7d82e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6dad5998d9be492885000fca6620bcd7",
            "placeholder": "​",
            "style": "IPY_MODEL_4c04bd5b2bc14ac5953c67a917a0325f",
            "tabbable": null,
            "tooltip": null,
            "value": "Map: 100%"
          }
        },
        "4b9a29d258304be0baac0c984f2cdfdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_bb0b3a2e68cb481aabb9c0abace3afa0",
            "max": 714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_020d54f72b1b458989c9c781b2817e5c",
            "tabbable": null,
            "tooltip": null,
            "value": 714
          }
        },
        "dd24de92f6d74e64a7ed3654e0a47a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9c784c7027a3453c9568e780a5bf23da",
            "placeholder": "​",
            "style": "IPY_MODEL_9489506bd13145faa03e11c9a4d27844",
            "tabbable": null,
            "tooltip": null,
            "value": " 714/714 [00:00&lt;00:00, 1249.40 examples/s]"
          }
        },
        "e5175593afd241878b3edfa6593554eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dad5998d9be492885000fca6620bcd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c04bd5b2bc14ac5953c67a917a0325f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "bb0b3a2e68cb481aabb9c0abace3afa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "020d54f72b1b458989c9c781b2817e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c784c7027a3453c9568e780a5bf23da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9489506bd13145faa03e11c9a4d27844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4cad422b16d44dfeaa82caff8fe7fc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21839f7b077a448fba14bb720a5fc1e6",
              "IPY_MODEL_3a0b9ae0adf54b6a8c67aa9d93560044",
              "IPY_MODEL_c1fdf85f020d43058150d858efde2e34"
            ],
            "layout": "IPY_MODEL_d1035cfdc09343e8bc3b323b87732314",
            "tabbable": null,
            "tooltip": null
          }
        },
        "21839f7b077a448fba14bb720a5fc1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_53a80d22816043558bd0643af312dbdb",
            "placeholder": "​",
            "style": "IPY_MODEL_ca90af390cf44f49835991f66ec17ceb",
            "tabbable": null,
            "tooltip": null,
            "value": "config.json: 100%"
          }
        },
        "3a0b9ae0adf54b6a8c67aa9d93560044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_d0c0e36c4f464431a75dfee21d580de2",
            "max": 571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_000558dc9c1a4a1a913ca03d2180354e",
            "tabbable": null,
            "tooltip": null,
            "value": 571
          }
        },
        "c1fdf85f020d43058150d858efde2e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9c62ff4089204c69a674ab98e3b1839a",
            "placeholder": "​",
            "style": "IPY_MODEL_0f294c5d77c7457ba4dee69d25c0a6ce",
            "tabbable": null,
            "tooltip": null,
            "value": " 571/571 [00:00&lt;00:00, 45.8kB/s]"
          }
        },
        "d1035cfdc09343e8bc3b323b87732314": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53a80d22816043558bd0643af312dbdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca90af390cf44f49835991f66ec17ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "d0c0e36c4f464431a75dfee21d580de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "000558dc9c1a4a1a913ca03d2180354e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c62ff4089204c69a674ab98e3b1839a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f294c5d77c7457ba4dee69d25c0a6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "fc44be96362546559b8f2e71fd06e160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_853ac956a1e34ebf99f10b3a098bd80c",
              "IPY_MODEL_cd83b453c28248e59d65ea79a9ec20c5",
              "IPY_MODEL_64c76a71254a4442b421380ab6496543"
            ],
            "layout": "IPY_MODEL_8e7fa961b51648f4be69903fc1b43fc5",
            "tabbable": null,
            "tooltip": null
          }
        },
        "853ac956a1e34ebf99f10b3a098bd80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7778c9fbe2f94d88918416574679f33c",
            "placeholder": "​",
            "style": "IPY_MODEL_a883e022ed884986931bea87d90a0327",
            "tabbable": null,
            "tooltip": null,
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "cd83b453c28248e59d65ea79a9ec20c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_634261ec000247b2a9f4831a23968dd6",
            "max": 25125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84d3610c1a584f9699f2bc31a572d776",
            "tabbable": null,
            "tooltip": null,
            "value": 25125
          }
        },
        "64c76a71254a4442b421380ab6496543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6083310d84904961a60398aeae78ed43",
            "placeholder": "​",
            "style": "IPY_MODEL_072d92cc645d45abb45daffd0edab010",
            "tabbable": null,
            "tooltip": null,
            "value": " 25.1k/25.1k [00:00&lt;00:00, 1.80MB/s]"
          }
        },
        "8e7fa961b51648f4be69903fc1b43fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7778c9fbe2f94d88918416574679f33c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a883e022ed884986931bea87d90a0327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "634261ec000247b2a9f4831a23968dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84d3610c1a584f9699f2bc31a572d776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6083310d84904961a60398aeae78ed43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "072d92cc645d45abb45daffd0edab010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "4093614e2a204e7189b0123003430940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48de606c82404efeacaf0da7a4bea7df",
              "IPY_MODEL_cc09f8c4d61f42c099d25316ee0fa7a5",
              "IPY_MODEL_3e09b5271c004e58bfcb2d0004d7aca0"
            ],
            "layout": "IPY_MODEL_70a399a8abdd49acb8676867e8d94589",
            "tabbable": null,
            "tooltip": null
          }
        },
        "48de606c82404efeacaf0da7a4bea7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_da1cb166be374ea888c27647fa37c283",
            "placeholder": "​",
            "style": "IPY_MODEL_e08d6dbabaa046c88451ed6ec04dd252",
            "tabbable": null,
            "tooltip": null,
            "value": "Downloading shards: 100%"
          }
        },
        "cc09f8c4d61f42c099d25316ee0fa7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_7eb34bc193fc451f85cf817231cf963b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b6bd25360234c77983144190385dcc6",
            "tabbable": null,
            "tooltip": null,
            "value": 2
          }
        },
        "3e09b5271c004e58bfcb2d0004d7aca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_245e8258a51244aa9df61ead09792170",
            "placeholder": "​",
            "style": "IPY_MODEL_3a6c3146c3bd4837971f0fe333163edf",
            "tabbable": null,
            "tooltip": null,
            "value": " 2/2 [01:00&lt;00:00, 28.92s/it]"
          }
        },
        "70a399a8abdd49acb8676867e8d94589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da1cb166be374ea888c27647fa37c283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e08d6dbabaa046c88451ed6ec04dd252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "7eb34bc193fc451f85cf817231cf963b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b6bd25360234c77983144190385dcc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "245e8258a51244aa9df61ead09792170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a6c3146c3bd4837971f0fe333163edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "be0c311c77064d44be0c8a85c1cb0a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f9f5fe148e64fe090342f449fd50285",
              "IPY_MODEL_89d3dde9f0bd415f87dadb20032f551f",
              "IPY_MODEL_0be2eb5399e04786bff84a7b7235252f"
            ],
            "layout": "IPY_MODEL_b1a0154ac7034e02b251f7b50920c0c3",
            "tabbable": null,
            "tooltip": null
          }
        },
        "6f9f5fe148e64fe090342f449fd50285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_2b9809065b4f48db9aa876ed8ba9bbe3",
            "placeholder": "​",
            "style": "IPY_MODEL_1d4bcb093f2744e1a5abf49abe05c53a",
            "tabbable": null,
            "tooltip": null,
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "89d3dde9f0bd415f87dadb20032f551f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_fb8a89752f3e4dec90ea51756efcc2e8",
            "max": 9942981696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b6509ddd37347acacfbf13c52540841",
            "tabbable": null,
            "tooltip": null,
            "value": 9942981696
          }
        },
        "0be2eb5399e04786bff84a7b7235252f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_80a14e27a47f48ebb42663156d39886c",
            "placeholder": "​",
            "style": "IPY_MODEL_2bfa29f249b6405cbea5210b2a3a015e",
            "tabbable": null,
            "tooltip": null,
            "value": " 9.94G/9.94G [00:37&lt;00:00, 285MB/s]"
          }
        },
        "b1a0154ac7034e02b251f7b50920c0c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b9809065b4f48db9aa876ed8ba9bbe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d4bcb093f2744e1a5abf49abe05c53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "fb8a89752f3e4dec90ea51756efcc2e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b6509ddd37347acacfbf13c52540841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80a14e27a47f48ebb42663156d39886c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bfa29f249b6405cbea5210b2a3a015e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a1152f2475ce43948c9b249f8f8f3af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_104e474ce4994d33b114c15d95cfef74",
              "IPY_MODEL_5b4869b36e844d3a8c720290eb81dc1c",
              "IPY_MODEL_fd64a60abdc14597b2abfc2cf7c2959a"
            ],
            "layout": "IPY_MODEL_c4729a508b05477f9519d80a09c1a96f",
            "tabbable": null,
            "tooltip": null
          }
        },
        "104e474ce4994d33b114c15d95cfef74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_f61ae0368c7b400ebe5daa02480b0582",
            "placeholder": "​",
            "style": "IPY_MODEL_81e9c629bfb1477fb8366188d8ef83a2",
            "tabbable": null,
            "tooltip": null,
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "5b4869b36e844d3a8c720290eb81dc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_3a7528a8f33b491db4ae54ac9e2b4eb4",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8cca96404e6471c8367bf280312af83",
            "tabbable": null,
            "tooltip": null,
            "value": 4540516344
          }
        },
        "fd64a60abdc14597b2abfc2cf7c2959a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a43182820dfb4416891f6cd8bc1c2f22",
            "placeholder": "​",
            "style": "IPY_MODEL_4b11538c1a1744b6ab7c2b2b31a3c89a",
            "tabbable": null,
            "tooltip": null,
            "value": " 4.54G/4.54G [00:22&lt;00:00, 440MB/s]"
          }
        },
        "c4729a508b05477f9519d80a09c1a96f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f61ae0368c7b400ebe5daa02480b0582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e9c629bfb1477fb8366188d8ef83a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "3a7528a8f33b491db4ae54ac9e2b4eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8cca96404e6471c8367bf280312af83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a43182820dfb4416891f6cd8bc1c2f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b11538c1a1744b6ab7c2b2b31a3c89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "aede343f6eee4183aa627aaa5e480922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0385696f7769440ba194126d599bc970",
              "IPY_MODEL_d9b2d6a7e677449eb4339fa5f6385fbb",
              "IPY_MODEL_ead40e8686a6483eadd98ed2799a9867"
            ],
            "layout": "IPY_MODEL_9605ee8f0b35423a830ccd56ccdf88b9",
            "tabbable": null,
            "tooltip": null
          }
        },
        "0385696f7769440ba194126d599bc970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e7f6738247024a14a3b35e174e9b31a0",
            "placeholder": "​",
            "style": "IPY_MODEL_175ab11a6d2f4ca0837f40f088fba1be",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d9b2d6a7e677449eb4339fa5f6385fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_63a74cc04c45441483a72108b91f68b6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dec53933d87940d783e3c2759b51320c",
            "tabbable": null,
            "tooltip": null,
            "value": 2
          }
        },
        "ead40e8686a6483eadd98ed2799a9867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e0c8c4f119034c65bb5fe8bf1eb5acb4",
            "placeholder": "​",
            "style": "IPY_MODEL_8105bae29d4542e49624cba4fedafa7d",
            "tabbable": null,
            "tooltip": null,
            "value": " 2/2 [00:08&lt;00:00,  4.17s/it]"
          }
        },
        "9605ee8f0b35423a830ccd56ccdf88b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f6738247024a14a3b35e174e9b31a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175ab11a6d2f4ca0837f40f088fba1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "63a74cc04c45441483a72108b91f68b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec53933d87940d783e3c2759b51320c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0c8c4f119034c65bb5fe8bf1eb5acb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8105bae29d4542e49624cba4fedafa7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "f25d88626abc4136a45011f8357b4e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25d2ab7ad5b84b88922f94507e0d6197",
              "IPY_MODEL_3fbef5f6ac70403eb43ab4d3ec23d53b",
              "IPY_MODEL_34fbe5b33ad0427e8bf91d1923870bb5"
            ],
            "layout": "IPY_MODEL_4c0d562f86954955bd36071cf1231c30",
            "tabbable": null,
            "tooltip": null
          }
        },
        "25d2ab7ad5b84b88922f94507e0d6197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_afac4264eb1c4b09a56178774234e9a0",
            "placeholder": "​",
            "style": "IPY_MODEL_12f5fea121cb419d9d1037c3179a9ecd",
            "tabbable": null,
            "tooltip": null,
            "value": "generation_config.json: 100%"
          }
        },
        "3fbef5f6ac70403eb43ab4d3ec23d53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_de3fe63c0bb44c299af029c250e0f1ae",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdbdd89baf3d488fb5cda0b1ee654993",
            "tabbable": null,
            "tooltip": null,
            "value": 116
          }
        },
        "34fbe5b33ad0427e8bf91d1923870bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_077968b3357540999b6c109e79c9c5fd",
            "placeholder": "​",
            "style": "IPY_MODEL_2b4244b1b5fd402d9fd4144468124cae",
            "tabbable": null,
            "tooltip": null,
            "value": " 116/116 [00:00&lt;00:00, 9.28kB/s]"
          }
        },
        "4c0d562f86954955bd36071cf1231c30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afac4264eb1c4b09a56178774234e9a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f5fea121cb419d9d1037c3179a9ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "de3fe63c0bb44c299af029c250e0f1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdbdd89baf3d488fb5cda0b1ee654993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "077968b3357540999b6c109e79c9c5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b4244b1b5fd402d9fd4144468124cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "8979076ffd004c89bc55056a507bbe63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3beb3fab771640a0ac1720c9d383798e",
              "IPY_MODEL_d3d78cecb4cd41f59e197659d61135e1",
              "IPY_MODEL_07340a6b878242f88200ee66d100af5b"
            ],
            "layout": "IPY_MODEL_41629a2de0ac427eb8b461fda0ca1170",
            "tabbable": null,
            "tooltip": null
          }
        },
        "3beb3fab771640a0ac1720c9d383798e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1d48448610d0474a8067868617ef074a",
            "placeholder": "​",
            "style": "IPY_MODEL_abe11602ca084af196c476f3cf50c1cd",
            "tabbable": null,
            "tooltip": null,
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d3d78cecb4cd41f59e197659d61135e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a47713dbdff14c3ca7e87917d0cecf91",
            "max": 967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9bf1b7ee1ba3419bb005ba8b4aa5bc8f",
            "tabbable": null,
            "tooltip": null,
            "value": 967
          }
        },
        "07340a6b878242f88200ee66d100af5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_db174e0f7d724cd0825c3fb6d7d6c976",
            "placeholder": "​",
            "style": "IPY_MODEL_7996c149e19b4e308973d6abd8980e99",
            "tabbable": null,
            "tooltip": null,
            "value": " 967/967 [00:00&lt;00:00, 78.8kB/s]"
          }
        },
        "41629a2de0ac427eb8b461fda0ca1170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d48448610d0474a8067868617ef074a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abe11602ca084af196c476f3cf50c1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a47713dbdff14c3ca7e87917d0cecf91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf1b7ee1ba3419bb005ba8b4aa5bc8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db174e0f7d724cd0825c3fb6d7d6c976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7996c149e19b4e308973d6abd8980e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "0218ffc1bbf7454b8a6e8fc11a1119a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_610df534a09c4ea8acca5bd208bf6ffa",
              "IPY_MODEL_b97109099a7a4d189da9824212b647c4",
              "IPY_MODEL_b904f8468e5341489bc495ace16d2db6"
            ],
            "layout": "IPY_MODEL_dfb3689d407344e7a8c00229f75980f7",
            "tabbable": null,
            "tooltip": null
          }
        },
        "610df534a09c4ea8acca5bd208bf6ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_8a5f95eb7fb749789e6e1bfb86d7c166",
            "placeholder": "​",
            "style": "IPY_MODEL_838b1f4718fe4cc0b12170a24980a513",
            "tabbable": null,
            "tooltip": null,
            "value": "tokenizer.model: 100%"
          }
        },
        "b97109099a7a4d189da9824212b647c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6c405c18011b4e0a921b26804bc450b4",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad18ecdd2b734c07822cd16c247da365",
            "tabbable": null,
            "tooltip": null,
            "value": 493443
          }
        },
        "b904f8468e5341489bc495ace16d2db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1736b5f930c847c78c1b501a3fdbbe3b",
            "placeholder": "​",
            "style": "IPY_MODEL_936d79b6c5f6429482d031d494ab2961",
            "tabbable": null,
            "tooltip": null,
            "value": " 493k/493k [00:00&lt;00:00, 22.0MB/s]"
          }
        },
        "dfb3689d407344e7a8c00229f75980f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a5f95eb7fb749789e6e1bfb86d7c166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838b1f4718fe4cc0b12170a24980a513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "6c405c18011b4e0a921b26804bc450b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad18ecdd2b734c07822cd16c247da365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1736b5f930c847c78c1b501a3fdbbe3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936d79b6c5f6429482d031d494ab2961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a2c3d034ab3f4fa4b84023e45054bb37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b85103561b294927b10b31dacbbccff7",
              "IPY_MODEL_396e533776cb4077a39d058076a0f273",
              "IPY_MODEL_a6f3bf664fed46bdafdc822f9ed32aee"
            ],
            "layout": "IPY_MODEL_78bcc09396ba4b4e90c57a13ce0b5b93",
            "tabbable": null,
            "tooltip": null
          }
        },
        "b85103561b294927b10b31dacbbccff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_60feec27d42c4d28b9624f7e154d13e9",
            "placeholder": "​",
            "style": "IPY_MODEL_529e83433aec48baa2d224f18e7f09c6",
            "tabbable": null,
            "tooltip": null,
            "value": "tokenizer.json: 100%"
          }
        },
        "396e533776cb4077a39d058076a0f273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_de6f782e22014a63b844437ba875d10b",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_951cd121fecb484fab0420b95ef6d38a",
            "tabbable": null,
            "tooltip": null,
            "value": 1795303
          }
        },
        "a6f3bf664fed46bdafdc822f9ed32aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_30ea0a982e78476c99df3d71fdda56ff",
            "placeholder": "​",
            "style": "IPY_MODEL_b176a4d2e1fe4536a4fee4e69ba7bb0d",
            "tabbable": null,
            "tooltip": null,
            "value": " 1.80M/1.80M [00:00&lt;00:00, 3.83MB/s]"
          }
        },
        "78bcc09396ba4b4e90c57a13ce0b5b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60feec27d42c4d28b9624f7e154d13e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529e83433aec48baa2d224f18e7f09c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "de6f782e22014a63b844437ba875d10b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "951cd121fecb484fab0420b95ef6d38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30ea0a982e78476c99df3d71fdda56ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b176a4d2e1fe4536a4fee4e69ba7bb0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "ad41084ecb1f48a7bb0c2cf9bdc90c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac16cef18b3047e8b2b9d1835474e4cf",
              "IPY_MODEL_61a8233455c3484ea855cf870177d6e8",
              "IPY_MODEL_826353cd707f4e76a6fee4bb16ac881c"
            ],
            "layout": "IPY_MODEL_394ac921a4054a869dee9fbe92ef5468",
            "tabbable": null,
            "tooltip": null
          }
        },
        "ac16cef18b3047e8b2b9d1835474e4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_9906dea00e9d48eda2ca8129f5a3046b",
            "placeholder": "​",
            "style": "IPY_MODEL_c60ec5300ec34af69cbec8c2b340f84a",
            "tabbable": null,
            "tooltip": null,
            "value": "special_tokens_map.json: 100%"
          }
        },
        "61a8233455c3484ea855cf870177d6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_a6adf9f29c66407d97d63d6cfa1bc93a",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a5e3e60cb2e42c394570c6bc8ad698b",
            "tabbable": null,
            "tooltip": null,
            "value": 72
          }
        },
        "826353cd707f4e76a6fee4bb16ac881c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1df7d49870744fefa745d464551c9d54",
            "placeholder": "​",
            "style": "IPY_MODEL_1c1125fd1b5f4b22a6bc11b38e566103",
            "tabbable": null,
            "tooltip": null,
            "value": " 72.0/72.0 [00:00&lt;00:00, 5.88kB/s]"
          }
        },
        "394ac921a4054a869dee9fbe92ef5468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9906dea00e9d48eda2ca8129f5a3046b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c60ec5300ec34af69cbec8c2b340f84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "a6adf9f29c66407d97d63d6cfa1bc93a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a5e3e60cb2e42c394570c6bc8ad698b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1df7d49870744fefa745d464551c9d54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c1125fd1b5f4b22a6bc11b38e566103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIAlchemy1/Generative-AI/blob/main/08_LLM_Fine_Tuning/LLM_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1. Interpretation with Logit Lens\n",
        "\n",
        "Logit Lens is an interpretation technique introduced in [this post](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens). The idea is the following. Imagine that we predict the continuation of a phrase \"IPhone was developed by\". We naturally expect to see \"Apple\", but we're also curious to see the \"thought process\" of an LLM, so we **feed outputs of intermediate layers (intermediate transformer blocks) to the classification head** to see *what would an LLM output if we cut its \"thought process\" short in the middle of it*. The general trend, as one moves from earlier to later layers, is\n",
        "- \"nonsense / not interpretable\" (sometimes, in very early layers) -->\n",
        "  - \"shallow guesses\" (words that are the right part of speech / register / etc) -->\n",
        "- \"better guesses\" near the end.\n",
        "However, it's not always like that, of course.\n",
        "\n",
        "The author of the Logit Lens also created visualization tools and published a [jupyter notebook demo](https://colab.research.google.com/drive/1MjdfK2srcerLrAJDRaJQKO0sUiZ-hQtA?usp=sharing) with cool pictures, but in this task we'll need to reproduce the Logit Lens technique on our own.\n",
        "\n",
        "**Note** If we're really short on compute, we can use GPT-2 instead of zephyr, but we risk losing all the fun and most of interpretability."
      ],
      "metadata": {
        "id": "HipjxMgiDZ4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1.1.** Write a function\n",
        "\n",
        "```\n",
        "logit_lens(model, input_sentence, top_k)\n",
        "```\n",
        "\n",
        "that for each transformer block returns a dictionary\n",
        "\n",
        "```\n",
        "{\n",
        "    'top_tokens' : [\n",
        "        sorted list of top_k tokens,\n",
        "        from most probable to least probable,\n",
        "        according to the classification head\n",
        "        ],\n",
        "    'top_token_logits' : [logits of these tokens]\n",
        "}\n",
        "```\n",
        "\n",
        "Hint:\n",
        "- To get hidden states of a model we'll need to use `model(**encoded_input, output_hidden_states=True)` instead of `model.generate`\n"
      ],
      "metadata": {
        "id": "D23vGULEFQsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is how it should work:"
      ],
      "metadata": {
        "id": "MtqnfCh2IYwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q accelerate"
      ],
      "metadata": {
        "id": "llVZfior0Lwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe65d28-ba9c-460a-eaa3-be0b64b5fd9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('stabilityai/stablelm-zephyr-3b')\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    'stabilityai/stablelm-zephyr-3b',\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "prompt = [{'role': 'user', 'content': 'List 3 synonyms for the word \"tiny\"'}]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    prompt,\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "tokens = model.generate(\n",
        "    inputs.to(model.device),\n",
        "    max_new_tokens=1024,\n",
        "    temperature=0.8,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ],
      "metadata": {
        "id": "JafFNnijBQ4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489,
          "referenced_widgets": [
            "a1b2901134ea4c3785191bf38d6b6679",
            "a8df78d9bf884cffa52848504cd0a3a2",
            "70ae8ca2e28e4fa4b37bf6e880dbf097",
            "c71663ed1a944066bf89a2660ca8c247",
            "9ce23f642f3645629d4f2e1cbd6b3ad8",
            "f6a2786266be4d63893257d35edc385c",
            "16eb9d8cc14048a792e9380095663e35",
            "fbe6beca15494398b5919b25b69971f4",
            "11a6e751a0bd46a09d31eac9648db51a",
            "d6ab65d25c47458f91b0ab27bce0d924",
            "1e89c37033a34f98be7988fe28e9076d",
            "6f78e8b2a7b849cbbeb9673e472f8953",
            "ad19aa3771224a5fa2e56b59d7779d98",
            "ae7ec4c2bc6240ac911fb73df739a689",
            "f7b5671a61cc4d44997f95f35b205603",
            "0227b2723672494b852201a8c6e573f5",
            "cf15ad859ccb4ed190d83721dd3fca36",
            "c3e002c6ecee4fada2adb4f5705c0e6d",
            "82f2a2f71988442cbef602fd6df3e186",
            "28c34f1c83334f708f8340b80945ae8d",
            "06c0fae86cfc4ce888b9720589bfa3ab",
            "cbba15d7a4c44328a8e0583693778225",
            "6a25b7d6c49740ecbf8d1a64388c72a7",
            "b42ce5008bb4431ca84daed4f4aaa26c",
            "b676927beb994913a54a64ccb53b13e2",
            "b1f7b839d419444bacbee8bf2a55890a",
            "c5dbc4749cbb44cc9f406e767ce7a808",
            "22e53e18f9b64bbc8c43f4f8f537e83b",
            "f56fd632b1e444ec84dd92aceb9fc94a",
            "4b87399fe1e54ef8af2c8315cd168f0f",
            "38b4209ea4914b7b816a1d5bfd04307d",
            "d2eb27d01422445e8735a60ddb29ba93",
            "c8ec8ea2591646cea9b265814aad8665",
            "69064717665b457db70b9b757d61f32d",
            "10f9a807e6b74b47ba0f667e2ec606c8",
            "01511cb332a740e48279a32532517af9",
            "ee505afac8384d179628663e1a0a9408",
            "7742f54a84e640bf85e9a6da28e8f36b",
            "e2ccd1f6833b4376b851b77ce3fe7dd1",
            "7ebc57604dbb475199e7b2646cb12da0",
            "100956e6948247298cac138300fa853d",
            "81c1cc4e462f4dbf891b4fc4946b5e3c",
            "1117604d6a534009a229ed5d39f2815a",
            "f1a8742198324fa0aa8f280edfa12f8d",
            "f08ecea54a0a4acb8d64d011ff34d072",
            "236d856e1f5b430b86638aec6c1e1945",
            "1a7cf227e66e4844b8ecf751d01df105",
            "452140429d974a74b50eacf264f1fc31",
            "ed2cf7c08bb5449c932744d8ab45b404",
            "ab683c7acd9d4de3a070b79327132a63",
            "43c2039cd0a449bcb74694edc53999c8",
            "25eb3ed4333545b9994172057aa8f68a",
            "d76a1d6dc9544efb807f3b15f0da9f11",
            "14010514e6574f94837f0efd7172858b",
            "0ead5b35c39b4816adbfeb22233e7d8a",
            "eb1b7b7d613a407baffa0b9e18ffe898",
            "98950d10fc6a4106806c99d5697a94a7",
            "3f984f3a535a4a06948de59293fb85a5",
            "40617703bbcd4cfd97f61bab28cb90ea",
            "b78b90df5b0f4b128687114a6735fdc8",
            "d025c23bca884eef9191a4fb0fddff12",
            "03b175b5c8cc4782ac1d4374f8b2e75c",
            "c5aaca12aef340818eca10967f5fda49",
            "1583442c1cbf4168ab7c93b297b3e65b",
            "7f5ad2e940744bcd833eb9c376c6730c",
            "86a14c44b7d445849a9b30c18c17ef90"
          ]
        },
        "outputId": "56cdc47b-56c1-49e4-b439-8e6ae6ac45d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/5.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1b2901134ea4c3785191bf38d6b6679"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f78e8b2a7b849cbbeb9673e472f8953"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/587 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a25b7d6c49740ecbf8d1a64388c72a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69064717665b457db70b9b757d61f32d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.59G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f08ecea54a0a4acb8d64d011ff34d072"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb1b7b7d613a407baffa0b9e18ffe898"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|user|>\n",
            "List 3 synonyms for the word \"tiny\"<|endoftext|>\n",
            "<|assistant|>\n",
            "1.élan (slang)\n",
            "2.petite (feminine)\n",
            "3.small<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def logit_lens(model, input_sentence, top_k=5):\n",
        "    # Tokenize the input sentence\n",
        "    tokenizer = AutoTokenizer.from_pretrained('stabilityai/stablelm-zephyr-3b')\n",
        "    inputs = tokenizer(input_sentence, return_tensors=\"pt\")\n",
        "\n",
        "    # Move the inputs to the same device as the model\n",
        "    inputs = inputs.to(model.device)\n",
        "\n",
        "    # Pass the tokens through the model to get the logits\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Get the probabilities from the logits\n",
        "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "    # Get the top k tokens and their probabilities\n",
        "    top_k_probs, top_k_tokens = torch.topk(probs, top_k, dim=-1)\n",
        "\n",
        "    # Flatten the tensor and convert it to a list of integers\n",
        "    top_k_tokens = top_k_tokens.flatten().tolist()\n",
        "\n",
        "    # Decode the tokens back into words\n",
        "    top_k_words = [tokenizer.decode([token]) for token in top_k_tokens]\n",
        "\n",
        "    # Convert tensor to numpy array and then to list\n",
        "    top_k_probs = top_k_probs.flatten().cpu().numpy().tolist()\n",
        "\n",
        "    return list(zip(top_k_words, top_k_probs))"
      ],
      "metadata": {
        "id": "zXSiOQx9Q8d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = logit_lens(model, \"IPhone was developed by\", top_k=5)"
      ],
      "metadata": {
        "id": "A0-j00fhH4wP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ac2629-ad71-45fe-c25e-e1100d65fcbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[-5:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8D5graFHVZg",
        "outputId": "a0f70e82-19d7-432d-8c31-ebe4fbc82cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(' Apple', 0.9472056031227112),\n",
              " (' a', 0.031474072486162186),\n",
              " (' the', 0.003716561710461974),\n",
              " (' IBM', 0.00304100732319057),\n",
              " (' an', 0.0029841407667845488)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, \"Apple\" appears as the most probable token in the last two layers."
      ],
      "metadata": {
        "id": "7rwbGrocR2CG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1.2**\n",
        "\n",
        "Now we'll use Logit Lens to investigate how transformers deal with redefinition.\n",
        "\n",
        "Use Logit Lens on the sentence\n",
        "\n",
        "```\n",
        "\"In this text the word IPhone means Windows operating system. IPhone was developed by\"\n",
        "```\n",
        "\n",
        "Look at the most probable tokens for all layers. A good LLM knows that IPhone was developed by Apple through *memorization*. However, *in-context learning* will press it to output Microsoft. Check in which layers the most probable token is Microsoft and in which it is Apple.\n",
        "\n",
        "Perform experiments with 9 other sentences with redefinition. Can we observe a pattern of competition between memorization and in-context learning?"
      ],
      "metadata": {
        "id": "4AkMOVa4SQDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def logit_lens(model, input_sentence, layer_idx, top_k=5):\n",
        "    # Tokenize the input sentence\n",
        "    tokenizer = AutoTokenizer.from_pretrained('stabilityai/stablelm-zephyr-3b')\n",
        "    inputs = tokenizer(input_sentence, return_tensors=\"pt\")\n",
        "\n",
        "    # Move the inputs to the same device as the model\n",
        "    inputs = inputs.to(model.device)\n",
        "\n",
        "    # Pass the tokens through the model to get the hidden states\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs, output_hidden_states=True)\n",
        "    hidden_states = outputs.hidden_states\n",
        "\n",
        "    # Get the logits for the specified layer\n",
        "    logits = hidden_states[layer_idx]\n",
        "\n",
        "    # Get the probabilities from the logits\n",
        "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "    # Get the top k tokens and their probabilities\n",
        "    top_k_probs, top_k_tokens = torch.topk(probs, top_k, dim=-1)\n",
        "\n",
        "    # Flatten the tensor and convert it to a list of integers\n",
        "    top_k_tokens = top_k_tokens.flatten().tolist()\n",
        "\n",
        "    # Decode the tokens back into words\n",
        "    top_k_words = [tokenizer.decode([token]) for token in top_k_tokens]\n",
        "\n",
        "    # Convert tensor to numpy array and then to list\n",
        "    top_k_probs = top_k_probs.flatten().cpu().numpy().tolist()\n",
        "\n",
        "    return list(zip(top_k_words, top_k_probs))"
      ],
      "metadata": {
        "id": "hz-X_zHuSYH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"In this text the word IPhone means Windows operating system. IPhone was developed by\"\n",
        "for layer_idx in range(model.config.num_hidden_layers):\n",
        "    print(f\"Layer {layer_idx}:\")\n",
        "    print(logit_lens(model, sentence, layer_idx))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoxwz9fFSg9Q",
        "outputId": "ff87fe8a-db2e-40d0-aa0a-37cedf3761fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ier', 0.0004038846818730235), ('yl', 0.00040309663745574653), ('ript', 0.0004018192703370005), ('AC', 0.00040147604886442423), ('\\x1e', 0.00040015499689616263), ('AC', 0.0004079891077708453), ('ript', 0.0004035313322674483), (' though', 0.000402891484554857), ('for', 0.0004015167651232332), (' true', 0.00040107587119564414), (').', 0.0004024695954285562), ('ire', 0.0004022240173071623), ('put', 0.000401439203415066), (' j', 0.0004002159694209695), ('uc', 0.0004001671331934631), (' though', 0.00041626900201663375), ('\\\\]', 0.00040961531340144575), (' treatment', 0.00040951528353616595), (' ab', 0.0004069240821991116), (' [@', 0.00040573367732577026), ('AC', 0.00040061501204036176), ('usion', 0.00040061501204036176), ('mu', 0.00040051722317002714), (' top', 0.0003996381419710815), ('ace', 0.00039949180791154504), ('AC', 0.0004137893265578896), (' best', 0.0004008625983260572), ('m', 0.0004005691152997315), (' complet', 0.000400275836000219), ('\\x01', 0.000400275836000219), (' look', 0.0004017601313535124), ('\\xa0\\xa0', 0.0004017601313535124), (' em', 0.00040166208054870367), (' sam', 0.0004006826493423432), ('all', 0.0003995104634668678), (' though', 0.00040500645991414785), ('angu', 0.00040107054519467056), ('ouse', 0.0004005323862656951), ('ant', 0.0004005323862656951), ('AC', 0.0004003368376288563), ('ection', 0.00040101123158819973), ('9', 0.00039974050014279783), ('resp', 0.0003996429149992764), (' dec', 0.00039949658093973994), ('ibility', 0.00039944786112755537), ('\">', 0.00039901037234812975), (' ad', 0.00039896168163977563), ('ds', 0.0003989129909314215), ('Name', 0.0003987182572018355), (' G', 0.0003987182572018355), (' bl', 0.00040360854472965), ('Ch', 0.0004023787041660398), (' require', 0.0004013485449831933), (' the', 0.0004010057309642434), (' Sh', 0.00040066323708742857), ('AC', 0.00042023436981253326), ('raw', 0.0004188004822935909), (' though', 0.0004126096609979868), ('imal', 0.0004103994579054415), (' leg', 0.0004056181642226875), ('AC', 0.0004137893265578896), (' best', 0.0004008625983260572), ('m', 0.0004005691152997315), (' complet', 0.000400275836000219), ('\\x01', 0.000400275836000219), (' look', 0.0004017601313535124), ('\\xa0\\xa0', 0.0004017601313535124), (' em', 0.00040166208054870367), (' sam', 0.0004006826493423432), ('all', 0.0003995104634668678), ('AC', 0.0004059005295857787), (' one', 0.0004050096613354981), (' though', 0.00040352914948016405), ('no', 0.0004033321747556329), ('yl', 0.00040288930176757276), ('y', 0.0004007631214335561), (' took', 0.000400225369958207), (' where', 0.000399981188820675), (' able', 0.00039978590211831033), (' spec', 0.00039963950985111296), ('AC', 0.00041226818575523794), (' though', 0.00041096180211752653), (' health', 0.00040429423097521067), (' sc', 0.0004041955107823014), (' one', 0.00040301308035850525)]\n",
            "\n",
            "Layer 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(' though', 0.0010163241531699896), ('AC', 0.0005943719297647476), ('ful', 0.0004822243645321578), ('ts', 0.000448944658273831), ('\\n', 0.00044588244054466486), (' though', 0.0007422598428092897), ('AC', 0.0005958924302831292), ('ological', 0.00042019219836220145), ('�', 0.00041891480213962495), (' read', 0.00041831526323221624), (' though', 0.0006919909501448274), ('AC', 0.0005059723043814301), ('etic', 0.0004662816063500941), (' similar', 0.00045869697351008654), ('ms', 0.0004243979346938431), (' though', 0.000700358476024121), ('AC', 0.0006342288106679916), ('se', 0.00042076868703588843), ('M', 0.0004186166333965957), (' air', 0.0004152584879193455), (' though', 0.0006855034735053778), ('AC', 0.0005302755744196475), (' similar', 0.0004676294338423759), ('etic', 0.000453170039691031), (',', 0.0004197322705294937), (' though', 0.0007154287886805832), ('AC', 0.0006054032128304243), (' why', 0.00043198169441893697), (' leg', 0.0004219850816298276), (' complet', 0.00041892568697221577), (' though', 0.0006800165283493698), ('etic', 0.00044330101809464395), (' leg', 0.00044187327148392797), (' why', 0.0004381716134957969), ('AC', 0.00043696985812857747), (' though', 0.0006501980824396014), ('AC', 0.0005465174908749759), ('ety', 0.0004397487791720778), (' health', 0.0004188286839053035), ('erm', 0.00041199856786988676), (' though', 0.0007703613373450935), ('ators', 0.00047272592200897634), ('etic', 0.0004470192943699658), ('AC', 0.0004389804962556809), (' why', 0.0004350166127551347), (' though', 0.0006788777536712587), ('etic', 0.0004841317131649703), ('ators', 0.0004764628829434514), ('AC', 0.000458153139334172), ('Ch', 0.00044167027226649225), (' though', 0.0007088871789164841), ('AC', 0.0005402793758548796), ('etic', 0.0004705548635683954), (' similar', 0.0004315947589930147), (' self', 0.00042720569763332605), ('ful', 0.0009286760468967259), (' though', 0.0008631651289761066), ('AC', 0.00077432842226699), (' treatment', 0.0005119406851008534), (' leg', 0.0004807557270396501), (' though', 0.0007072189473547041), ('AC', 0.000617652724031359), (' why', 0.00042656526784412563), (' leg', 0.0004177677910774946), (' indic', 0.00041715538827702403), (' though', 0.0006428894703276455), (' leg', 0.0004397355660330504), ('AC', 0.0004375040589366108), (' why', 0.0004363791667856276), ('etic', 0.0004334434343036264), (' though', 0.0006955907447263598), ('AC', 0.0006254700128920376), ('ety', 0.00041652657091617584), ('\\xa0\\xa0', 0.00041036485345102847), ('ign', 0.0004077365156263113), (' though', 0.0006458610878325999), ('AC', 0.0004950652946718037), ('etic', 0.0004466580576263368), ('ators', 0.00044386761146597564), ('ety', 0.0004400263715069741), (' though', 0.0007134492043405771), ('AC', 0.0006334151257760823), (' health', 0.00043112196726724505), (' sc', 0.00041640139534138143), (' cost', 0.0004153628833591938)]\n",
            "\n",
            "Layer 2:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(' though', 0.8253530859947205), ('\\n', 0.07031140476465225), ('ful', 0.00043677890789695084), ('ts', 0.00014398722851183265), ('name', 6.55666517559439e-05), (' though', 0.0011097417445853353), ('AC', 0.0005572344525717199), (' air', 0.0005090232589282095), ('ological', 0.00046798819676041603), ('our', 0.00045268525718711317), (' though', 0.0008399335201829672), (' similar', 0.0005408626748248935), ('etic', 0.0005035022622905672), ('AC', 0.0004685747262556106), (' under', 0.00046473118709400296), ('\\n', 0.857668936252594), (' though', 0.142331063747406), (' treatment', 8.904098704014263e-13), ('name', 8.737409125207651e-13), ('ts', 8.447244639886442e-13), (' though', 0.0007431106641888618), (' similar', 0.0005764754605479538), ('AC', 0.0005262629711069167), ('etic', 0.0005224442575126886), ('ate', 0.0004649768816307187), (' though', 0.0009831814095377922), ('AC', 0.0006069221417419612), (' why', 0.0004582620458677411), (' leg', 0.0004365336790215224), ('br', 0.00043505110079422593), (' though', 0.000794081250205636), ('No', 0.00048732198774814606), ('\\n', 0.0004642136045731604), ('ators', 0.0004629710747394711), (' leg', 0.0004615702200680971), (' though', 0.0006923001492395997), ('AC', 0.0005849525914527476), ('ety', 0.00051263312343508), (' health', 0.00045310327550396323), (' path', 0.0004385592183098197), (' though', 0.0010416751028969884), ('ators', 0.0005417214706540108), ('etic', 0.000500078487675637), (' X', 0.0004566325224004686), ('bar', 0.00045507895993068814), (' though', 0.0006551305996254086), ('etic', 0.0005835171323269606), ('ators', 0.0005453262128867209), ('AC', 0.0004730074433609843), ('Ch', 0.0004585431015584618), (' though', 0.0007100916700437665), ('etic', 0.0006310274475254118), ('AC', 0.0005866074934601784), ('Ch', 0.00047195778461173177), (' self', 0.00044964399421587586), (' though', 0.656037449836731), ('\\n', 0.3439474105834961), ('ful', 1.2000117521893117e-07), (' treatment', 1.971255514376935e-08), ('name', 1.6676050762498562e-08), (' though', 0.0009241390507668257), ('AC', 0.0006284067058004439), ('raw', 0.0004517326015047729), (' leg', 0.00044838126632384956), (' why', 0.0004483525990508497), (' though', 0.0007014208240434527), ('No', 0.0004785349883604795), ('ators', 0.00046078854938969016), (' leg', 0.00045408715959638357), (' similar', 0.0004516579501796514), (' though', 0.0008335091988556087), ('AC', 0.0006588627002201974), ('cret', 0.00042553621460683644), (' room', 0.00042262455099262297), ('}{', 0.0004224001313559711), (' though', 0.0006617940962314606), ('AC', 0.0005304926307871938), ('ators', 0.0004930555587634444), ('etic', 0.0004920358769595623), ('Ch', 0.0004661169077735394), (' though', 0.0008578978595323861), ('AC', 0.0006522695766761899), (' health', 0.0004607648588716984), (' cost', 0.0004503214149735868), (' sc', 0.0004377840959932655)]\n",
            "\n",
            "Layer 3:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(' though', 0.9862663745880127), ('\\n', 0.01249729935079813), ('ful', 6.222774572961498e-06), ('ts', 4.731202807306545e-06), ('name', 8.412169449911744e-07), (' though', 0.002894763136282563), ('\\n', 0.0005746880196966231), (' air', 0.0005562981241382658), ('AC', 0.0005145559553056955), ('ological', 0.0005093708168715239), (' though', 0.00161697156727314), (' similar', 0.0005836552008986473), ('etic', 0.0005205500638112426), ('\\n', 0.0004994088085368276), (' under', 0.0004926170804537833), ('\\n', 0.6706891655921936), (' though', 0.3293108344078064), ('ts', 2.2670760939109275e-13), ('name', 2.2169766022983595e-13), ('gr', 1.8784363712935626e-13), (' though', 0.0011923661222681403), (' similar', 0.000624299980700016), ('etic', 0.0005336672766134143), ('AC', 0.0005014727939851582), ('ate', 0.000472029933007434), (' though', 0.0014398818602785468), ('AC', 0.0005954333464615047), ('\\n', 0.0004903491353616118), (' why', 0.00047272854135371745), ('br', 0.0004603553388733417), (' though', 0.001068786601535976), ('ators', 0.0005302224308252335), ('No', 0.0005281174089759588), (' similar', 0.0005007595755159855), ('hen', 0.00047602743143215775), (' though', 0.0007846647640690207), ('AC', 0.0005908727762289345), ('ety', 0.0005503133870661259), (' health', 0.0004855029401369393), (' similar', 0.0004573295882437378), (' though', 0.002569403499364853), ('ators', 0.0005963120493106544), ('etic', 0.0005224447231739759), (' pract', 0.0004875967279076576), ('\\n', 0.0004733755486086011), (' though', 0.0007931103464215994), ('etic', 0.0006104946951381862), ('ators', 0.0005647627986036241), ('AC', 0.0004889052943326533), ('—', 0.0004772050306200981), (' though', 0.0009252371964976192), ('etic', 0.000882669526617974), ('AC', 0.0005886630970053375), (' self', 0.0005245469510555267), ('ate', 0.00047983290278352797), (' though', 0.8447656035423279), ('\\n', 0.1552327424287796), ('ful', 1.884337841318029e-08), ('name', 2.307544821888996e-09), (' res', 1.5032701750072874e-09), (' though', 0.001012059859931469), ('AC', 0.0006366674788296223), ('raw', 0.0005865343264304101), (' leg', 0.0004646906163543463), (' best', 0.00046140202903188765), (' though', 0.0009477221174165606), ('ators', 0.0005283030914142728), ('No', 0.0005072266794741154), (' similar', 0.000505659612827003), ('hen', 0.00048267634701915085), (' though', 0.0010734280804172158), ('AC', 0.0006655197939835489), ('}{', 0.0004431201086845249), (' room', 0.00043506233487278223), (' V', 0.00043146111420355737), (' though', 0.0007706824108026922), ('AC', 0.0005412166938185692), ('etic', 0.0005102675640955567), ('ators', 0.000509747420437634), ('Ch', 0.000505828473251313), (' though', 0.0010018897010013461), ('AC', 0.0006467844941653311), ('ety', 0.00047566837747581303), (' cost', 0.0004722715530078858), (' sc', 0.0004562846152111888)]\n",
            "\n",
            "Layer 4:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.003237247234210372), (' air', 0.0006080061430111527), ('AC', 0.0005670571699738503), ('ological', 0.0005293986760079861), ('ety', 0.0005021175602450967), (' though', 0.0022958433255553246), (' similar', 0.0006231319275684655), ('etic', 0.0005742900539189577), ('\\n', 0.0005528376786969602), ('ety', 0.0005184077890589833), (' though', 0.004336543846875429), (' air', 0.0006345169967971742), ('AC', 0.0005354281165637076), ('}{', 0.0004861900524701923), ('om', 0.00048444149433635175), (' though', 0.0014601959846913815), (' similar', 0.0007265399908646941), ('etic', 0.0005536281387321651), ('AC', 0.0005373082240112126), ('ate', 0.0005170427612029016), (' though', 0.0016220611287280917), ('AC', 0.000638019701000303), (' why', 0.0005061118281446397), ('our', 0.0004902688669972122), ('tern', 0.00048415939090773463), (' though', 0.0006808926118537784), ('ators', 0.0006005184259265661), ('No', 0.0005977657856419683), (' similar', 0.0005896918592043221), (' how', 0.000544312410056591), (' though', 0.0014908717712387443), ('ety', 0.0007126742275431752), ('AC', 0.0006215636385604739), (' similar', 0.0005305968225002289), (' health', 0.0005127934855408967), (' though', 0.001332295243628323), ('ators', 0.0006394703523255885), ('etic', 0.0005816650227643549), (' pract', 0.0005067003658041358), ('ob', 0.0005027252482250333), ('etic', 0.0007345200283452868), ('ators', 0.0005723316571675241), ('AC', 0.0005497661768458784), (' sm', 0.0005075569497421384), ('pped', 0.000504818104673177), ('etic', 0.0010487788822501898), (' though', 0.0006657467456534505), ('AC', 0.0006354249198921025), ('Ch', 0.0005206696805544198), ('leg', 0.0005126982578076422), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.0018514067633077502), ('raw', 0.0006860577268525958), ('AC', 0.0006413671071641147), (' leg', 0.0004795201530214399), (' why', 0.0004662555584218353), (' though', 0.0007508823764510453), ('No', 0.0006003538728691638), (' similar', 0.0005656110588461161), ('ators', 0.0005647712969221175), ('ump', 0.0005577121046371758), (' though', 0.0023246249184012413), ('AC', 0.00067500164732337), ('ety', 0.0004786447389051318), (' V', 0.0004724237078335136), (' need', 0.00046244176337495446), (' though', 0.0010677878744900227), ('ety', 0.0005925024743191898), ('etic', 0.0005905535072088242), ('Ch', 0.0005548883927986026), ('AC', 0.0005324959638528526), (' though', 0.0020533627830445766), ('AC', 0.0006260278169065714), (' cost', 0.0005439926171675324), ('ety', 0.000531198107637465), ('}{', 0.0005079705151729286)]\n",
            "\n",
            "Layer 5:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.002993938745930791), (' air', 0.0006260685040615499), ('AC', 0.0005874668131582439), ('ological', 0.0005735219456255436), ('ety', 0.00051604158943519), (' though', 0.0024860547855496407), (' similar', 0.0006734671769663692), ('etic', 0.0006160004995763302), ('att', 0.0005271707195788622), ('put', 0.0005214386619627476), (' though', 0.0029414654709398746), ('AC', 0.0006215024623088539), (' air', 0.0005753201548941433), ('i', 0.0005402620299719274), ('ution', 0.0004968260182067752), (' though', 0.001899553695693612), (' similar', 0.0008367919945158064), ('etic', 0.0006252105231396854), ('ate', 0.0005354710156098008), ('AC', 0.000525851093698293), (' though', 0.0030777915380895138), ('AC', 0.0006121285259723663), (' why', 0.0005605959449894726), (' issue', 0.0004920330829918385), ('our', 0.0004890061682090163), (' though', 0.0022986638359725475), ('ators', 0.0007355338311754167), (' why', 0.0006485583144240081), (' similar', 0.0006444303435273468), ('No', 0.0006234987522475421), (' though', 0.002666289219632745), ('ety', 0.0007547008572146297), ('AC', 0.0006232793675735593), (' health', 0.0006177916657179594), (' similar', 0.0005703021306544542), (' though', 0.0018512933747842908), ('ators', 0.0007350129308179021), ('etic', 0.0007028203108347952), ('ob', 0.0005524155567400157), ('div', 0.0005426712450571358), ('etic', 0.0009440019493922591), (' though', 0.0006737433723174036), ('ators', 0.0006144001963548362), ('AC', 0.0005826830165460706), ('Ch', 0.0005120074492879212), ('etic', 0.0014083478599786758), ('AC', 0.0007549509755335748), ('ump', 0.0006035667029209435), ('--', 0.0005568734486587346), ('Ch', 0.0005505494773387909), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.0039049354381859303), ('raw', 0.0007443873910233378), ('AC', 0.0006098536541685462), (' why', 0.00048697777674533427), (' leg', 0.00048151364899240434), (' though', 0.0015287460992112756), ('ators', 0.000639543985016644), (' why', 0.0006337793893180788), ('No', 0.0006054739933460951), ('ump', 0.000604611705057323), (' though', 0.003409049240872264), ('AC', 0.0006649912102147937), (' V', 0.0004928389098495245), ('}{', 0.0004748203791677952), ('\\x1d', 0.00046212098095566034), (' though', 0.001246185856871307), ('ety', 0.0006363455904647708), ('etic', 0.0006337527884170413), ('Ch', 0.000627926376182586), ('ators', 0.0005517789977602661), (' though', 0.00248003751039505), ('AC', 0.0006185511010698974), (' cost', 0.00059562548995018), ('ety', 0.0005742557696066797), (' better', 0.0005123306764289737)]\n",
            "\n",
            "Layer 6:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.004676360636949539), (' air', 0.0006799738039262593), ('AC', 0.0006187430117279291), ('ety', 0.0005938761169090867), ('ological', 0.0005890167667530477), (' though', 0.0026989353355020285), (' similar', 0.0007114466279745102), ('etic', 0.000705217884387821), ('ms', 0.000552734883967787), ('ety', 0.0005361916264519095), (' though', 0.0028825821354985237), ('AC', 0.0006985212094150484), (' air', 0.0005880278185941279), ('put', 0.000548212556168437), ('raw', 0.0005453319754451513), (' though', 0.001034185872413218), (' similar', 0.000981440651230514), ('etic', 0.0006267064018175006), ('AC', 0.0006073887343518436), ('very', 0.0005745748057961464), (' though', 0.0015072227688506246), ('AC', 0.0007189419120550156), (' why', 0.0005549250636249781), (' method', 0.000522504560649395), (' issue', 0.0005173583631403744), (' though', 0.0016132013406604528), ('ators', 0.0009167250245809555), ('etic', 0.000763345742598176), (' similar', 0.0006905150366947055), (' why', 0.0006208919803611934), (' though', 0.00186474050860852), ('ety', 0.0010759972501546144), ('AC', 0.000738230999559164), (' similar', 0.0005999307613819838), (' health', 0.0005963525618426502), (' though', 0.0015991070540621877), ('ators', 0.0008579901768825948), ('etic', 0.0007774934638291597), (' pract', 0.000600221857894212), (' else', 0.000585672096349299), ('etic', 0.0010043835500255227), ('ators', 0.0007001701160334051), ('AC', 0.0006536783766932786), (' though', 0.000628868758212775), ('ump', 0.0005423706606961787), ('etic', 0.0015643811784684658), ('AC', 0.0008125136373564601), ('ump', 0.0007023959769867361), ('�', 0.0006019206484779716), ('Ch', 0.0005652802647091448), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.0023720506578683853), ('raw', 0.0007110834703780711), ('AC', 0.0006611451972275972), (' leg', 0.0005485523142851889), ('ex', 0.0005141322035342455), (' though', 0.0015078469878062606), ('ators', 0.0007594465860165656), ('etic', 0.0007533786119893193), (' why', 0.000671482237521559), ('ump', 0.0006514688720926642), (' though', 0.0047225505113601685), ('AC', 0.0006597268511541188), (' V', 0.0005057606613263488), ('}{', 0.0004884516238234937), (' risk', 0.0004801130562555045), (' though', 0.0018826607847586274), ('etic', 0.0006883498863317072), ('ety', 0.0006499160081148148), ('Ch', 0.0006410391069948673), ('ars', 0.0006189088453538716), (' though', 0.00394825916737318), ('ety', 0.0006513494299724698), (' cost', 0.0006253393366932869), ('AC', 0.0006061318563297391), ('ars', 0.0005667712539434433)]\n",
            "\n",
            "Layer 7:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.0030529580544680357), ('\\n', 0.0008117904071696103), (' air', 0.0007541117374785244), ('ological', 0.0006836489192210138), ('ety', 0.0006374348886311054), (' though', 0.003663144074380398), ('\\n', 0.0015995812136679888), ('etic', 0.0007912765140645206), (' similar', 0.0007372808759100735), (' ab', 0.0006537296576425433), (' though', 0.0012632999569177628), ('AC', 0.0008010541787371039), ('raw', 0.0006450676009990275), (' air', 0.0006048163049854338), ('put', 0.0005840005469508469), (' though', 0.001168599701486528), (' similar', 0.0010776640847325325), ('\\n', 0.0007916072499938309), ('etic', 0.0006408437620848417), (' best', 0.0005876155919395387), (' though', 0.0008633416146039963), ('AC', 0.0007552984752692282), ('\\n', 0.0006839466514065862), ('am', 0.0005340484785847366), (' method', 0.0005330130807124078), ('\\n', 0.0015333793126046658), (' though', 0.0015113266417756677), ('ators', 0.001120791886933148), ('etic', 0.0008678039303049445), (' similar', 0.0006970551912672818), (' though', 0.0023403349332511425), ('ety', 0.0011376077309250832), ('\\n', 0.00084697111742571), ('AC', 0.0008119136327877641), ('ard', 0.000617282756138593), (' though', 0.001047563157044351), ('\\n', 0.001015844289213419), ('ators', 0.0010127718560397625), ('etic', 0.000849977950565517), (' pract', 0.0006592494319193065), ('etic', 0.0012221073266118765), ('AC', 0.000742133881431073), ('ators', 0.0007349418592639267), ('\\n', 0.0006393240764737129), (' sum', 0.0005779867060482502), ('etic', 0.0018015038222074509), ('AC', 0.0008219373994506896), ('ump', 0.0006585738738067448), ('ory', 0.0006070847739465535), ('�', 0.0005706594092771411), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.0017098459647968411), ('\\n', 0.0008330661221407354), ('raw', 0.0008162556914612651), ('AC', 0.0007113450556062162), ('ump', 0.0005608078208751976), ('ators', 0.0008887723088264465), ('etic', 0.0007228297763504088), (' why', 0.0006617029430344701), (' though', 0.0006435431423597038), ('\\n', 0.0006341313128359616), (' though', 0.006561934947967529), ('\\n', 0.0008321465575136244), ('AC', 0.0006521122995764017), (' V', 0.0005157269770279527), (' phys', 0.0005115498788654804), (' though', 0.002144930185750127), ('\\n', 0.0007563946419395506), ('Ch', 0.0007271597278304398), ('etic', 0.0006989295943640172), ('ars', 0.0006794088985770941), (' though', 0.00333492667414248), ('\\n', 0.0009198606130667031), (' cost', 0.0006626805406995118), ('ars', 0.0006272089085541666), ('AC', 0.0006167982937768102)]\n",
            "\n",
            "Layer 8:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.003279320430010557), ('\\n', 0.0013772723032161593), (' air', 0.0009346961160190403), ('ety', 0.0007814686396159232), ('ological', 0.0007206785958260298), ('\\n', 0.003305430756881833), (' though', 0.003287828527390957), ('etic', 0.0010271500796079636), (' similar', 0.0007808223599568009), ('put', 0.0006516119465231895), (' though', 0.0015399499097838998), ('\\n', 0.0008880618843249977), ('AC', 0.0008021302637644112), ('ety', 0.0007157644722610712), (' air', 0.0006670909351669252), ('\\n', 0.0014737793244421482), (' though', 0.001406351337209344), (' similar', 0.0011438721558079123), ('etic', 0.0007234917138703167), ('�', 0.0006626881076954305), (' though', 0.000898048747330904), ('AC', 0.0008783743833191693), ('\\n', 0.0008144216844812036), (' why', 0.0006829283083789051), ('18', 0.0006103161140345037), ('\\n', 0.0035415368620306253), (' though', 0.001577193383127451), ('ators', 0.0012897654669359326), ('etic', 0.0011175797553732991), (' similar', 0.0008056952501647174), (' though', 0.0021638369653373957), ('\\n', 0.0013583068503066897), ('ety', 0.0012540781171992421), ('AC', 0.0008352993172593415), (' similar', 0.0006555021973326802), ('\\n', 0.0015245153335854411), ('ators', 0.00131618557497859), ('etic', 0.0008918045787140727), (' though', 0.0007624002755619586), ('mun', 0.000659693032503128), ('etic', 0.0016059877816587687), ('ators', 0.0008984417654573917), ('\\n', 0.00085622095502913), ('AC', 0.0006948235677555203), ('18', 0.0006278807413764298), ('etic', 0.002491760067641735), ('\\n', 0.0016135197365656495), ('AC', 0.0007759713917039335), ('ory', 0.0006744276033714414), ('ump', 0.0006292093312367797), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.0017172767547890544), ('\\n', 0.0013804556801915169), ('raw', 0.0012480613077059388), ('AC', 0.0007958856294862926), ('18', 0.0006091072573326528), ('\\n', 0.0010559775400906801), ('ators', 0.0010460630292072892), ('etic', 0.0008300544577650726), (' though', 0.0007886483217589557), (' why', 0.0007437118329107761), (' though', 0.0053413077257573605), ('\\n', 0.001240276382304728), ('AC', 0.0006478252471424639), (' circ', 0.0005930367624387145), (' character', 0.0005771323922090232), (' though', 0.0014729499816894531), ('\\n', 0.0009178472682833672), ('Ch', 0.0008086725138127804), ('etic', 0.0008040285902097821), ('ars', 0.0007596915820613503), (' though', 0.003582561621442437), ('\\n', 0.0016062298091128469), (' cost', 0.0007048413972370327), ('ars', 0.0006657743942923844), ('An', 0.0006446985062211752)]\n",
            "\n",
            "Layer 9:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.005285189021378756), ('\\n', 0.0014087208546698093), (' air', 0.0010951112490147352), ('ological', 0.000768417667131871), ('ety', 0.0007111707236617804), ('\\n', 0.004635448567569256), (' though', 0.0034450211096554995), ('etic', 0.001283567980863154), (' ab', 0.0009058174910023808), (' similar', 0.0008431845926679671), (' though', 0.0030125086195766926), ('\\n', 0.001725142588838935), ('AC', 0.0007592562469653785), ('raw', 0.0007510744035243988), ('ety', 0.0007394372369162738), (' similar', 0.001387565629556775), ('\\n', 0.001282242126762867), (' though', 0.0011225421912968159), ('etic', 0.0008247431833297014), (' sc', 0.0006988157401792705), ('\\n', 0.0036235081497579813), (' though', 0.002178281545639038), (' why', 0.0008448947337456048), ('18', 0.0007942956872284412), ('AC', 0.000769894861150533), ('\\n', 0.0063446587882936), (' though', 0.0015593282878398895), ('etic', 0.0014164565363898873), ('ators', 0.0013867244124412537), (' similar', 0.0008920375839807093), (' though', 0.0018865299643948674), ('\\n', 0.001755183795467019), ('ety', 0.0011600400321185589), ('AC', 0.0008774246089160442), ('�', 0.0007519914652220905), ('\\n', 0.002731528365984559), ('ators', 0.0016531769651919603), ('etic', 0.0010443900246173143), (' though', 0.0009127398952841759), (' pract', 0.0006969845271669328), ('etic', 0.0025277556851506233), ('\\n', 0.0014397064223885536), ('ators', 0.0009774434147402644), ('18', 0.0007434761500917375), ('\\x1e', 0.000693559180945158), ('etic', 0.004502782132476568), ('\\n', 0.0032452179584652185), ('AC', 0.0008041700930334628), (' though', 0.0007539755315519869), ('ump', 0.0006842426955699921), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('\\n', 0.004682043567299843), (' though', 0.004556938540190458), ('raw', 0.0019001762848347425), ('AC', 0.0007195569342002273), ('18', 0.0006578262546099722), ('\\n', 0.002023265464231372), ('ators', 0.0011901567922905087), (' though', 0.0009749322198331356), ('etic', 0.0009454262326471508), (' why', 0.0007734096143394709), (' though', 0.007217948790639639), ('\\n', 0.0021390835754573345), ('AC', 0.0006925060297362506), (' character', 0.0006685899570584297), ('ret', 0.0006208671838976443), (' though', 0.001946157542988658), ('\\n', 0.001241261139512062), ('etic', 0.0009860574500635266), ('ars', 0.0008327792165800929), ('Ch', 0.000752483494579792), (' though', 0.0037114338483661413), ('\\n', 0.0015325126005336642), (' cost', 0.0007457704050466418), ('ars', 0.000740312912967056), ('}{', 0.0006671068840660155)]\n",
            "\n",
            "Layer 10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.007593794260174036), ('\\n', 0.0016213605413213372), (' air', 0.0011972960783168674), ('ety', 0.0008277721935883164), ('ars', 0.0008240515599027276), ('\\n', 0.004776687826961279), (' though', 0.00376777327619493), ('etic', 0.001515579642727971), (' ab', 0.0011319346958771348), ('put', 0.000873279816005379), (' though', 0.0036915999371558428), ('\\n', 0.0017738101305440068), ('ety', 0.0007513821474276483), ('put', 0.0007477301987819374), ('AC', 0.0007311592344194651), (' though', 0.0017651780508458614), ('\\n', 0.0013746884651482105), (' similar', 0.0013510986464098096), (' sc', 0.0007766670896671712), ('etic', 0.0007756126578897238), ('\\n', 0.0010137264616787434), (' though', 0.0009478805004619062), ('18', 0.0008434957708232105), (' why', 0.000771673396229744), ('ars', 0.0007599831442348659), ('\\n', 0.003188742557540536), ('ators', 0.0017399042844772339), ('etic', 0.001432399032637477), (' though', 0.001175182987935841), (' similar', 0.0009858676930889487), (' though', 0.0012792099732905626), ('ety', 0.0012362044071778655), ('AC', 0.0009374570799991488), ('type', 0.0008354376768693328), ('\\n', 0.0008059328538365662), ('ators', 0.001885114354081452), ('\\n', 0.0018297226633876562), ('etic', 0.0010420259786769748), ('ument', 0.0008153808885253966), (' though', 0.0007568479049950838), ('etic', 0.0029439034406095743), ('ators', 0.0009503397159278393), ('\\n', 0.000783373776357621), ('18', 0.0007803448243066669), ('ilon', 0.000756271299906075), ('etic', 0.005170837976038456), ('\\n', 0.0014538596151396632), ('AC', 0.0008899859967641532), ('Ch', 0.0006820318521931767), (' des', 0.0006681192317046225), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.002616471378132701), ('\\n', 0.002251897007226944), ('raw', 0.002184053882956505), ('ars', 0.0007652842323295772), ('AC', 0.0007260224083438516), ('ators', 0.0013799798907712102), ('etic', 0.0011109299957752228), (' similar', 0.0009571336559019983), ('}{', 0.0008914488716982305), (' why', 0.0008359724888578057), (' though', 0.005951439496129751), ('\\n', 0.0012049115030094981), ('ars', 0.0006762297707609832), ('AC', 0.0006634705932810903), (' character', 0.0006611472927033901), (' though', 0.002496026922017336), ('\\n', 0.0014556827954947948), ('etic', 0.0011626557679846883), ('ars', 0.0008595482795499265), ('Ch', 0.0007862895145080984), (' though', 0.0047915163449943066), ('\\n', 0.0020312636625021696), ('ars', 0.0008243939955718815), (' cost', 0.0007704175659455359), ('}{', 0.0006721712416037917)]\n",
            "\n",
            "Layer 11:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.00490428926423192), (' air', 0.0013009165413677692), ('\\n', 0.000927217595744878), ('ars', 0.0008978372206911445), ('ety', 0.0007854431169107556), ('\\n', 0.006457902491092682), (' though', 0.004128957167267799), ('etic', 0.001526338397525251), (' ab', 0.001461207284592092), ('put', 0.0009444757597520947), (' though', 0.004551906604319811), ('\\n', 0.0020638201385736465), ('AC', 0.0008529460174031556), (' air', 0.0008042239933274686), ('lection', 0.0008036289946176112), (' though', 0.001439462648704648), (' similar', 0.0014285242650657892), ('\\n', 0.0010087150149047375), (' sc', 0.000964521081186831), ('p', 0.0007430032128468156), ('\\n', 0.0016226352890953422), (' though', 0.001519444165751338), ('18', 0.000996092101559043), ('ars', 0.0009850163478404284), (' why', 0.0008219977607950568), ('\\n', 0.008059609681367874), ('ators', 0.002374140312895179), (' though', 0.00229241163469851), ('etic', 0.0019620652310550213), (' similar', 0.001099883927963674), (' though', 0.0031180079095065594), ('\\n', 0.0019813429098576307), ('ety', 0.001155829057097435), ('AC', 0.0008548409678041935), ('type', 0.0008518944378010929), ('\\n', 0.0063388766720891), (' though', 0.0024502442684024572), ('ators', 0.002237966051325202), ('etic', 0.0013236516388133168), (' pract', 0.0008772847359068692), ('etic', 0.003915002569556236), ('ators', 0.0010886701056733727), ('\\n', 0.0009304392151534557), ('18', 0.0008693967247381806), ('AC', 0.0007806275971233845), ('etic', 0.007063321769237518), ('\\n', 0.005241038277745247), (' though', 0.0013674652436748147), ('AC', 0.0009624219383113086), ('18', 0.0007356330752372742), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.004161374177783728), ('\\n', 0.002725012367591262), ('raw', 0.002694870112463832), ('ars', 0.000851670338306576), ('AC', 0.0008145070169121027), ('\\n', 0.0019982405938208103), ('etic', 0.001680157845839858), ('ators', 0.0016417759470641613), (' though', 0.0012991962721571326), (' similar', 0.000926363340113312), (' though', 0.008648177608847618), ('\\n', 0.0015097588766366243), ('AC', 0.0007699987618252635), ('ars', 0.0007649038452655077), (' character', 0.0007574536721222103), (' though', 0.0041941008530557156), ('\\n', 0.001929377787746489), ('etic', 0.0014196877600625157), ('ars', 0.0009254093747586012), ('ators', 0.0007498657796531916), (' though', 0.004681435413658619), ('\\n', 0.001597441267222166), ('ars', 0.0008559157140552998), (' cost', 0.0007648765458725393), ('�', 0.0007604292477481067)]\n",
            "\n",
            "Layer 12:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.014328183606266975), ('\\n', 0.0021431308705359697), (' air', 0.0014930183533579111), ('ars', 0.0008786338148638606), ('ms', 0.0008308591204695404), ('\\n', 0.007866578176617622), (' though', 0.006145210471004248), (' ab', 0.0016656327061355114), ('etic', 0.0015849346527829766), ('put', 0.0010717172408476472), (' though', 0.007805203553289175), ('\\n', 0.002945002168416977), ('put', 0.0008994749514386058), (' air', 0.0007709151250310242), ('AC', 0.0007513576420024037), (' though', 0.0018939245492219925), (' similar', 0.001412845915183425), ('\\n', 0.0013183722039684653), (' sc', 0.0010322339367121458), ('ploy', 0.0007998114451766014), ('\\n', 0.0016979686915874481), (' though', 0.0016002404736354947), ('18', 0.001151114935055375), ('ars', 0.001018022419884801), (' why', 0.0008768991101533175), ('\\n', 0.01793835125863552), (' though', 0.0032860643696039915), ('etic', 0.0028378257993608713), ('ators', 0.0027185925282537937), (' similar', 0.0011601903242990375), (' though', 0.002061089500784874), ('ety', 0.0011012095492333174), (' process', 0.000992110464721918), ('type', 0.0009474099497310817), ('AC', 0.0008741117781028152), ('\\n', 0.006216101814061403), (' though', 0.0031196018680930138), ('ators', 0.002637907164171338), ('etic', 0.0016652393387630582), (' pract', 0.0009472226956859231), ('etic', 0.007460169494152069), ('\\n', 0.002130019012838602), ('ators', 0.001039027003571391), ('18', 0.000985866878181696), (' strong', 0.0008413083851337433), ('etic', 0.01041759829968214), ('\\n', 0.006117659155279398), (' though', 0.001919631497003138), ('AC', 0.0008501002448610961), (' turn', 0.0008375472389161587), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.0025137532502412796), ('raw', 0.0021050055511295795), ('\\n', 0.001019359682686627), (' told', 0.000916067510843277), ('ars', 0.0008894619531929493), ('\\n', 0.004275039304047823), (' though', 0.0023898303043097258), ('etic', 0.002118482021614909), ('ators', 0.001865668105892837), (' why', 0.0010948441922664642), (' though', 0.013479257002472878), ('\\n', 0.002481791889294982), ('ars', 0.0008395291515626013), ('AC', 0.0007610193570144475), (' hand', 0.0007257774705067277), (' though', 0.005011704284697771), ('etic', 0.001839501434005797), ('\\n', 0.0017610073555260897), ('ars', 0.001062295283190906), ('ators', 0.0007992053288035095), (' though', 0.005848567467182875), ('\\n', 0.0021218005567789078), ('ars', 0.0009828456677496433), (' cost', 0.0008310960256494582), ('�', 0.0008229820523411036)]\n",
            "\n",
            "Layer 13:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.014393935911357403), ('\\n', 0.002137515926733613), (' air', 0.0016305866884067655), ('ars', 0.0010851852130144835), ('ms', 0.0010222839191555977), ('\\n', 0.014047623611986637), (' though', 0.007906888611614704), (' ab', 0.001875370740890503), ('etic', 0.001589975319802761), ('put', 0.0011490605538710952), (' though', 0.01991286128759384), ('\\n', 0.00926835648715496), ('span', 0.0009275197517126799), ('put', 0.0008998347329907119), (' air', 0.0008794637979008257), (' though', 0.0020667288918048143), (' similar', 0.001523943617939949), ('\\n', 0.0011153004597872496), (' sc', 0.001076876069419086), (' However', 0.0008865849813446403), (' though', 0.0013793675461784005), ('ars', 0.0013249486219137907), ('\\n', 0.0012290956219658256), ('18', 0.001126511488109827), (' why', 0.0009161362540908158), ('\\n', 0.022680217400193214), (' though', 0.0035675240214914083), ('etic', 0.002970146480947733), ('ators', 0.002809855155646801), (' cost', 0.0012966740177944303), (' though', 0.00591433048248291), ('\\n', 0.0022797551937401295), ('ety', 0.001163157750852406), ('\\n    ', 0.0010162305552512407), ('type', 0.0010127680143341422), ('\\n', 0.009948167018592358), (' though', 0.004343792796134949), ('ators', 0.00271450262516737), ('etic', 0.0020048965234309435), ('ased', 0.0009744418784976006), ('etic', 0.010562284849584103), ('\\n', 0.003552695270627737), ('ators', 0.0010819373419508338), ('18', 0.0010250373743474483), (' hum', 0.0008866544812917709), ('etic', 0.013485732488334179), ('\\n', 0.008982264436781406), (' though', 0.002851729979738593), (' turn', 0.0008435509516857564), ('AC', 0.0007980055524967611), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.026943912729620934), ('\\n', 0.025882303714752197), ('raw', 0.002605319954454899), (' Co', 0.0009572614217177033), (' by', 0.0009192454745061696), ('etic', 0.002183472039178014), ('ators', 0.0020017516799271107), (' similar', 0.0012692682212218642), (' though', 0.001091914251446724), ('}{', 0.0010270432103425264), (' though', 0.02002984844148159), ('\\n', 0.0032272522803395987), ('ars', 0.0008694824064150453), ('�', 0.0007879757322371006), ('om', 0.0007436436135321856), (' though', 0.007157936692237854), ('\\n', 0.0027980590239167213), ('etic', 0.0022668149322271347), ('ars', 0.0009710297454148531), ('om', 0.0009399526170454919), (' though', 0.008142195641994476), ('\\n', 0.0035853057634085417), ('ars', 0.0010926475515589118), ('�', 0.0009167409152723849), ('etic', 0.000907625537365675)]\n",
            "\n",
            "Layer 14:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.02484600804746151), ('\\n', 0.002888467162847519), (' air', 0.0016259941039606929), ('ars', 0.0011164939496666193), ('ms', 0.0010739669669419527), ('\\n', 0.01052878051996231), (' though', 0.008474444039165974), (' ab', 0.0021702067460864782), ('etic', 0.0019114745082333684), ('put', 0.0012557691661641002), (' though', 0.019451657310128212), ('\\n', 0.003553868969902396), ('span', 0.0016684047877788544), (' air', 0.0010083626257255673), ('put', 0.000954855524469167), (' though', 0.0021237796172499657), (' similar', 0.0014519654214382172), ('\\n', 0.0012733342591673136), (' sc', 0.00113359943497926), ('span', 0.0010226598242297769), ('\\n', 0.0014454382471740246), (' though', 0.001258027390576899), ('ars', 0.001249120570719242), ('18', 0.001156929531134665), ('our', 0.0009442376322112978), ('\\n', 0.020776119083166122), ('etic', 0.00407328549772501), ('ators', 0.003781237406656146), (' though', 0.0032845591194927692), (' cost', 0.0013012905837967992), (' though', 0.004623038694262505), ('\\n', 0.0015381749253720045), ('ety', 0.0012783464044332504), ('type', 0.0010333484970033169), ('ars', 0.00101518037263304), ('ators', 0.003008128609508276), ('\\n', 0.0029066901188343763), ('etic', 0.0020658704452216625), (' though', 0.0018481065053492785), ('span', 0.0010772730456665158), ('etic', 0.013165486045181751), ('\\n', 0.0017900760285556316), ('ators', 0.0012308548903092742), ('18', 0.0011420812224969268), ('ax', 0.000860410975292325), ('etic', 0.01679125428199768), ('\\n', 0.0021986616775393486), (' though', 0.00115926843136549), ('ax', 0.0008297947351820767), ('AC', 0.0008156916592270136), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.003495143260806799), ('raw', 0.0026885797269642353), (' by', 0.0011221123859286308), ('span', 0.0010414415737614036), (' told', 0.0010019257897511125), ('etic', 0.0029114913195371628), ('ators', 0.002590826014056802), (' similar', 0.0013883905485272408), ('}{', 0.0011294306023046374), (' why', 0.0010060983477160335), (' though', 0.02068297751247883), ('\\n', 0.003319954266771674), ('span', 0.0011137071996927261), ('ars', 0.0009181915083900094), ('AC', 0.0008230454986914992), (' though', 0.015901120379567146), ('\\n', 0.0047152284532785416), ('etic', 0.0027612869162112474), ('ators', 0.0009220067295245826), ('ars', 0.0009102803887799382), (' though', 0.015973933041095734), ('\\n', 0.005965333431959152), ('ars', 0.0010677253594622016), ('etic', 0.0009743491536937654), (' health', 0.000947064661886543)]\n",
            "\n",
            "Layer 15:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.04536351561546326), ('\\n', 0.0051435320638120174), ('span', 0.001846219995059073), (' air', 0.0017465766286477447), ('ars', 0.0014373465673997998), ('\\n', 0.017667310312390327), (' though', 0.011995186097919941), (' ab', 0.002511520404368639), ('etic', 0.0025082796346396208), ('span', 0.0014915169449523091), (' though', 0.060751114040613174), ('\\n', 0.010900002904236317), ('span', 0.0055511523969471455), (' air', 0.0011752148857340217), ('put', 0.0009134684223681688), ('\\n', 0.00804845243692398), (' though', 0.005815885495394468), ('span', 0.003301942255347967), (' similar', 0.0018996658036485314), (' ab', 0.001200266880914569), ('\\n', 0.002792441053315997), (' though', 0.0019928745459765196), ('ars', 0.0012055067345499992), ('18', 0.0011927896412089467), (' why', 0.0011186813935637474), ('\\n', 0.13041844964027405), (' though', 0.006081019062548876), ('etic', 0.004605352878570557), ('ators', 0.003763774409890175), ('span', 0.001777374534867704), (' though', 0.014724284410476685), ('\\n', 0.005593480076640844), ('span', 0.0022674808278679848), ('ety', 0.0012201406061649323), (' process', 0.0011624905746430159), ('\\n', 0.007390646729618311), ('ators', 0.0033258988987654448), ('span', 0.0030866647139191628), ('etic', 0.0025946288369596004), (' though', 0.0025424722116440535), ('etic', 0.021951083093881607), ('\\n', 0.009484952315688133), ('18', 0.0016929747071117163), ('span', 0.0012210867134854198), ('ators', 0.0012071396922692657), ('etic', 0.04564566910266876), ('\\n', 0.01662098802626133), (' though', 0.0035252633970230818), ('span', 0.0025020285975188017), (' your', 0.001109061180613935), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.0048636170104146), ('\\n', 0.0035905500408262014), ('raw', 0.0030558437574654818), ('span', 0.0014992468059062958), ('ump', 0.001198133802972734), ('etic', 0.0036671184934675694), ('ators', 0.0029483800753951073), (' similar', 0.0014418803621083498), ('}{', 0.0013804014306515455), ('�', 0.0011257899459451437), (' though', 0.04711708426475525), ('\\n', 0.010777182877063751), ('span', 0.0027504651807248592), ('ars', 0.0008130118949338794), ('o', 0.0008053643978200853), (' though', 0.025187721475958824), ('\\n', 0.013540267013013363), ('etic', 0.002820238471031189), ('span', 0.0016248150495812297), ('ators', 0.0010389330564066768), (' though', 0.027745062485337257), ('\\n', 0.016263052821159363), ('ars', 0.0011414845939725637), ('span', 0.001074490719474852), (' cost', 0.0010218354873359203)]\n",
            "\n",
            "Layer 16:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.08876189589500427), ('\\n', 0.00939283799380064), ('span', 0.0034927218221127987), (' air', 0.0015906690387055278), ('ms', 0.0013765284093096852), ('\\n', 0.07762475311756134), (' though', 0.026225438341498375), ('span', 0.0035484791733324528), (' ab', 0.003152125747874379), ('etic', 0.002541981404647231), (' though', 0.20023252069950104), ('span', 0.03213046118617058), ('\\n', 0.025535646826028824), (' air', 0.0012144449865445495), (' top', 0.000795471656601876), ('\\n', 0.02479042299091816), (' though', 0.016249755397439003), ('span', 0.013900299556553364), (' similar', 0.0016980834770947695), (' ab', 0.0013696362730115652), ('\\n', 0.017194636166095734), (' though', 0.0048014200292527676), ('span', 0.0033727979753166437), (' why', 0.0014163004234433174), ('ok', 0.0013811311218887568), ('\\n', 0.38216403126716614), (' though', 0.005401980597525835), ('etic', 0.004303178749978542), ('span', 0.003756145481020212), ('ators', 0.002836447674781084), (' though', 0.018057871609926224), ('\\n', 0.008815218694508076), ('span', 0.004194732755422592), (' every', 0.001529888017103076), ('ety', 0.0014980260748416185), ('\\n', 0.027895642444491386), ('ators', 0.0035966073628515005), ('span', 0.002951590809971094), ('etic', 0.0026855384930968285), (' though', 0.0021748002618551254), ('\\n', 0.046885255724191666), ('etic', 0.03751960024237633), ('span', 0.002968303393572569), ('18', 0.0020055805798619986), (' though', 0.0013787802308797836), ('etic', 0.06435374170541763), ('\\n', 0.02251812443137169), (' though', 0.003978570457547903), ('span', 0.0028840808663517237), (' your', 0.0012384590227156878), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.004549035802483559), ('raw', 0.0036270625423640013), ('\\n', 0.0021942160092294216), ('span', 0.0019910484552383423), (' by', 0.0012049172073602676), ('ators', 0.0035684374161064625), ('etic', 0.0034504702780395746), (' cost', 0.0012641738867387176), ('}{', 0.001228796667419374), (' why', 0.0012246601982042193), (' though', 0.0533827543258667), ('\\n', 0.011781749315559864), ('span', 0.008166379295289516), (' told', 0.0010084316600114107), ('�', 0.0008968467591330409), (' though', 0.04091113433241844), ('\\n', 0.021051183342933655), ('span', 0.004902422893792391), ('etic', 0.003056228393688798), ('ators', 0.001166315283626318), (' though', 0.035580430179834366), ('\\n', 0.022924644872546196), ('span', 0.0019466805970296264), ('ars', 0.001395245548337698), (' cost', 0.0010231212945654988)]\n",
            "\n",
            "Layer 17:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), (' though', 0.05200883746147156), ('span', 0.013938222080469131), ('\\n', 0.004832240752875805), ('ms', 0.001822176855057478), (' air', 0.0017879146616905928), ('\\n', 0.05085957422852516), (' though', 0.020853180438280106), ('span', 0.011074786074459553), (' ab', 0.004300151020288467), ('etic', 0.0040791695937514305), ('span', 0.18950118124485016), (' though', 0.15612712502479553), ('\\n', 0.010743013583123684), (' air', 0.0012403458822518587), ('ety', 0.0008201606688089669), ('span', 0.05947937071323395), ('\\n', 0.022982275113463402), (' though', 0.017067832872271538), (' similar', 0.0017998113762587309), (' ab', 0.0017910971073433757), ('\\n', 0.01018744707107544), ('span', 0.00807681679725647), (' though', 0.002818679204210639), ('ars', 0.0015448775375261903), (' why', 0.001304365461692214), ('\\n', 0.45346003770828247), ('span', 0.012300657108426094), ('etic', 0.00354622770100832), ('ators', 0.0030640927143394947), (' though', 0.0021271249279379845), (' though', 0.02044440247118473), ('span', 0.015706457197666168), ('\\n', 0.009964652359485626), ('ety', 0.001455568941310048), (' process', 0.0014174001989886165), ('\\n', 0.08525217324495316), ('span', 0.0057561988942325115), ('ators', 0.00445257592946291), ('etic', 0.0026113097555935383), (' though', 0.0016973152523860335), ('\\n', 0.05945383384823799), ('etic', 0.0571499764919281), ('span', 0.008519942872226238), ('18', 0.0018706623231992126), ('ators', 0.0012121377512812614), ('etic', 0.09018246829509735), ('\\n', 0.04973239079117775), ('span', 0.015262472443282604), (' though', 0.004525588825345039), (' turn', 0.0012614933075383306), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('raw', 0.004439774435013533), (' though', 0.0014548794133588672), (' by', 0.0011478390078991652), ('ars', 0.0011276653967797756), (' function', 0.0010544772958382964), ('etic', 0.005659664981067181), ('ators', 0.0051239910535514355), (' why', 0.0014038624940440059), (' init', 0.0013065144885331392), (' There', 0.0012632848229259253), (' though', 0.0229765847325325), ('span', 0.021626446396112442), ('\\n', 0.014236646704375744), (' away', 0.0009488092618994415), ('o', 0.000926893437281251), ('\\n', 0.05535188317298889), (' though', 0.05080260708928108), ('span', 0.02526509389281273), ('etic', 0.0035574224311858416), ('ators', 0.001161779509857297), ('\\n', 0.14361721277236938), (' though', 0.0368351973593235), ('span', 0.005973815452307463), ('ars', 0.0011195676634088159), (' health', 0.00101872393861413)]\n",
            "\n",
            "Layer 18:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.1485733538866043), (' though', 0.07812375575304031), ('\\n', 0.010813875123858452), ('ms', 0.0021228960249572992), (' air', 0.001491402625106275), ('\\n', 0.20836029946804047), ('span', 0.07897163182497025), (' though', 0.02712288685142994), (' ab', 0.004026663023978472), ('etic', 0.00339896441437304), ('span', 0.770042896270752), (' though', 0.06377924978733063), ('\\n', 0.00943693146109581), (' air', 0.0002949924091808498), ('ety', 0.000260568835074082), ('span', 0.27038946747779846), ('\\n', 0.02184896357357502), (' though', 0.012008020654320717), (' ab', 0.0014119113329797983), ('return', 0.0013273423537611961), ('span', 0.03553326427936554), ('\\n', 0.013514806516468525), (' though', 0.0020188004709780216), (' why', 0.0013448212994262576), ('ars', 0.0012129226233810186), ('\\n', 0.8090454339981079), ('span', 0.031516022980213165), ('ators', 0.0011541388230398297), ('etic', 0.0010945709655061364), (' though', 0.0009177977335639298), ('span', 0.07565507292747498), (' though', 0.011757967993617058), ('\\n', 0.0027024371083825827), ('ety', 0.0017142677679657936), (' process', 0.001632406609132886), ('\\n', 0.06465280801057816), ('span', 0.011008170433342457), ('ators', 0.007511342875659466), ('etic', 0.0026832257863134146), ('t', 0.00123993877787143), ('etic', 0.06390213966369629), ('\\n', 0.04209362342953682), ('span', 0.0164578128606081), ('18', 0.0016922731883823872), ('ators', 0.0013492899015545845), ('etic', 0.10656622797250748), ('\\n', 0.0562969446182251), ('span', 0.026977382600307465), (' though', 0.00291854958049953), (' your', 0.0012941735330969095), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('raw', 0.004970483481884003), (' They', 0.0012798861134797335), ('ars', 0.0010805327910929918), (' by', 0.001016892259940505), ('�', 0.0010123501997441053), ('ators', 0.007813878357410431), ('etic', 0.005759998224675655), ('span', 0.001568760839290917), ('�', 0.001424675458110869), (' similar', 0.0014029773883521557), ('span', 0.06078073009848595), ('\\n', 0.04267415776848793), (' though', 0.03984537348151207), (' ear', 0.001182400155812502), ('eral', 0.0010488895932212472), ('\\n', 0.13061439990997314), (' though', 0.08571266382932663), ('span', 0.08444688469171524), ('etic', 0.003148367628455162), ('ators', 0.0009085023193620145), ('\\n', 0.5171456933021545), (' though', 0.022862309589982033), ('span', 0.011286099441349506), (' health', 0.000618254765868187), ('//', 0.0006012569065205753)]\n",
            "\n",
            "Layer 19:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.4444446861743927), (' though', 0.09388881921768188), ('\\n', 0.0049131023697555065), ('ms', 0.0012245363323017955), (' air', 0.0011442953255027533), ('span', 0.1748315542936325), ('\\n', 0.10221211612224579), (' though', 0.028080709278583527), (' ab', 0.00450059212744236), ('etic', 0.0030783251859247684), ('span', 0.9507654309272766), (' though', 0.011936340481042862), ('\\n', 0.0007024701917544007), ('#', 6.109272362664342e-05), (' air', 6.0468966694315895e-05), ('span', 0.3853631317615509), (' though', 0.00550101650878787), ('\\n', 0.0031978862825781107), (' ab', 0.0011547256726771593), (' used', 0.0010787427891045809), ('span', 0.041300784796476364), ('ars', 0.0012887130724266171), (' due', 0.0012798759853467345), (' why', 0.0012627985561266541), (' appro', 0.0012184132356196642), ('\\n', 0.5829142332077026), ('span', 0.10681971907615662), ('etic', 0.002247563563287258), ('ators', 0.002187246223911643), ('ars', 0.001059001311659813), ('span', 0.17187966406345367), (' though', 0.011217258870601654), ('type', 0.0016976931365206838), ('ety', 0.0016634507337585092), (' process', 0.001523624756373465), ('span', 0.026074081659317017), ('\\n', 0.020084258168935776), ('ators', 0.009190945886075497), ('etic', 0.002898121252655983), ('t', 0.001434815232641995), ('etic', 0.08664146810770035), ('span', 0.0379505455493927), ('\\n', 0.01355445571243763), ('18', 0.0014261960750445724), ('ators', 0.0013660936383530498), ('etic', 0.14364667236804962), ('span', 0.044401466846466064), ('\\n', 0.020295897498726845), (' though', 0.0015226888936012983), (' your', 0.0013066736282780766), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('raw', 0.0054259286262094975), ('span', 0.0019480128539726138), (' They', 0.0012972530676051974), (' though', 0.0012763856211677194), ('iple', 0.0012308727018535137), ('ators', 0.007915537804365158), ('etic', 0.006159156560897827), (' process', 0.0014287575613707304), ('span', 0.0014044457348063588), ('rit', 0.0013130535371601582), ('span', 0.09751281887292862), (' though', 0.031065063551068306), ('\\n', 0.01650378480553627), (' ear', 0.0015881910221651196), ('om', 0.0013785730116069317), ('span', 0.22238443791866302), ('\\n', 0.09312301129102707), (' though', 0.0656215250492096), ('etic', 0.0027406823355704546), (' making', 0.0008995938114821911), ('\\n', 0.7256007790565491), ('span', 0.02526574209332466), (' though', 0.01180723961442709), (' health', 0.00038714002585038543), ('//', 0.00035638254485093057)]\n",
            "\n",
            "Layer 20:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.9742493033409119), (' though', 0.009491311386227608), ('\\n', 0.00021765146811958402), ('ms', 3.8976788346190006e-05), ('ou', 3.8530331949004903e-05), ('span', 0.8745131492614746), ('\\n', 0.009645471349358559), (' though', 0.008849270641803741), ('etic', 0.0005900273099541664), (' ab', 0.0005022815894335508), ('span', 0.9987174272537231), (' though', 0.0005566845065914094), ('\\n', 3.422887675696984e-05), ('ety', 1.1355468814144842e-06), ('#', 1.0562941952230176e-06), ('span', 0.9662196636199951), (' though', 0.0011461526155471802), ('\\n', 0.0008804886601865292), (' going', 7.378613372566178e-05), (' used', 5.816896737087518e-05), ('span', 0.7290809750556946), (' though', 0.0010030505945906043), ('\\n', 0.0006633319426327944), ('ars', 0.00039561642915941775), (' why', 0.0003786090819630772), ('span', 0.48909440636634827), ('\\n', 0.3751233220100403), ('etic', 0.0011343271471560001), ('ators', 0.0009540985338389874), (' though', 0.00045606307685375214), ('span', 0.8070429563522339), (' though', 0.00883745402097702), ('\\n', 0.0006477265851572156), ('type', 0.0004977277712896466), (' process', 0.00047863362124189734), ('span', 0.07976367324590683), ('\\n', 0.012299956753849983), ('ators', 0.009037401527166367), ('etic', 0.0030851736664772034), ('this', 0.0016772170783951879), ('span', 0.26956701278686523), ('etic', 0.08859121054410934), ('\\n', 0.011853829026222229), (' across', 0.0010746148182079196), ('\\t', 0.0010343649191781878), ('span', 0.3530257046222687), ('etic', 0.11942368745803833), ('\\n', 0.03144532069563866), (' though', 0.001812442671507597), (' comp', 0.000980535289272666), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.012193559668958187), ('raw', 0.0060317437164485455), (' though', 0.003440017579123378), (' They', 0.0016310473438352346), ('iple', 0.001353748026303947), ('span', 0.06225821375846863), ('ators', 0.009385188110172749), ('\\n', 0.007720521185547113), ('etic', 0.006024104077368975), (' though', 0.002434903522953391), ('span', 0.6252114176750183), (' though', 0.029452579095959663), ('\\n', 0.014788503758609295), ('\\xa0\\xa0', 0.0005907465820200741), (' exist', 0.0005631542881019413), ('span', 0.7144286632537842), ('\\n', 0.0705430880188942), (' though', 0.04477272555232048), ('etic', 0.0008661768515594304), ('na', 0.0003588604158721864), ('\\n', 0.813465416431427), ('span', 0.09036677330732346), (' though', 0.005010945722460747), (' health', 0.00017988526087719947), ('//', 0.00011600947618717328)]\n",
            "\n",
            "Layer 21:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.9994537234306335), (' though', 0.00032847386319190264), ('\\n', 1.4285871657193638e-05), ('ms', 6.396605840564007e-07), ('ou', 5.446646014206635e-07), ('span', 0.9838115572929382), ('\\n', 0.00237572961486876), (' though', 0.0016068830154836178), ('etic', 6.21284416411072e-05), (' ab', 5.057450835010968e-05), ('span', 0.9998937845230103), (' though', 6.251281592994928e-05), ('\\n', 3.7763275031466037e-06), ('ety', 6.96885109618961e-08), ('#', 6.513611339187264e-08), ('span', 0.99552983045578), (' though', 0.00020162004511803389), ('\\n', 0.0001428167161066085), (' used', 8.677183359395713e-06), ('une', 8.586688636569306e-06), ('span', 0.8990294337272644), (' though', 0.0005395868793129921), ('\\n', 0.0003320315445307642), (' appro', 0.0001599324750714004), (' process', 0.00015120198077056557), ('span', 0.7578883767127991), ('\\n', 0.20027515292167664), ('etic', 0.0003729233576450497), ('ators', 0.00026217298000119627), (' though', 0.0001601146359462291), ('span', 0.9682003855705261), (' though', 0.0038997770752757788), ('\\n', 0.000800776993855834), (' process', 7.723472663201392e-05), ('ety', 7.152356556616724e-05), ('span', 0.34150922298431396), ('\\n', 0.0359812006354332), ('ators', 0.007344088517129421), ('etic', 0.0020923535339534283), ('�', 0.0017201738664880395), ('span', 0.5709221363067627), ('etic', 0.06901602447032928), ('\\n', 0.015689440071582794), (' prob', 0.0006888871430419385), ('ad', 0.0006208746926859021), ('span', 0.41853877902030945), ('etic', 0.14103689789772034), ('\\n', 0.031061943620443344), (' though', 0.002079336205497384), (' comp', 0.001145759830251336), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.05836784467101097), ('raw', 0.006532764527946711), (' though', 0.004624530207365751), ('iple', 0.0015868960181251168), (' process', 0.0015263496898114681), ('span', 0.1904744952917099), ('\\n', 0.010042521171271801), ('ators', 0.008716082200407982), ('etic', 0.006401498336344957), (' though', 0.0015098078874871135), ('span', 0.9208722114562988), (' though', 0.007238925434648991), ('\\n', 0.0053549460135400295), (' exist', 0.00011937627277802676), ('om', 0.00011725984222721308), ('span', 0.9731135964393616), ('\\n', 0.01262874435633421), (' though', 0.0037138904444873333), ('etic', 6.368858885252848e-05), ('ators', 2.5704777726787142e-05), ('\\n', 0.8242502808570862), ('span', 0.162573903799057), (' though', 0.0007386396173387766), (' health', 3.22474843414966e-05), ('//', 1.7348169421893544e-05)]\n",
            "\n",
            "Layer 22:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.9997280240058899), (' though', 0.00017188183846883476), ('\\n', 5.102904651721474e-06), ('ety', 3.750091650545073e-07), ('ms', 3.2058497367870586e-07), ('span', 0.9974253177642822), ('\\n', 0.0007475190795958042), (' though', 0.0006798602407798171), ('etic', 7.821920917194802e-06), (' ab', 6.60702562527149e-06), ('span', 0.9999878406524658), (' though', 7.3981732384709176e-06), ('\\n', 2.3574862950681563e-07), ('#', 8.735531409342912e-09), ('ety', 8.424370534498848e-09), ('span', 0.9992642998695374), (' though', 5.994186722091399e-05), ('\\n', 5.8524568885331973e-05), (' ab', 1.6261801647488028e-06), ('une', 1.4695629033667501e-06), ('span', 0.9751611351966858), (' though', 0.0001653079962125048), ('\\n', 0.00011381721560610458), (' process', 4.467738472158089e-05), ('         ', 4.225180600769818e-05), ('span', 0.9475759267807007), ('\\n', 0.05051330849528313), ('etic', 2.3738810341455974e-05), (' though', 1.730155599943828e-05), ('ators', 1.0386019312136341e-05), ('span', 0.9947195053100586), (' though', 0.000848514842800796), ('\\n', 0.0001199723337776959), ('ety', 1.0329115866625216e-05), (' process', 1.0213600035058334e-05), ('span', 0.7985571622848511), ('\\n', 0.033128511160612106), ('ators', 0.002073652343824506), ('etic', 0.0009516880381852388), ('�', 0.0005924603319726884), ('span', 0.9337332248687744), ('\\n', 0.01707126945257187), ('etic', 0.014919954352080822), ('wh', 8.183717000065371e-05), (' prob', 6.54922187095508e-05), ('span', 0.7760878205299377), ('etic', 0.09837515652179718), ('\\n', 0.03580491617321968), (' though', 0.002218247391283512), (' comp', 0.000272980920271948), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.10980982333421707), ('raw', 0.009590967558324337), (' though', 0.007885579951107502), ('iple', 0.002515822649002075), ('�', 0.0019024232169613242), ('span', 0.5479910969734192), ('\\n', 0.005809383932501078), ('ators', 0.004727448336780071), ('etic', 0.0030123358592391014), (' though', 0.0010487716645002365), ('span', 0.9899563789367676), (' though', 0.001109501114115119), ('\\n', 0.0004050044808536768), (' ear', 1.7951204426935874e-05), ('om', 1.63884451467311e-05), ('span', 0.9917647242546082), ('\\n', 0.00438332837074995), (' though', 0.0014874222688376904), ('etic', 1.49288334796438e-05), ('ators', 5.653111657011323e-06), ('\\n', 0.6540479063987732), ('span', 0.3372917175292969), (' though', 0.00037298290408216417), (' health', 2.4158794985851273e-05), ('AC', 1.5283681932487525e-05)]\n",
            "\n",
            "Layer 23:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.9999971389770508), (' though', 1.5619024225088651e-06), ('\\n', 8.035404874817687e-08), ('ety', 5.6133702130978236e-09), ('ms', 5.471624930919461e-09), ('span', 0.9994840621948242), ('\\n', 0.00012234751193318516), (' though', 0.00011256130528636277), ('etic', 2.3154125301516615e-06), (' ab', 1.4877163039273e-06), ('span', 0.9999997615814209), (' though', 1.1977168412613537e-07), ('\\n', 5.904731370520722e-09), ('ety', 2.3438070928527566e-10), (' hand', 2.2988068393292593e-10), ('span', 0.9999364614486694), ('\\n', 6.759390544175403e-06), (' though', 3.7689833334297873e-06), ('une', 1.5482908111152938e-07), (' ab', 1.210500499837508e-07), ('span', 0.9996458292007446), (' though', 4.220844857627526e-06), ('\\n', 3.81036511498678e-06), (' process', 6.796692559873918e-07), ('une', 6.730757036166324e-07), ('span', 0.9872744083404541), ('\\n', 0.011856764554977417), ('etic', 1.0881191883527208e-05), ('amma', 4.818742581846891e-06), (' though', 4.650724349630764e-06), ('span', 0.9996426105499268), (' though', 0.00010814557754201815), ('\\n', 1.4520976947096642e-05), ('inal', 7.502064249820251e-07), (' Con', 7.130508947739145e-07), ('span', 0.9262077212333679), ('\\n', 0.01708022877573967), ('ators', 0.000745336408726871), ('etic', 0.0003453719837125391), ('!', 0.00018246119725517929), ('span', 0.9850243330001831), ('\\n', 0.0047794971615076065), ('etic', 0.0027514994144439697), ('AA', 2.3200493160402402e-05), ('wh', 1.8766842913464643e-05), ('span', 0.762270450592041), ('etic', 0.11463235318660736), ('\\n', 0.02256958745419979), (' though', 0.002896240446716547), (' comp', 0.0003170364652760327), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.6993468403816223), (' though', 0.008856352418661118), ('raw', 0.002429085550829768), ('iple', 0.0009040157310664654), ('\\n', 0.0006867367774248123), ('span', 0.8009351491928101), ('\\n', 0.002597811631858349), ('ators', 0.0021810398902744055), ('etic', 0.0009564204374328256), ('ves', 0.00045089219929650426), ('span', 0.9997895359992981), (' though', 5.5806471209507436e-05), ('\\n', 1.4900973837939091e-05), (' exist', 3.3926508535842004e-07), (' ear', 3.250598865633947e-07), ('span', 0.9994736313819885), ('\\n', 0.00038395231240428984), (' though', 5.8218545746058226e-05), ('etic', 4.081107647380122e-07), ('ators', 2.873088646992983e-07), ('span', 0.701547384262085), ('\\n', 0.2949341833591461), (' though', 0.00012326754222158343), (' health', 1.2573778803925961e-05), ('//', 7.919927156763151e-06)]\n",
            "\n",
            "Layer 24:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), (' though', 3.311403773409438e-08), ('\\n', 1.4463409359066759e-09), ('ms', 1.0727643079411209e-10), ('ety', 8.670095891227803e-11), ('span', 0.9999942779541016), ('\\n', 4.203384378342889e-06), (' though', 4.436037670529913e-07), ('etic', 1.2139735439120614e-08), (' ab', 4.406442322135717e-09), ('span', 1.0), (' though', 9.73352731747923e-10), ('\\n', 9.314597010368075e-11), (' hand', 1.3412086111858068e-12), ('ety', 9.80620424272105e-13), ('span', 0.9999997615814209), ('\\n', 1.453169318210712e-07), (' though', 8.944946117139807e-09), ('une', 3.4741712284791504e-10), ('ploy', 2.1879585643258537e-10), ('span', 0.999996542930603), ('\\n', 9.141304246895743e-08), (' though', 6.458509460571804e-08), ('une', 1.0249257442751514e-08), (' process', 7.87612908226265e-09), ('span', 0.999357283115387), ('\\n', 0.0006334923091344535), ('etic', 1.4703115880365658e-07), (' though', 8.182929889244406e-08), ('amma', 4.946452492049502e-08), ('span', 0.999998927116394), (' though', 3.4624974887265125e-07), ('\\n', 2.776287431061064e-07), ('inal', 1.6896072319028121e-09), ('ety', 1.5499858063705574e-09), ('span', 0.9938562512397766), ('\\n', 0.003311468753963709), ('ators', 3.990323602920398e-05), ('etic', 1.803805207600817e-05), ('this', 1.3500964087143075e-05), ('span', 0.9996657371520996), ('\\n', 0.0002846351417247206), ('etic', 1.4109427866060287e-05), ('AA', 1.1409796485395418e-07), ('----------------------------------------------------------------', 8.48654764240564e-08), ('span', 0.9582238793373108), ('etic', 0.022669922560453415), ('\\n', 0.0071282759308815), (' though', 0.0009178424952551723), (' process', 3.2481635571457446e-05), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.9776906371116638), (' though', 0.0013454108266159892), ('\\n', 0.00014812454173807055), ('raw', 0.0001244593586307019), ('.\"', 6.228812708286569e-05), ('span', 0.9822721481323242), ('\\n', 0.0006213759770616889), ('ators', 0.00018801033729687333), ('etic', 9.202738874591887e-05), ('ves', 5.629331644740887e-05), ('span', 0.9999947547912598), (' though', 2.096443495247513e-06), ('\\n', 1.0598290600682958e-06), ('bar', 5.467584607288245e-09), (' ear', 5.323354201891561e-09), ('span', 0.9999833106994629), ('\\n', 1.5012305993877817e-05), (' though', 9.819968909141608e-07), ('etic', 4.686602661507777e-09), ('ators', 2.494430217936383e-09), ('span', 0.9363448023796082), ('\\n', 0.06284742057323456), (' though', 2.394646617176477e-05), (' health', 2.664692374310107e-06), ('}{', 2.1430566903291037e-06)]\n",
            "\n",
            "Layer 25:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), (' though', 1.5324059798871303e-09), ('\\n', 2.767262634317813e-11), ('ms', 4.825006279934874e-12), (' human', 4.261465746252524e-12), ('span', 0.9999997615814209), ('\\n', 1.8073673402341228e-07), (' though', 4.636650885458948e-08), ('etic', 4.715019485956873e-10), (' ab', 1.9792249783545657e-10), ('span', 1.0), (' though', 3.263170983425212e-11), ('\\n', 1.6596563533199937e-12), ('ething', 2.8637780758985e-14), ('ety', 2.5252898188353468e-14), ('span', 1.0), ('\\n', 4.345107829095696e-09), (' though', 7.337979668342598e-10), (' ab', 2.0327795002827997e-11), ('une', 1.748943004309389e-11), ('span', 0.9999995231628418), (' though', 1.4111101620528643e-08), ('\\n', 9.83861259129526e-09), ('une', 1.4637465683975392e-09), (' happ', 1.301721619384466e-09), ('span', 0.9994311928749084), ('\\n', 0.0005490820622071624), ('etic', 2.5863670316539356e-07), (' though', 2.550860074279626e-07), ('amma', 1.2177048347439268e-07), ('span', 0.9999998807907104), (' though', 5.0784752403387756e-08), ('\\n', 2.394714293529887e-08), (' week', 3.7968425625756197e-10), (' Con', 3.211631793842429e-10), ('span', 0.9978868365287781), ('\\n', 0.001454948796890676), ('ators', 1.216794134961674e-05), ('etic', 4.0863242247723974e-06), ('this', 3.5170155570085626e-06), ('span', 0.9999039173126221), ('\\n', 9.006042091641575e-05), ('etic', 1.9065007563767722e-06), ('AA', 1.4640149537115121e-08), ('ck', 9.692765701174721e-09), ('span', 0.9110965132713318), ('etic', 0.05048368498682976), ('\\n', 0.017023315653204918), (' though', 0.001633295789361), (' discuss', 8.339301712112501e-05), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.9974713325500488), (' though', 0.00036557449493557215), ('\\n', 2.512629725970328e-05), ('raw', 1.3316596778167877e-05), (' method', 1.1557958714547567e-05), ('span', 0.9210078716278076), ('\\n', 0.0007580419187434018), ('ators', 0.0006499120499938726), ('etic', 0.00044646766036748886), (' though', 0.0002854320628102869), ('span', 0.9999985694885254), (' though', 6.078963110667246e-07), ('\\n', 2.284401290353344e-07), ('bar', 2.128895948416698e-09), ('ators', 2.12403272747963e-09), ('span', 0.9999947547912598), ('\\n', 4.607280516211176e-06), (' though', 4.849498509429395e-07), ('etic', 1.3687367905745873e-09), (' exp', 6.837130861470087e-10), ('span', 0.9653868079185486), ('\\n', 0.033342186361551285), (' though', 2.2974467356107198e-05), (' health', 4.713103862741264e-06), ('AC', 3.957436092605349e-06)]\n",
            "\n",
            "Layer 26:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), (' though', 1.5563976496490994e-10), ('\\n', 7.341347148248634e-12), ('ms', 4.463344028138999e-13), (' human', 4.381559134611357e-13), ('span', 1.0), ('\\n', 2.485127126305997e-08), (' though', 6.82898237958085e-10), ('etic', 5.093657266808105e-12), ('urs', 2.738059562065742e-12), ('span', 1.0), (' though', 1.3242808542465734e-13), ('\\n', 4.7477331717752855e-14), ('ething', 1.2154676624148914e-16), ('ety', 1.0411288927563982e-16), ('span', 1.0), ('\\n', 7.886325620320989e-11), (' though', 1.291048431356634e-12), ('une', 3.122447030210092e-14), (' ab', 2.4295344382141426e-14), ('span', 1.0), ('\\n', 1.1026060064978083e-09), (' though', 4.683846088759935e-10), ('une', 6.334339303082359e-11), (' Cal', 4.011273604942467e-11), ('span', 0.9998831748962402), ('\\n', 0.0001139280793722719), ('etic', 4.62664075939756e-08), (' though', 3.021018102344897e-08), ('amma', 2.5223503286042614e-08), ('span', 1.0), (' though', 4.310439116750331e-09), ('\\n', 3.6737448638746173e-09), (' disc', 4.0986516264274186e-11), (')\\\\', 3.441786439184469e-11), ('span', 0.9996820688247681), ('\\n', 0.00029029202414676547), ('ators', 6.799881475672009e-07), ('etic', 2.0565269664984953e-07), ('this', 1.5197119296317396e-07), ('span', 0.9999966621398926), ('\\n', 3.383560397196561e-06), ('etic', 1.6520700363287233e-09), ('AA', 1.0003802473901313e-11), ('clude', 8.278540179762484e-12), ('span', 0.9932016730308533), ('\\n', 0.004329184535890818), ('etic', 0.001887385151349008), (' though', 6.241502705961466e-05), (' process', 4.038721726828953e-06), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.9998607635498047), (' though', 2.2688765966449864e-05), ('\\n', 1.4990645240686717e-06), ('raw', 8.148220445036713e-07), (' cal', 7.246935638249852e-07), ('span', 0.8312838077545166), ('ators', 0.00144590949639678), ('etic', 0.0009016695548780262), ('\\n', 0.0008465148275718093), (' though', 0.0005463478155434132), ('span', 0.9999992847442627), (' though', 3.4020496286757407e-07), ('\\n', 1.0612847489710475e-07), (' int', 1.6524430712649973e-09), ('bar', 1.4840626505474575e-09), ('span', 0.9999996423721313), ('\\n', 2.9295196668499557e-07), (' though', 6.891186732360666e-09), ('etic', 1.4373379222942795e-11), (' dis', 1.4084730777519372e-11), ('span', 0.5758792757987976), ('\\n', 0.2019541710615158), (' though', 0.001601658994331956), (' short', 0.0010847366647794843), ('\\x0b', 0.0009303140686824918)]\n",
            "\n",
            "Layer 27:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), (' though', 6.563426017958118e-13), ('\\n', 1.8322655878969495e-14), (' human', 2.103516327255409e-15), ('ms', 1.9520880121100216e-15), ('span', 1.0), ('\\n', 9.374000881079425e-11), (' though', 2.992425317954739e-12), ('etic', 1.8649502176392406e-14), ('ru', 1.606770848371162e-14), ('span', 1.0), ('\\n', 3.806676907162908e-17), (' though', 3.4815098922625975e-17), ('ething', 5.155448404176494e-20), ('�', 4.6631240745168566e-20), ('span', 1.0), ('\\n', 4.2392912097399815e-13), (' though', 5.665796184403963e-15), (' ab', 1.4004309383843628e-16), ('une', 1.3773105123445666e-16), ('span', 1.0), ('\\n', 1.0517924725617078e-10), (' though', 9.261645617097969e-11), ('une', 1.679675495913635e-11), ('ide', 1.0127995664355183e-11), ('span', 0.9999860525131226), ('\\n', 1.3227442650531884e-05), ('etic', 1.7821234266079955e-08), (' though', 1.0089847179983735e-08), ('amma', 8.231450188134204e-09), ('span', 1.0), (' though', 9.724248073439412e-10), ('\\n', 2.2282931055883637e-10), (' disc', 1.0806497190152253e-11), (')\\\\', 6.621168023579482e-12), ('span', 0.9999650716781616), ('\\n', 3.1344894523499534e-05), ('ators', 7.654988820604558e-08), (' |', 2.746342886439379e-08), ('this', 2.1786984660820963e-08), ('span', 0.9999997615814209), ('\\n', 2.1505921665720962e-07), ('etic', 1.120103246265991e-10), ('AA', 7.067643996092055e-13), ('velop', 5.134778236284832e-13), ('span', 0.9992522597312927), ('\\n', 0.0004481503274291754), ('etic', 0.0002158975403290242), (' though', 7.678732799831778e-06), (' discuss', 5.581190976045036e-07), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.9999470710754395), (' though', 9.390169907419477e-06), ('\\n', 3.789670017795288e-07), ('.\"', 2.9078637453494594e-07), ('raw', 2.460270422943722e-07), ('span', 0.859463095664978), ('ators', 0.001104364637285471), ('etic', 0.0009151824633590877), (' Co', 0.000672159600071609), (' let', 0.00040577276377007365), ('span', 0.9999997615814209), (' though', 7.568694826431965e-08), ('\\n', 1.1542328870461915e-08), (' int', 7.958678716057932e-10), (' ear', 6.368892080388378e-10), ('span', 1.0), ('\\n', 2.0416381474319678e-08), (' though', 1.0510750048098316e-09), (' dis', 2.6392904788757887e-12), ('etic', 2.3516282237484587e-12), ('span', 0.2248987853527069), ('\\n', 0.15104542672634125), ('AC', 0.005067686550319195), ('..', 0.005008648615330458), (' {\\\\', 0.004786492791026831)]\n",
            "\n",
            "Layer 28:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), (' though', 1.0144809715379819e-16), ('\\n', 5.947331989560723e-17), (' human', 4.194518890428236e-19), ('ou', 3.3676789728900035e-19), ('span', 1.0), ('\\n', 1.4343231463653794e-11), (' though', 1.6265523541773852e-13), ('etic', 1.0925019306982941e-15), ('ru', 9.846166147559347e-16), ('span', 1.0), ('\\n', 1.3010487074396229e-18), (' though', 2.453894359660264e-19), ('ething', 4.39108505056348e-22), ('�', 3.7460495180178524e-22), ('span', 1.0), ('\\n', 1.3376466275784316e-13), (' though', 1.5783544176500852e-15), (' \\n', 3.5065010038012946e-17), ('une', 3.4263180856873443e-17), ('span', 1.0), (' though', 8.814725858952155e-12), ('\\n', 8.718979531419091e-12), ('une', 1.3077852602932927e-12), (' happ', 8.627197263869069e-13), ('span', 0.9999996423721313), ('\\n', 3.7299955124581174e-07), ('etic', 9.25449022970426e-11), ('amma', 6.734538621211428e-11), (' though', 5.75554499893105e-11), ('span', 1.0), (' though', 2.14333498865793e-12), ('\\n', 1.9390140534869538e-12), (')\\\\', 1.2637816276328886e-14), ('\\n\\t\\t', 1.0412530280817962e-14), ('span', 0.9999661445617676), ('\\n', 3.078838926739991e-05), ('ators', 5.990933971133927e-08), (' |', 2.483640493267103e-08), ('this', 2.0258783095528088e-08), ('span', 1.0), ('\\n', 1.765576840284666e-08), ('etic', 5.782834280876337e-12), ('AA', 4.7996681499032356e-14), (' |', 3.555264264411273e-14), ('span', 0.9998749494552612), ('\\n', 8.743781654629856e-05), ('etic', 2.8413582185748965e-05), (' though', 7.675157576159108e-07), (' process', 5.727231311425385e-08), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 0.9999991655349731), (' though', 1.252667658491191e-07), ('.\"', 6.099663885095197e-09), ('\\n', 5.71366776114246e-09), ('raw', 4.957497079516315e-09), ('span', 0.972153902053833), ('etic', 0.00021809284226037562), ('ators', 0.00016470803529955447), (' Co', 0.00013237513485364616), ('\\n', 0.00012635011808015406), ('span', 1.0), (' though', 8.970011400322164e-09), ('\\n', 1.2722254361108298e-09), (' ear', 2.729198533835131e-10), (' int', 1.3792759989694758e-10), ('span', 1.0), ('\\n', 9.771385478529737e-09), (' though', 6.326506540865751e-10), ('ators', 1.886903177109045e-12), ('{', 1.6625107323794963e-12), ('\\n', 0.08623594790697098), ('span', 0.057917699217796326), (' {\\\\', 0.021935727447271347), ('AC', 0.01208536233752966), ('99', 0.0055546024814248085)]\n",
            "\n",
            "Layer 29:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), ('\\n', 1.0283900218098671e-18), (' though', 8.508530741182234e-19), (' human', 1.1777591431986075e-20), ('ms', 7.160577022064081e-21), ('span', 1.0), ('\\n', 7.42117820104124e-14), (' though', 7.498798563910082e-17), ('ru', 1.0831882558496676e-18), ('ok', 1.0539349100891532e-18), ('span', 1.0), ('\\n', 1.0306044877072482e-19), (' though', 5.939271504817245e-21), ('�', 1.7271527340466e-23), ('aking', 1.461410265310065e-23), ('span', 1.0), ('\\n', 5.810717486569425e-16), (' though', 1.1989388442890864e-18), (' ab', 2.6422009921321948e-20), ('une', 2.4969902433920778e-20), ('span', 1.0), ('\\n', 9.454645454130134e-14), (' though', 3.405779889879834e-14), ('ide', 5.929012096279711e-15), ('une', 5.782483443217716e-15), ('span', 1.0), ('\\n', 3.646629886944197e-09), ('etic', 6.677908009553035e-13), ('amma', 5.795518687352896e-13), (' though', 2.4208624471375173e-13), ('span', 1.0), (' though', 1.494168490648838e-14), ('\\n', 1.1811777887705231e-14), (')\\\\', 2.2802714569192923e-16), ('\\n\\t\\t', 1.6680596007477295e-16), ('span', 0.9999997615814209), ('\\n', 2.508900536213332e-07), ('ators', 9.810890294614794e-11), ('�', 4.690073329705058e-11), (' li', 3.5433538048135205e-11), ('span', 1.0), ('\\n', 2.458693804108236e-10), ('etic', 8.084396189598705e-14), ('AA', 4.86824086681851e-16), ('�', 4.2487638502396695e-16), ('span', 0.9999935626983643), ('\\n', 4.485178578761406e-06), ('etic', 1.5729104916317738e-06), (' though', 2.4735395953712214e-08), (' process', 8.03897393097941e-09), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), (' though', 7.410786651007584e-09), ('new', 4.9827619807985e-10), ('raw', 4.2075268269492483e-10), (' method', 3.5252362140525406e-10), ('span', 0.9996472597122192), ('etic', 2.121484612871427e-06), (' Co', 2.0357765606604517e-06), ('�', 1.649801674830087e-06), ('}{', 1.5576391660943045e-06), ('span', 1.0), (' though', 1.2560630313629417e-10), (' ear', 1.1261051986732884e-11), ('\\n', 1.1232521857085231e-11), (' int', 7.160063774519498e-12), ('span', 1.0), ('\\n', 4.657207258729201e-11), (' though', 8.313359224111638e-13), ('{', 6.56740134686749e-15), ('S', 6.45742470657836e-15), ('span', 0.9877257943153381), ('\\n', 0.0021430288907140493), (' {\\\\', 0.00021451064094435424), (' keep', 0.00010195927461609244), (' Ad', 7.846297376090661e-05)]\n",
            "\n",
            "Layer 30:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), (' though', 5.396039822620259e-22), ('\\n', 5.314733885494174e-22), (' human', 1.7569499037029702e-23), ('ms', 1.5557047025773052e-23), ('span', 1.0), ('\\n', 3.5479730471529554e-15), (' though', 4.213848622758255e-17), ('ru', 2.9384077520425336e-18), ('etic', 1.9056431855631798e-18), ('span', 1.0), ('\\n', 3.7186703648081657e-22), (' though', 1.4382209101401882e-23), ('�', 1.3582081980555344e-25), ('aking', 1.294573500540717e-25), ('span', 1.0), ('\\n', 4.8054319841161745e-17), (' though', 6.834267550538152e-19), ('31', 4.3337446320073623e-20), ('�', 2.743914157555527e-20), ('span', 1.0), ('\\n', 1.3643308573935275e-17), (' though', 5.265384274801183e-18), ('ide', 3.3629306976800077e-18), ('ine', 1.783186540500217e-18), ('span', 1.0), ('\\n', 1.2540849435305201e-11), ('etic', 2.213074321510359e-14), ('amma', 1.5213646857061003e-14), ('ok', 9.90036842112886e-15), ('span', 1.0), (' though', 1.0432121305855007e-16), ('\\n', 1.2641943576713281e-17), ('Re', 3.12976895572147e-18), ('�', 2.1045164299750164e-18), ('span', 1.0), ('\\n', 8.909564641612633e-09), ('ators', 5.4394294624060535e-11), ('�', 1.8248012476074216e-11), (' comm', 1.67825042057812e-11), ('span', 1.0), ('\\n', 3.1596020938495784e-11), ('etic', 5.991863363981331e-13), ('�', 4.5175460391282986e-15), ('о', 4.1404601000213665e-15), ('span', 0.9999986886978149), ('etic', 7.574157052658848e-07), ('\\n', 3.648576694104122e-07), (' though', 6.385808326569986e-09), (' process', 5.566254568378781e-09), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), (' though', 7.773590663317717e-14), ('new', 1.9365578747803508e-14), ('.\"', 1.8166341030751397e-14), (' inf', 1.6036358100267843e-14), ('span', 0.9999997615814209), (' Co', 2.051500747057844e-09), ('}{', 1.5076958570503507e-09), ('�', 1.472682975567352e-09), ('�', 1.3974285062445801e-09), ('span', 1.0), (' though', 1.875587596204039e-14), (' ear', 6.018108950902549e-15), ('\\n', 2.8781069934540222e-15), (' int', 2.8156427605169907e-15), ('span', 1.0), ('\\n', 8.375729444861854e-14), (' though', 1.972915747601705e-14), (' making', 4.3275582960646127e-16), ('S', 4.1624866624191226e-16), ('span', 0.9993176460266113), (' {\\\\', 3.1505496735917404e-05), ('\\n', 3.0240977139328606e-05), (' keep', 8.468655323667917e-06), (' exc', 7.912315595604014e-06)]\n",
            "\n",
            "Layer 31:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), ('\\n', 2.6446635803244285e-26), (' though', 4.723095706611842e-28), ('�', 1.63456382719129e-28), ('ou', 1.5228198069998628e-28), ('span', 1.0), ('\\n', 8.954115747317445e-20), ('ok', 2.575769190194943e-22), (' though', 1.196930321120682e-22), ('ru', 6.165360706327819e-23), ('span', 1.0), ('\\n', 5.605249313155153e-26), (' though', 4.879031031971585e-28), (' prob', 2.0279241849764458e-29), ('aking', 2.0113753310027446e-29), ('span', 1.0), ('\\n', 4.728593319737155e-21), (' though', 1.4240649589681782e-23), ('31', 4.340088664028924e-24), (' take', 2.649149536469581e-24), ('span', 1.0), ('ide', 1.9615331299904883e-20), ('ok', 1.96131631819712e-20), (' happ', 1.2554362494787385e-20), (' process', 1.1676713363552252e-20), ('span', 1.0), ('\\n', 6.364782383796552e-16), ('ok', 2.3231258315710925e-17), ('amma', 1.487143520992133e-17), ('etic', 4.794772272998326e-18), ('span', 1.0), (' though', 1.5359293177863488e-20), ('Re', 3.2084730471217638e-21), ('�', 2.8327749234319595e-21), (' Con', 2.2425853933948172e-21), ('span', 1.0), ('\\n', 8.436869909297928e-13), ('ok', 9.407122162404663e-14), (' comm', 8.045662389360303e-14), ('J', 5.252355421794287e-14), ('span', 1.0), ('\\n', 2.6127390355570976e-16), ('etic', 2.4076557492401314e-17), ('ok', 3.3653431699365186e-18), ('ful', 1.448868984830146e-18), ('span', 1.0), ('etic', 3.943379303650296e-11), ('ok', 2.1110769382604033e-11), ('\\n', 1.8324176811329584e-12), (' process', 1.289584107902475e-12), ('\\n', 1.0), ('!', 0.0), ('<|endoftext|>', 0.0), ('\"', 0.0), ('<|padding|>', 0.0), ('span', 1.0), (' method', 2.141078267999197e-17), ('.\"', 1.6357705062750486e-17), ('new', 1.496156811818756e-17), (' inf', 1.399607794413199e-17), ('span', 1.0), ('ok', 7.270858719786444e-13), (' Co', 4.207159252055115e-13), ('�', 3.3120777171227744e-13), ('AC', 3.227156497760675e-13), ('span', 1.0), (' ear', 1.6535884729778083e-17), (' though', 1.0234984478985042e-17), (' int', 8.426716374746145e-18), ('bar', 6.286497795557574e-18), ('span', 1.0), ('\\n', 2.4807185344556513e-19), (' though', 9.60789749305305e-21), ('ok', 7.407095423856923e-21), ('les', 2.295863014205978e-21), ('span', 0.9999992847442627), ('\\n', 4.261251973503022e-08), (' {\\\\', 3.904203538240836e-08), (' keep', 9.042065762798757e-09), ('he', 8.04113664543138e-09)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2. Rotary embeddings\n",
        "\n",
        "**Task 2.1**\n",
        "\n",
        "In this task we'll need to code rotary embeddings. Actually, they are not just embeddings, but rather a transformation that is applied to queries and keys. It works like that:\n",
        "\n",
        "$$f_q(x_m, m) = x_mW_QR^d_{\\Theta, m},\\quad f_k(x_n, n) = x_nW_KR^d_{\\Theta, n},$$\n",
        "where\n",
        "$$R^d_{\\Theta, m} =\n",
        "\\begin{pmatrix}\n",
        "\\cos{m\\theta_1} & \\sin{m\\theta_1} & 0 & 0 & \\dots & 0 & 0\\\\\n",
        "-\\sin{m\\theta_1} & \\cos{m\\theta_1} & 0 & 0 & \\dots & 0 & 0\\\\\n",
        "0 & 0 & \\cos{m\\theta_2} & \\sin{m\\theta_2} & \\dots & 0 & 0\\\\\n",
        "0 & 0 & -\\sin{m\\theta_2} & \\cos{m\\theta_2} & \\dots & 0 & 0\\\\\n",
        "\\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\n",
        "0 & 0 & 0 & 0 & \\dots & \\cos{m\\theta_{d/2}} & \\sin{m\\theta_{d/2}}\\\\\n",
        "0 & 0 & 0 & 0 & \\dots & -\\sin{m\\theta_{d/2}} & \\cos{m\\theta_{d/2}}\\\\\n",
        "\\end{pmatrix},$$\n",
        "where the parameters $\\Theta$ are set to\n",
        "$$\\theta_i = b^{-2(i-1)/d}$$\n",
        "for some base $b$ (default $10000$).\n",
        "\n",
        "As we see, the transformation is the same for both keys and values, so we just need one transformation that takes a tensor of size `[batch_size, num_heads, seq_len, head_size]` and \"rotates\" it outputting a tensor of the same size."
      ],
      "metadata": {
        "id": "tPKjwA9KT60j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please try our best to make calculations efficient and don't forget to use `torch` (and not `numpy`) and load all the tensors to the right `device`.\n",
        "\n",
        "Hints:\n",
        "1. As we've discussed in the longread, rotary embeddings can be $f_{q,k}(x_m, m) = x_mW_{Q,K}R^d_{\\Theta, m}$ of $f_{q,k}(x_m, m) = \\left(R^d_{\\Theta, m}\\right)^TW_{Q,K}x_m$ depending on whether $x_m$ is a row vector (first formula) or a column vector (second formula). In our case the input dimension is `[batch_size, num_heads, seq_len, head_size]`, so after we choose a particular batch element and a particular attention head, $x_m$ has dimension `(1, head_size)` which is a row.\n",
        "2. Recalculating all the $\\theta_i = b^{-2(i-1)/d}$, sines and cosines takes much time. A good ideas it to cache them as soon as they are needed. we can either calculate $R^d_{\\Theta, m}$ for large sequence length right at the initialization or:\n",
        "  - At initialization cache $R^d_{\\Theta, m}$ for moderately short sequences;\n",
        "  - When we encounter a longer sequence, recalculate and cache again.\n",
        "3. We don't need to store all the matrix $R^d_{\\Theta, m}$ because it has too many zeros. Actually, we can just store sines and cosines and do $x \\mapsto xR^d_{\\Theta, m}$ in linear time:\n",
        "$$xR^d_{\\Theta, m} = \\begin{pmatrix}\n",
        "x_1\\cos{m\\theta_1} - x_2\\sin{m\\theta_1}\\\\\n",
        "x_1\\sin{m\\theta_1} + x_2\\cos{m\\theta_1}\\\\\n",
        "x_3\\cos{m\\theta_2} - x_4\\sin{m\\theta_2}\\\\\n",
        "x_3\\sin{m\\theta_2} + x_4\\cos{m\\theta_2}\\\\\n",
        "\\vdots\n",
        "\\end{pmatrix} =\n",
        "\\begin{pmatrix}x_1\\\\x_2\\\\x_3\\\\x_4\\\\\\vdots\\end{pmatrix}\\otimes\n",
        "\\begin{pmatrix}\\cos{m\\theta_1}\\\\\\cos{m\\theta_1}\\\\\\cos{m\\theta_2}\\\\\\cos{m\\theta_2}\\\\\\vdots\\end{pmatrix} +\n",
        "\\begin{pmatrix}-x_2\\\\x_1\\\\-x_4\\\\x_2\\\\\\vdots\\end{pmatrix}\\otimes\n",
        "\\begin{pmatrix}\\sin{m\\theta_1}\\\\\\sin{m\\theta_1}\\\\\\sin{m\\theta_2}\\\\\\sin{m\\theta_2}\\\\\\vdots\\end{pmatrix}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "RmHUFdyDY8Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from typing import Optional\n",
        "\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        max_position_embeddings: int,\n",
        "        base: int = 10_000,\n",
        "        device: Optional[torch.device] = None,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.base = base\n",
        "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.pe = self.generate_positional_embeddings().to(self.device)\n",
        "\n",
        "    def generate_positional_embeddings(self):\n",
        "        position = torch.arange(0, self.max_position_embeddings).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, self.dim, 2) * -(math.log(10000.0) / self.dim))\n",
        "        pe = torch.zeros(self.max_position_embeddings, self.dim)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).unsqueeze(1)\n",
        "        return pe\n",
        "\n",
        "    def forward(self, x: torch.Tensor, seq_len: Optional[int] = None):\n",
        "        pe = self.pe[:, :, :x.size(2), :x.size(-1)].to(x.device)  # Move pe to the same device as x\n",
        "        x = x + pe\n",
        "        return x\n",
        "\n",
        "# Initialize the RotaryEmbedding\n",
        "rotary_embedding = RotaryEmbedding(dim=768, max_position_embeddings=512, device=torch.device('cuda'))\n",
        "\n",
        "# Load the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('stabilityai/stablelm-zephyr-3b')\n",
        "model = AutoModelForCausalLM.from_pretrained('stabilityai/stablelm-zephyr-3b')\n",
        "\n",
        "# Prepare the inputs\n",
        "prompt = [{'role': 'user', 'content': 'List 3 synonyms for the word \"tiny\"'}]\n",
        "inputs = tokenizer(prompt[0]['content'], return_tensors='pt')\n",
        "\n",
        "# Reshape inputs['input_ids'] to have the expected dimensions\n",
        "inputs_reshaped = inputs['input_ids'].unsqueeze(1).unsqueeze(-1).expand(-1, model.config.num_attention_heads, -1, model.config.hidden_size // model.config.num_attention_heads)\n",
        "\n",
        "# Apply the rotary embedding\n",
        "inputs_embedded = rotary_embedding(inputs_reshaped)\n",
        "\n",
        "# Reshape inputs_embedded to merge the num_heads dimension with the head_size dimension\n",
        "inputs_embedded = inputs_embedded.reshape(inputs_embedded.shape[0], inputs_embedded.shape[2], -1)\n",
        "\n",
        "# Now we can pass inputs_embedded to the model.generate method\n",
        "tokens = model.generate(\n",
        "    inputs_embeds=inputs_embedded.to(model.device),\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(tokens[0], skip_special_tokens=False))"
      ],
      "metadata": {
        "id": "_VyBg2gQWZAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1a6d1e-8434-4c27-f4fe-3dafa6ea4ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "charts), table-defishive partahi, fractional-light-like-intersebs-to-nisse-tra-part-like-a-nnd-mi-ve-table-32-part-les-20ext-that-none-form-at-the-feat-to-ha-nd-d-d-aten-ha-ot-od-a-hasard-that-a-wrapper-pi L2/4) Slient-L2) Nisse-fe/ (5/had) to-table-2-times-had-there-with-the-form-laze-had-had-to-had-to-use-the-neat-to-battake *ard) Wickie *wort) highly &there &ve ve boll-to-sander-whichard-dyiedole-shern-it-else, tra-deep-noge-wlatop-that,shere-s-1nest-bath-to-the-game-for-heavy-cath-at-ha-nd-there-veat-h-ld-b-to-the-have-nd-ve-bath-ndd-  function-owe-vot-ne-bou-tod-high-thereve-td-hi-te-gat-d-1at-\t1aw-&[oeavat-leot-b-homb-to-et-hi-let-liat-hi-e-te-gat-d-4-tehot-bota-ard-d-d-ad-venot-bou-bota-important working L'ander-named-odot-from-batt-to-venot-high-nouat-oi-tableotod-tohtodillegrillehiilleve,watts-liitowe-thaat-forzegat-with-had-to-thaatat-hadat-mu-itatan-dirzi-watts-mi-veatan-dir-hi-ve(ot) la-high-renot-i-vou-batt-venot-here-batt-part-had-eot-to-had-eat-h1&3 times-to-had-eta-high-reve-ha-w-to-had-to-had-z-has-to-had-to-an-d-ot-avat-spect-divot-the-woman-b-ot-here-b-to-h-1-has-to-have-to-/ ha-& 4-7-table-to-have-public-obs-ole-uter-ext-battat-partok-[vadot-ot)3-cdot-has-to-have-3female,unden-battles-to-have-ve(ve)nosole-ot-here-high-there-to-have-d(se)ou-ode-ha-has-to-make-so-there-evenot-there-checked-ot-there-4-primary-there-8-depat-hon-ot-has-2-ha-to-h-uen-lits-4-tha-to-a-parent-g-tha-you-have-the-haz-to-re-ve-here-b-d-w-ve-tha-ter-such-craw-that-which-high-there-that-there-which-opinion-that-which-qu-e-has-that-h-u-e-g-1-1-0-tha-1-h-e-ve-arent-(_\"v)h-t)h-(dir-aten-w-as-h-ent-zi-l-which-high-burg-arent-which-has-do-(which)h-ter-high-that-have-tha-2-gels-ke-which-li-ith-that-ve,whichhurgent(here)ws/to(here)ws)ve(int)38)else(this)hurgurgaten(ve)ws)whichat)spirits,which_n(ve)have)that(here)which-the-to-such-that(the)which-theatat-to-the-it,theto(which)that(which-to)that(such-which)thatto(he)ve)that+curzody-to-h+b+g3to+to,which-to+hs@tetaDivznat(here)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 2.2** Take a model from Hugging Face that has rotary embeddings. we can use `stabilityai/stablelm-zephyr-3b` or `mistralai/Mistral-7B-v0.1`, but many others will also work. Somewhere in `model.model.layers` we'll find the `RotaryEmbedding()` layer. Play around changing the `base` parameter. What do we observe if we make the base very small? Very large? How would the outputs of the model change? What would we expect to observe? Please don't only output sentences, but also provide some reflection."
      ],
      "metadata": {
        "id": "6ZsMSyyqgrqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from typing import Optional\n",
        "\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        max_position_embeddings: int,\n",
        "        base: int = 10_000,\n",
        "        device: Optional[torch.device] = None,\n",
        "    ):\n",
        "        super(RotaryEmbedding, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.base = base\n",
        "        self.device = device if device is not None else torch.device('cpu')\n",
        "\n",
        "        # Create position encodings\n",
        "        position_ids = torch.arange(0, max_position_embeddings, dtype=torch.float).unsqueeze(1)\n",
        "        frequencies = torch.pow(base, -torch.arange(0, dim, 2).float() / dim).unsqueeze(0)\n",
        "\n",
        "        # Generate sine and cosine functions\n",
        "        angles = position_ids * frequencies\n",
        "        sine = torch.sin(angles)\n",
        "        cosine = torch.cos(angles)\n",
        "\n",
        "        # Concatenate sine and cosine embeddings to get full position encoding matrix\n",
        "        sine_cosine_embedding = torch.zeros(max_position_embeddings, dim)\n",
        "        sine_cosine_embedding[:, 0::2] = sine\n",
        "        sine_cosine_embedding[:, 1::2] = cosine\n",
        "        self.register_buffer('positional_embeddings', sine_cosine_embedding.to(device))\n",
        "\n",
        "    def forward(self, x: torch.Tensor, seq_len: Optional[int] = None):\n",
        "        \"\"\"\n",
        "        Applies rotary embeddings to the input tensor.\n",
        "\n",
        "        Parameters:\n",
        "        - x: Input tensor of shape [batch_size, num_heads, seq_len, head_size].\n",
        "        - seq_len: Optional specific sequence length. If not provided, derived from x.\n",
        "\n",
        "        Returns:\n",
        "        - Tensor of the same shape as x with rotary embeddings applied.\n",
        "        \"\"\"\n",
        "        if seq_len is None:\n",
        "            seq_len = x.size(2)\n",
        "\n",
        "        # Get the appropriate slice of the positional embedding matrix\n",
        "        pos_embedding = self.positional_embeddings[:seq_len, :]\n",
        "\n",
        "        # Apply rotary embeddings\n",
        "        x_rotated = x * pos_embedding\n",
        "\n",
        "        return x_rotated\n",
        "\n",
        "embed_dim = 64  # Dimension of the token embeddings\n",
        "max_position_embeddings = 512  # Maximum position for the positional embeddings\n",
        "num_heads = 8  # Number of attention heads\n",
        "head_size = embed_dim // num_heads  # Assuming embed_dim is divisible by num_heads\n",
        "seq_len = 10  # Sequence length\n",
        "batch_size = 1  # Batch size\n",
        "\n",
        "# Initialize the rotary embedding layer\n",
        "rotary_embedding = RotaryEmbedding(dim=head_size, max_position_embeddings=max_position_embeddings, base=10000)\n",
        "\n",
        "# Create a dummy input tensor with the desired shape [batch_size, num_heads, seq_len, head_size]\n",
        "input_tensor = torch.randn(batch_size, num_heads, seq_len, head_size)\n",
        "\n",
        "# Apply rotary embeddings\n",
        "rotary_encoded_output = rotary_embedding(input_tensor, seq_len=seq_len)\n",
        "\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "print(\"Output shape after applying rotary embeddings:\", rotary_encoded_output.shape)"
      ],
      "metadata": {
        "id": "Ux6t2pM-iRNi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ee26f2-9854-43a9-eddf-71573334aa39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([1, 8, 10, 8])\n",
            "Output shape after applying rotary embeddings: torch.Size([1, 8, 10, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we adjust the base parameter of the RotaryEmbedding() layer in a model, we're effectively changing how sensitively the model responds to the position of tokens within a sequence. The base parameter influences the rate at which the positional encoding oscillates, impacting the model's ability to differentiate between tokens based on their positions.\n",
        "\n",
        "### Very Small Base\n",
        "\n",
        "When the base is very small, the oscillation in the positional encoding happens very slowly as we move from one token to the next. This slow change means that tokens that are far apart in the sequence may receive very similar positional encodings, making it harder for the model to distinguish between distant tokens based on their positions. The model might then struggle with understanding long-range dependencies or the overall structure of the sequence. For tasks that rely heavily on understanding the sequence structure or detailed positional information (like parsing long texts or handling complex sentence structures), the performance might degrade.\n",
        "\n",
        "### Very Large Base\n",
        "\n",
        "Conversely, if the base is very large, the oscillation in the positional encoding happens very rapidly. This means even adjacent tokens can have significantly different positional encodings. While at first glance this seems beneficial for distinguishing token positions, it can also lead to a scenario where the model becomes too sensitive to position changes. This hyper-sensitivity might hinder the model's ability to generalize patterns across different parts of a sequence or to capture similarities between sequences of different lengths. In practical terms, the model might struggle with tasks that require understanding the similarity between sequences or applying learned patterns across different contexts.\n",
        "\n",
        "### Observations in Outputs\n",
        "\n",
        "With a very small base, I'd expect the model to produce outputs that show a diminished sensitivity to the order of words or tokens. The generated text might be grammatically correct but could lack coherence over longer spans or fail to maintain a consistent theme or narrative thread.\n",
        "\n",
        "With a very large base, the model's outputs might exhibit an overemphasis on local structure at the expense of global coherence. Sentences might be tightly constructed but could be disconnected from each other, leading to a fragmented narrative or argument.\n",
        "\n",
        "### Reflection\n",
        "\n",
        "Adjusting the base parameter in rotary embeddings illustrates a fundamental trade-off in machine learning and natural language processing: the balance between sensitivity to local context and the ability to generalize across broader sequences. Finding the optimal setting for such parameters requires careful tuning, as it depends on the specific tasks the model is being trained for and the nature of the datasets involved. The examples given illustrate how a seemingly minor tweak in the model's architecture can have wide-ranging implications for its behavior and performance."
      ],
      "metadata": {
        "id": "1ZGV6iZzrDVA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3. Going deeper into Mixtral\n",
        "\n",
        "In this task we'll try to understand better what happens inside the Mixtral of Experts model and, in the same time, fine tune it with QLoRA.\n",
        "\n",
        "**Caution**. Mixtral is quite large. It will consume >90 GB of disk space and ~23 GB VRAM on GPU when we load its 4-bit version. So, for a comfortable experience with this task, we will need A100 with 200GB disk space. If we don't have a way of finding this hardware, we can still do whatever doesn't require actually running the models, and there is a bonus task about Mistral for we in the end which we can do to get points.\n",
        "\n",
        "Apart from studying Mixtral, we will fine tune it. I've taken most of the fine tuning part from [this notebook](https://colab.research.google.com/github/brevdev/notebooks/blob/main/mixtral-finetune.ipynb#scrollTo=ece42f7c-3825-45c7-9afc-efb355e9474c).\n"
      ],
      "metadata": {
        "id": "p9Cbs6wH37nX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's load the libraries:"
      ],
      "metadata": {
        "id": "GwuhQpFo5TPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U datasets scipy ipywidgets matplotlib"
      ],
      "metadata": {
        "id": "42-7CMW75Z-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7818f67-c784-4df1-ec9e-9f77cecb2fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
        "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
        "\n",
        "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
        "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
        "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
        ")\n",
        "\n",
        "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
      ],
      "metadata": {
        "id": "iAIwVqkq5hzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For fine tuning we'll be using the [Viggo functional representation](https://huggingface.co/datasets/GEM/viggo) dataset. This dataset contains messages about video games such as\n",
        "\n",
        "*we said we loved The Legend of Zelda: Ocarina of Time. Do we often tend to play similar Nintendo games that are also rated E?*\n",
        "\n",
        "and meaning representations of such messages:\n",
        "\n",
        "*verify_attribute(name[The Legend of Zelda: Ocarina of Time], esrb[E (for Everyone)], rating[excellent], platforms[Nintendo])*\n",
        "\n",
        "We'll try to teach Mixtral to transform messages into their meaning representations. This is a good task for fine tuning, because it is about format tuning, not factuality."
      ],
      "metadata": {
        "id": "6YQcbzZx55ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset('gem/viggo', split='train')\n",
        "eval_dataset = load_dataset('gem/viggo', split='validation')\n",
        "test_dataset = load_dataset('gem/viggo', split='test')"
      ],
      "metadata": {
        "id": "UfHZyaq75o1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27642f08-34bc-4862-9a56-0ca0247d843d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for gem/viggo contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/gem/viggo\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for gem/viggo contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/gem/viggo\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load base model\n",
        "\n",
        "We'll be downloading the model in full precision (so it will take ~100 GB on the disk) and then loading it in 4-bit quantization on GPU."
      ],
      "metadata": {
        "id": "sqPRhaJK-RLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"cuda\")"
      ],
      "metadata": {
        "id": "3ZzCtLm4-d1r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "6030b674d9e34afc8a1186668406a49e",
            "b3ffe1011bee4f59844d6589a01ff453",
            "b3b5af1f3c3e496cb6f745ddc15f6a4f",
            "50120a8097294e169266afcfedfc01b1",
            "18919ff56b74459fad626601de952f8a",
            "4f61bfef631a4350aaa6a18fc70b205b",
            "14742482fa3a4f7a8fc10a31eb7317da",
            "aef376ae5dc1489ab62ceac7de5832dd",
            "95ee75791b4441d9b7e0ab52790c89dc",
            "cb0fc88027cf46268b6b079798661595",
            "48e98fb20e8d4115b025f39a0e920df3"
          ]
        },
        "outputId": "40c41701-84a9-40c4-b97f-4a47852c2dac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6030b674d9e34afc8a1186668406a49e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3.1.** Check which layers are 4-bit quantized and which are not. Actually, we can learn it by just typing `model` and printing its structure, but we encourage we to actually check the `dtype` to be sure about the result.\n",
        "\n",
        "we will find out that not all layers are quantized. Estimate the proportion of parameters that stay in full precision. Why these parameters aren't quantized? Any reasonable hypotesis will get points."
      ],
      "metadata": {
        "id": "RS-Mrtig_E0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbyBDUdfL_9C",
        "outputId": "d308a3d6-53e0-4049-8ff0-bce753704cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MixtralForCausalLM(\n",
              "  (model): MixtralModel(\n",
              "    (embed_tokens): Embedding(32000, 4096)\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x MixtralDecoderLayer(\n",
              "        (self_attn): MixtralSdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
              "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "          (rotary_emb): MixtralRotaryEmbedding()\n",
              "        )\n",
              "        (block_sparse_moe): MixtralSparseMoeBlock(\n",
              "          (gate): Linear4bit(in_features=4096, out_features=8, bias=False)\n",
              "          (experts): ModuleList(\n",
              "            (0-7): 8 x MixtralBlockSparseTop2MLP(\n",
              "              (w1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (w2): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
              "              (w3): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (input_layernorm): MixtralRMSNorm()\n",
              "        (post_attention_layernorm): MixtralRMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): MixtralRMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_quantization(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        print(f\"Layer: {name}, Dtype: {param.dtype}\")\n",
        "\n",
        "check_quantization(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxEbliMhFsyS",
        "outputId": "cf15f89d-5191-4225-8571-96300db2377f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: model.embed_tokens.weight, Dtype: torch.float16\n",
            "Layer: model.layers.0.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.0.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.0.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.1.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.1.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.1.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.2.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.2.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.2.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.3.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.3.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.3.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.4.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.4.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.4.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.5.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.5.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.5.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.6.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.6.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.6.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.7.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.7.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.7.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.8.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.8.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.8.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.9.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.9.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.9.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.10.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.10.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.10.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.11.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.11.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.11.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.12.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.12.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.12.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.13.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.13.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.13.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.14.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.14.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.14.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.15.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.15.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.15.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.16.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.16.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.16.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.17.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.17.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.17.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.18.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.18.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.18.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.19.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.19.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.19.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.20.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.20.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.20.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.21.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.21.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.21.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.22.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.22.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.22.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.23.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.23.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.23.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.24.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.24.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.24.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.25.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.25.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.25.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.26.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.26.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.26.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.27.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.27.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.27.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.28.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.28.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.28.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.29.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.29.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.29.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.30.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.30.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.30.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.31.self_attn.q_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.self_attn.k_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.self_attn.v_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.self_attn.o_proj.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.gate.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.0.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.0.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.0.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.1.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.1.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.1.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.2.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.2.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.2.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.3.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.3.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.3.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.4.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.4.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.4.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.5.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.5.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.5.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.6.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.6.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.6.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.7.w1.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.7.w2.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.block_sparse_moe.experts.7.w3.weight, Dtype: torch.uint8\n",
            "Layer: model.layers.31.input_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.layers.31.post_attention_layernorm.weight, Dtype: torch.float16\n",
            "Layer: model.norm.weight, Dtype: torch.float16\n",
            "Layer: lm_head.weight, Dtype: torch.float16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output shows the data type (`dtype`) of the weights for each layer in our model.\n",
        "\n",
        "The `torch.uint8` dtype indicates that the weights for those layers are quantized to 8 bits. This is a form of quantization where the weights are compressed from floating point representations to 8-bit integers. This is done to reduce the memory footprint and improve the computational efficiency of the model.\n",
        "\n",
        "The `torch.float16` dtype indicates that the weights for those layers are represented as 16-bit floating point numbers (also known as half-precision floating point). This is a balance between memory usage and precision, and is often used in deep learning models to improve efficiency without significantly impacting the accuracy of the model.\n",
        "\n",
        "In my case, it seems like most of the layers are quantized to 8 bits (`torch.uint8`), but the last few layers (`model.layers.31.input_layernorm.weight`, `model.layers.31.post_attention_layernorm.weight`, `model.norm.weight`, and `lm_head.weight`) are using 16-bit floating point numbers (`torch.float16`). This could be because these layers require higher precision for the model to function effectively."
      ],
      "metadata": {
        "id": "Wk3QJbHrA3iY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspecting the model\n",
        "\n",
        "**Task 3.2.** Mixtral paper provides the following model chatacteristics:\n",
        "\n",
        "| Parameter | Value |\n",
        "| :--- |  ---: |\n",
        "| dim | 4096 |\n",
        "| n_layers | 32 |\n",
        "| head_dim | 128 |\n",
        "| hidden_dim | 14336 |\n",
        "| n_heads | 32 |\n",
        "| n_kv_heads | 128 |\n",
        "| context_len | 32768 |\n",
        "| vocab_size | 32000 |\n",
        "| num_experts | 8 |\n",
        "| top_k_experts | 2 |\n",
        "\n",
        "Some numbers can also be obtained by printing the `model`. Print it and browse through the dimensions.\n",
        "\n",
        "Some of the numbers are easies to understand. For example, we have 8 experts and 2 of them are used at inference. That's ok.\n",
        "\n",
        "Now, we have several questions for we:\n",
        "\n",
        "1. Why are the output dimensions (`out_features` in the model rollout) of `q_proj`, `k_proj` and `v_proj` different from 128 which is the dimension of a head (see table above)?\n",
        "2. Why are the output dimensions (`out_features` in the model rollout) of `k_proj` and `v_proj` different from the output dimensions of `q_proj`?\n",
        "\n",
        "Check the long read, it should be enough to answer all the questions."
      ],
      "metadata": {
        "id": "NuNjrpezcA06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:\n",
        "\n",
        "The output dimensions of q_proj, k_proj, and v_proj are different from the head dimension because they are not directly representing the heads themselves. Instead, they are representing the projections of the input into the query, key, and value spaces, respectively.\n",
        "\n",
        "In the context of the transformer model, the input is first linearly transformed (projected) into three different spaces: query, key, and value. These projections are then used in the self-attention mechanism. The dimensionality of these projections is typically the same as the dimensionality of the input, not the number of heads.\n",
        "\n",
        "The number of heads comes into play after these projections. The projected queries, keys, and values are split into multiple \"heads\". Each head then independently performs the self-attention operation on its portion of the projections. This allows the model to capture different types of information in different heads.\n",
        "\n",
        "So, the output dimensions of q_proj, k_proj, and v_proj are not directly related to the number of heads, but rather to the dimensionality of the input and the internal workings of the transformer model."
      ],
      "metadata": {
        "id": "00CtT9BZdbPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2:\n",
        "\n",
        "In the context of the Transformer model, `q_proj`, `k_proj`, and `v_proj` refer to the linear transformations that project the input embeddings into \"query\", \"key\", and \"value\" spaces respectively for the self-attention mechanism.\n",
        "\n",
        "Typically, in a standard Transformer model, the dimensions of the query, key, and value projections are all the same. However, in some variants of the Transformer model, the dimensions of these projections might be different. This could be due to a variety of reasons, such as optimizing computational efficiency, reducing the model's memory footprint, or improving the model's ability to capture different types of information."
      ],
      "metadata": {
        "id": "i1BH9icXNLPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating prompts for fine tuning"
      ],
      "metadata": {
        "id": "PqXekydTAxAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    add_eos_token=True,\n",
        "    add_bos_token=True,\n",
        ")\n",
        "\n",
        "def tokenize(prompt):\n",
        "    result = tokenizer(prompt['target'])\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ],
      "metadata": {
        "id": "YmpiquPFBGNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be training Mixtral to transform text to meaning representation when prompted by a specific command. Namely, we'll fine tune it on prompts of the following form:\n",
        "\n",
        "```\n",
        "<s> Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
        "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
        "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
        "\n",
        "### Target sentence:\n",
        "Dirt: Showdown is a sport racing game that was released in 2012. The game is available on PlayStation, Xbox, and PC, and it has an ESRB Rating of E 10+ (for Everyone 10 and Older). However, it is not yet available as a Steam, Linux, or Mac release.\n",
        "\n",
        "### Meaning representation:\n",
        "inform(name[Dirt: Showdown], release_year[2012], esrb[E 10+ (for Everyone 10 and Older)], genres[driving/racing, sport], platforms[PlayStation, Xbox, PC], available_on_steam[no], has_linux_release[no], has_mac_release[no])\n",
        "</s>\n",
        "```"
      ],
      "metadata": {
        "id": "LrFNK6UmBGs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For fine tuning we will be padding the texts, and for that we need to understand the distribution of lengths"
      ],
      "metadata": {
        "id": "efknjmVMDrhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
        "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
        "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
        "    print(len(lengths))\n",
        "\n",
        "    # Plotting the histogram\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
        "    plt.xlabel('Length of input_ids')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Lengths of input_ids')\n",
        "    plt.show()\n",
        "\n",
        "# Tokenize the datasets\n",
        "tokenized_train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "tokenized_val_dataset = eval_dataset.map(tokenize, batched=True)\n",
        "\n",
        "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
      ],
      "metadata": {
        "id": "hwH5EQrFCdvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "48153a89-b36a-484a-aebe-21c63973da5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5817\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will find that 340 is a good estimate of max length. We will include padding and truncation into the `tokenization` routine:"
      ],
      "metadata": {
        "id": "3TL3ONExDynK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 340 # This was an appropriate max length for my dataset\n",
        "\n",
        "# redefine the tokenize function and tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    padding_side=\"left\",\n",
        "    add_eos_token=True,\n",
        "    add_bos_token=True,\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "def tokenize(prompt):\n",
        "    result = tokenizer(\n",
        "        prompt,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ],
      "metadata": {
        "id": "azadmjD9ENmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now, let's assemble the prompts for fine tuning:"
      ],
      "metadata": {
        "id": "Io4Dxb3eEORR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_tokenize_prompt(data_point):\n",
        "    full_prompt =f\"\"\"Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
        "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
        "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
        "\n",
        "### Target sentence:\n",
        "{data_point[\"target\"]}\n",
        "\n",
        "### Meaning representation:\n",
        "{data_point[\"meaning_representation\"]}\n",
        "\"\"\"\n",
        "    return tokenize(full_prompt)"
      ],
      "metadata": {
        "id": "5hSWcYBoBIjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
        "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
      ],
      "metadata": {
        "id": "o5MNiiD7Bhb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "48a7e947be82487eb7324f35c4a4ffbf",
            "ad3884aa753a4a35895779b54c7d82e9",
            "4b9a29d258304be0baac0c984f2cdfdc",
            "dd24de92f6d74e64a7ed3654e0a47a14",
            "e5175593afd241878b3edfa6593554eb",
            "6dad5998d9be492885000fca6620bcd7",
            "4c04bd5b2bc14ac5953c67a917a0325f",
            "bb0b3a2e68cb481aabb9c0abace3afa0",
            "020d54f72b1b458989c9c781b2817e5c",
            "9c784c7027a3453c9568e780a5bf23da",
            "9489506bd13145faa03e11c9a4d27844"
          ]
        },
        "outputId": "526f4224-24cc-41c8-f88a-065a8713078d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/714 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48a7e947be82487eb7324f35c4a4ffbf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "q0_XUgmdQOiM",
        "outputId": "dbc8a34b-db36-4202-88c3-82b3ad083ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5817\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the model for the first time\n",
        "\n",
        "Now, let's try to apply Mixtral!"
      ],
      "metadata": {
        "id": "iyVrvtccFXCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompt = \"\"\"Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
        "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
        "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
        "\n",
        "### Target sentence:\n",
        "Earlier, we stated that we didn't have strong feelings about PlayStation's Little Big Adventure. Is our opinion true for all games which don't have multiplayer?\n",
        "\n",
        "### Meaning representation:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "E9P4fP5XFxXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can apply accelerator to the model. If we're using colab, it can start raising stupid errors like\n",
        "\n",
        "```\n",
        "TypeError: device() received an invalid combination of arguments - got (NoneType), but expected one of:\n",
        " * (torch.device device)\n",
        "      didn't match because some of the arguments have invalid types: (!NoneType!)\n",
        " * (str type, int index)\n",
        "\n",
        "```\n",
        "\n",
        "Most likely, we'll be able to overcome it by running\n",
        "\n",
        "`model.hf_device_map = {'': torch.device('cuda', index=0)}`"
      ],
      "metadata": {
        "id": "V5BeR4y6F03x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the accelerator. we can comment this out to remove the accelerator.\n",
        "# model = accelerator.prepare_model(model)\n",
        "model.hf_device_map = {'': torch.device('cuda', index=0)}"
      ],
      "metadata": {
        "id": "SNzB8UTFFx8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-init the tokenizer so it doesn't add padding or eos token\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    add_bos_token=True,\n",
        ")"
      ],
      "metadata": {
        "id": "hEtbvs6ZIZ3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(device)"
      ],
      "metadata": {
        "id": "2BPeKOzwIjJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=128)[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "PMagIWF9Iji4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b7f68c-ef2c-4b6d-c207-016385476e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
            "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
            "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
            "\n",
            "### Target sentence:\n",
            "Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
            "\n",
            "### Meaning representation:\n",
            "inform(name(Little Big Adventure), has_multiplayer(Little Big Adventure))\n",
            "\n",
            "### Target sentence:\n",
            "I'm looking for a game that is available on Steam and has a multiplayer mode. Can you recommend any games that meet these criteria?\n",
            "\n",
            "### Meaning representation:\n",
            "request(name(game), has_multiplayer(game), available_on_steam(game))\n",
            "\n",
            "### Target sentence:\n",
            "I'm looking for a game that is available on Steam and has a multiplayer mode. Can you recommend any games that meet these criteria?\n",
            "\n",
            "### Mean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that the model doesn't understand which formatting we are expecting from it. We will try to improve it with fine tuning."
      ],
      "metadata": {
        "id": "xm48VG57P2Z_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Investigating Mixtral heads\n",
        "\n",
        "**Task 3.3.** Apply Mixtral to some sentence\n",
        "\n",
        "`router_logits = model(**model_input, output_router_logits=True)`\n",
        "\n",
        "to make it return router logits that decide which heads are used for inference.\n",
        "\n",
        "Do the logits stay the same when we apply Mixtral several times to the same sentence? Why?\n",
        "\n",
        "Now:\n",
        "- get router logits of 10th, 20th and 30th layers for the first 100 elements of `tokenized_train_dataset`.\n",
        "- For each expert of each of these layers, make a list of tokens for which this expert has top-1 logit (yes, please do it separately for each of the experts),\n",
        "- Output top-5 most frequent tokens from each of the lists.\n",
        "\n",
        "our output should be like:\n",
        "\n",
        "```\n",
        "At layer 20:\n",
        "\n",
        "Expert 0:\n",
        "[('token1', how_many_times_expert_0_got_top1_router_logit_with_this_token),\n",
        "('token2', how_many_times_expert_0_got_top1_router_logit_with_this_token),\n",
        "('token3', how_many_times_expert_0_got_top1_router_logit_with_this_token),\n",
        "('token4', how_many_times_expert_0_got_top1_router_logit_with_this_token),\n",
        "('token5', how_many_times_expert_0_got_top1_router_logit_with_this_token),]\n",
        "\n",
        "Expert 1\n",
        "....\n",
        "```\n",
        "\n",
        "Do we observe any patterns?"
      ],
      "metadata": {
        "id": "TVU3GGRSIllV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "import torch\n",
        "\n",
        "# Initialize a dictionary to store the tokens for each expert\n",
        "expert_tokens = defaultdict(list)\n",
        "\n",
        "# Loop over the first 100 elements of the tokenized_train_dataset\n",
        "for i in range(100):\n",
        "    # Get the input for the model\n",
        "    model_input = tokenized_train_dataset[i]\n",
        "\n",
        "    # Remove unnecessary keys from the model input\n",
        "    for key in ['gem_id', 'meaning_representation', 'target', 'references']:\n",
        "        if key in model_input:\n",
        "            del model_input[key]\n",
        "\n",
        "    # Convert input_ids, attention_mask, and labels to tensors if they're lists\n",
        "    # Add the batch dimension if it's missing\n",
        "    for key in ['input_ids', 'attention_mask', 'labels']:\n",
        "        if isinstance(model_input.get(key), list):\n",
        "            model_input[key] = torch.tensor(model_input[key])\n",
        "        if len(model_input.get(key).shape) == 1:\n",
        "            model_input[key] = model_input[key].unsqueeze(0)\n",
        "\n",
        "    # Iterate over all layers in router_logits\n",
        "    for layer in range(len(router_logits)):\n",
        "        # Get the logits for this layer\n",
        "        logits = router_logits[layer]\n",
        "\n",
        "        # Check if logits is not a 0-dimensional tensor\n",
        "        if isinstance(logits, tuple):\n",
        "            for tensor in logits:\n",
        "                if isinstance(tensor, torch.Tensor) and tensor.dim() > 0:\n",
        "                    for expert in range(tensor.shape[-1]):\n",
        "                        # Get the tokens where this expert has the top-1 logit\n",
        "                        top1_indices = tensor[..., expert].argmax(-1)\n",
        "\n",
        "                        # Check if the top1_indices are within the range of the tensor\n",
        "                        if top1_indices < model_input['input_ids'].shape[0]:\n",
        "                            top1_tokens = model_input['input_ids'][top1_indices]\n",
        "\n",
        "                            # Add these tokens to the list for this expert\n",
        "                            expert_tokens[(layer, expert)].extend(top1_tokens.tolist())\n",
        "                        else:\n",
        "                            print(f\"Index {top1_indices} is out of range. Skipping this index.\")\n",
        "                else:\n",
        "                    print(\"Tensor is not a tensor or is a scalar, skipping this loop.\")\n",
        "        else:\n",
        "            if logits.dim() > 0:\n",
        "                print(\"Logits is a scalar, skipping this loop.\")\n",
        "\n",
        "# For each expert, count the frequency of each token and get the top-5 most frequent tokens\n",
        "for (layer, expert), tokens in expert_tokens.items():\n",
        "    token_counts = Counter(tokens)\n",
        "    top5_tokens = token_counts.most_common(5)\n",
        "\n",
        "    print(f\"At layer {layer}:\\n\")\n",
        "    print(f\"Expert {expert}:\")\n",
        "    for token, count in top5_tokens:\n",
        "        print(f\"('{eval_tokenizer.decode([token])}', {count})\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "TnwxQnAKRzzO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70a67b3-599d-4c2d-e953-26856cf17a60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n",
            "Logits is a scalar, skipping this loop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up LoRA\n",
        "\n",
        "We will be fine tuning our model with LoRA. To start, we have to apply some preprocessing to the model to prepare it for training. For that use the prepare_model_for_kbit_training method from PEFT."
      ],
      "metadata": {
        "id": "rrIlFIiY9EoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "KPe8MODnK8vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll define which layers are subject to fine tuning and understand how many trainable parameters we are going to have."
      ],
      "metadata": {
        "id": "fQO5t9qY9R6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "r--3XXmz9M1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"w1\",\n",
        "        \"w2\",\n",
        "        \"w3\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "hPOEbNqu9kWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "id": "PpOnXfu8R9ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d399d818-30ab-48fe-adb6-2e045d956fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 120350720 || all params: 23602952192 || trainable%: 0.5098968934945001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, only a small ratio of parameters are trainable."
      ],
      "metadata": {
        "id": "H2B14IhNR_O6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look closer at the config.\n",
        "\n",
        "* `r` is the rank of the low-rank matrix used in the adapters. The larger it is, the more trainable parameters we have, so the more expressive the model is, but also the more compute we need for fine tuning. We set `r = 8` which is a reasonable default value.\n",
        "* `lora_alpha` is the scaling factor for the learned weights. The weight matrix $\\Delta W$ is scaled by `lora_alpha/r`, and thus a higher value for alpha assigns more weight to the LoRA activations. We use `lora_alpha = 16` which is also a reasonable default.\n",
        "\n",
        "\n",
        "The trainable layers are indicated by their codes \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"w1\", \"w2\", \"w3\", \"lm_head\". Here,\n",
        "\n",
        "* \"q_proj\", \"k_proj\", \"v_proj\" are $W_Q, W_K, W_V$ matrices making queries, keys and values from transformer layer inputs like in $q = xW_Q$.\n",
        "* \"o_proj\" is the output projection matrix $W_o$ that comes at the final step of QKV-attention mechanism. For the linearized attention mechanism it would look like this:\n",
        "$$o_n = \\sum_{m=1}^N\\frac{\\left(\\psi(q_n)R^d_{\\Theta, n}\\right)\\left(\\phi(k_m)R^d_{\\Theta, m}\\right)^T}{\\sum_{m=1}^N\\psi(q_n)\\phi(k_m)^T}v_m,$$\n",
        "$$\\quad$$\n",
        "$$output = oW_o,$$\n",
        "* \"lm_head\" is the language modeling head that goes after the last transformer block and predicts next token logits.\n",
        "\n",
        "It is reasonable that we don't fine tune the embedding layer. It is only reasonable to train it if we introduce new tokens (for example, if we want to adapt our model to new languages), and in this case we only train the embeddings of newly added tokens."
      ],
      "metadata": {
        "id": "dPzHiX6b9k2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3.4.** Now, we have a quest for we. The labels \"w1\", \"w2\" and \"w3\" stand for the linear layers inside each of the experts (who are just MLPs). But how are they connected to each other? What is the architecture of this MLP?\n",
        "\n",
        "It's not addressed well in the Mixtral/Mistral papers (feel free to check though, maybe the author of this hometask wasn't attentive enough), so our best chance to grasp it is finding the source code in the Transformers library."
      ],
      "metadata": {
        "id": "7C3ktN8v_sQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The labels \"w1\", \"w2\", and \"w3\" represent the weights of the linear layers in each expert of the Mixture of Experts (MoE) model. In the context of the MixtralForCausalLM model, each expert is a MixtralBlockSparseTop2MLP module, which is a type of multi-layer perceptron (MLP).\n",
        "\n",
        "The architecture of this MLP can be inferred from the model structure:\n",
        "\n",
        "MixtralBlockSparseTop2MLP(\n",
        "  (w1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
        "  (w2): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
        "  (w3): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
        "  (act_fn): SiLU()\n",
        ")\n",
        "\n",
        "The input to the MLP is a vector of size 4096 (as indicated by in_features=4096 in the w1 layer).\n",
        "\n",
        "This input is passed through the w1 layer, which is a linear layer that transforms the input vector from size 4096 to size 14336.\n",
        "\n",
        "The output of the w1 layer is then passed through the activation function (act_fn), which is a Scaled Exponential Linear Unit (SiLU).\n",
        "\n",
        "The activated output is then passed through the w2 layer, which is another linear layer that transforms the vector from size 14336 back to size 4096.\n",
        "\n",
        "The output of the w2 layer is again passed through the activation function.\n",
        "\n",
        "Finally, the activated output is passed through the w3 layer, which is a third linear layer that transforms the vector from size 4096 back to size 14336.\n",
        "\n",
        "This forms a three-layer MLP with sizes 4096-14336-4096-14336. The use of the SiLU activation function between the layers adds non-linearity, allowing the MLP to model more complex functions."
      ],
      "metadata": {
        "id": "MEx5KQCAR67a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Training\n",
        "\n",
        "Fine tuning can take some time. However, we can stop training earlier (say, after 100-500 steps) if we observe overfitting or are just tired of waiting. Thought, the result can be not so great."
      ],
      "metadata": {
        "id": "N6YPuXtWJ-aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
        "    model.is_parallelizable = True\n",
        "    model.model_parallel = True"
      ],
      "metadata": {
        "id": "e1ZtEQq2Jyap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.device_count() # should be 4 if using Brev's instance link"
      ],
      "metadata": {
        "id": "TlFcqYNZMxRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e052ab53-1613-4849-cd33-6e9aa160207a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from datetime import datetime\n",
        "\n",
        "project = \"viggo-finetune\"\n",
        "base_model_name = \"mixtral\"\n",
        "run_name = base_model_name + \"-\" + project\n",
        "output_dir = \"./\" + run_name\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_val_dataset,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        warmup_steps=5,\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_checkpointing=True,\n",
        "        gradient_accumulation_steps=4,\n",
        "        max_steps=1000,\n",
        "        learning_rate=2.5e-5,\n",
        "        logging_steps=25,\n",
        "        fp16=True,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        logging_dir=\"./logs\",        # Directory for storing logs\n",
        "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
        "        save_steps=50,                # Save checkpoints every 50 steps\n",
        "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
        "        eval_steps=50,               # Evaluate and save checkpoints every 50 steps\n",
        "        do_eval=True,                # Perform evaluation at the end of training\n",
        "        # report_to=\"wandb\",           # Comment this out if we don't want to use weights & baises\n",
        "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!"
      ],
      "metadata": {
        "id": "jL4N__SGMxPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47435cf8-dc51-486a-a097-10e5fb74c5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 3.5.** Run the training!"
      ],
      "metadata": {
        "id": "x8TfshujM780"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "DSkYaUNUM52B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69e47057-8638-4d9a-a994-cdd66ddf43e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 4:10:55, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.372100</td>\n",
              "      <td>0.318896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.269800</td>\n",
              "      <td>0.241046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.220300</td>\n",
              "      <td>0.208178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.200300</td>\n",
              "      <td>0.194138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.183300</td>\n",
              "      <td>0.185336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.178900</td>\n",
              "      <td>0.179672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.167200</td>\n",
              "      <td>0.176036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.180700</td>\n",
              "      <td>0.173043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.180200</td>\n",
              "      <td>0.171637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.152200</td>\n",
              "      <td>0.168480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.168700</td>\n",
              "      <td>0.166823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.157100</td>\n",
              "      <td>0.165282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.166600</td>\n",
              "      <td>0.164369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.157900</td>\n",
              "      <td>0.163076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.159000</td>\n",
              "      <td>0.162544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>0.161925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.153000</td>\n",
              "      <td>0.161352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.153700</td>\n",
              "      <td>0.161026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.165900</td>\n",
              "      <td>0.160453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.161000</td>\n",
              "      <td>0.160391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:139: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1000, training_loss=0.21224154019355773, metrics={'train_runtime': 15069.2305, 'train_samples_per_second': 0.265, 'train_steps_per_second': 0.066, 'total_flos': 3.8100730281984e+17, 'train_loss': 0.21224154019355773, 'epoch': 0.78})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that while training the model will save the adapter weights each 50 steps (`save_steps` param) in the folders like \"mixtral-viggo-finetune/checkpoint-50\", \"mixtral-viggo-finetune-2/checkpoint-100\" etc. This way, we'll be able to restore the trained model later."
      ],
      "metadata": {
        "id": "ysB7pTsSN5mS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try the model\n",
        "\n",
        "At this point, we recommend we to restart the kernel to avoid running into out of memory problems.\n",
        "\n",
        "To reload the model, we need to do two things:\n",
        "\n",
        "1. Load the base model,\n",
        "2. Load the adapter weights that oure saved in the checkpoints."
      ],
      "metadata": {
        "id": "o-NwafE9Nj0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,  # Mixtral, same as before\n",
        "    quantization_config=bnb_config,  # Same quantization config as before\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    add_bos_token=True,\n",
        "    trust_remote_code=True,\n",
        ")"
      ],
      "metadata": {
        "id": "rCrCl_L1NlJZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "4cad422b16d44dfeaa82caff8fe7fc29",
            "21839f7b077a448fba14bb720a5fc1e6",
            "3a0b9ae0adf54b6a8c67aa9d93560044",
            "c1fdf85f020d43058150d858efde2e34",
            "d1035cfdc09343e8bc3b323b87732314",
            "53a80d22816043558bd0643af312dbdb",
            "ca90af390cf44f49835991f66ec17ceb",
            "d0c0e36c4f464431a75dfee21d580de2",
            "000558dc9c1a4a1a913ca03d2180354e",
            "9c62ff4089204c69a674ab98e3b1839a",
            "0f294c5d77c7457ba4dee69d25c0a6ce",
            "fc44be96362546559b8f2e71fd06e160",
            "853ac956a1e34ebf99f10b3a098bd80c",
            "cd83b453c28248e59d65ea79a9ec20c5",
            "64c76a71254a4442b421380ab6496543",
            "8e7fa961b51648f4be69903fc1b43fc5",
            "7778c9fbe2f94d88918416574679f33c",
            "a883e022ed884986931bea87d90a0327",
            "634261ec000247b2a9f4831a23968dd6",
            "84d3610c1a584f9699f2bc31a572d776",
            "6083310d84904961a60398aeae78ed43",
            "072d92cc645d45abb45daffd0edab010",
            "4093614e2a204e7189b0123003430940",
            "48de606c82404efeacaf0da7a4bea7df",
            "cc09f8c4d61f42c099d25316ee0fa7a5",
            "3e09b5271c004e58bfcb2d0004d7aca0",
            "70a399a8abdd49acb8676867e8d94589",
            "da1cb166be374ea888c27647fa37c283",
            "e08d6dbabaa046c88451ed6ec04dd252",
            "7eb34bc193fc451f85cf817231cf963b",
            "0b6bd25360234c77983144190385dcc6",
            "245e8258a51244aa9df61ead09792170",
            "3a6c3146c3bd4837971f0fe333163edf",
            "be0c311c77064d44be0c8a85c1cb0a80",
            "6f9f5fe148e64fe090342f449fd50285",
            "89d3dde9f0bd415f87dadb20032f551f",
            "0be2eb5399e04786bff84a7b7235252f",
            "b1a0154ac7034e02b251f7b50920c0c3",
            "2b9809065b4f48db9aa876ed8ba9bbe3",
            "1d4bcb093f2744e1a5abf49abe05c53a",
            "fb8a89752f3e4dec90ea51756efcc2e8",
            "4b6509ddd37347acacfbf13c52540841",
            "80a14e27a47f48ebb42663156d39886c",
            "2bfa29f249b6405cbea5210b2a3a015e",
            "a1152f2475ce43948c9b249f8f8f3af1",
            "104e474ce4994d33b114c15d95cfef74",
            "5b4869b36e844d3a8c720290eb81dc1c",
            "fd64a60abdc14597b2abfc2cf7c2959a",
            "c4729a508b05477f9519d80a09c1a96f",
            "f61ae0368c7b400ebe5daa02480b0582",
            "81e9c629bfb1477fb8366188d8ef83a2",
            "3a7528a8f33b491db4ae54ac9e2b4eb4",
            "d8cca96404e6471c8367bf280312af83",
            "a43182820dfb4416891f6cd8bc1c2f22",
            "4b11538c1a1744b6ab7c2b2b31a3c89a",
            "aede343f6eee4183aa627aaa5e480922",
            "0385696f7769440ba194126d599bc970",
            "d9b2d6a7e677449eb4339fa5f6385fbb",
            "ead40e8686a6483eadd98ed2799a9867",
            "9605ee8f0b35423a830ccd56ccdf88b9",
            "e7f6738247024a14a3b35e174e9b31a0",
            "175ab11a6d2f4ca0837f40f088fba1be",
            "63a74cc04c45441483a72108b91f68b6",
            "dec53933d87940d783e3c2759b51320c",
            "e0c8c4f119034c65bb5fe8bf1eb5acb4",
            "8105bae29d4542e49624cba4fedafa7d",
            "f25d88626abc4136a45011f8357b4e01",
            "25d2ab7ad5b84b88922f94507e0d6197",
            "3fbef5f6ac70403eb43ab4d3ec23d53b",
            "34fbe5b33ad0427e8bf91d1923870bb5",
            "4c0d562f86954955bd36071cf1231c30",
            "afac4264eb1c4b09a56178774234e9a0",
            "12f5fea121cb419d9d1037c3179a9ecd",
            "de3fe63c0bb44c299af029c250e0f1ae",
            "fdbdd89baf3d488fb5cda0b1ee654993",
            "077968b3357540999b6c109e79c9c5fd",
            "2b4244b1b5fd402d9fd4144468124cae",
            "8979076ffd004c89bc55056a507bbe63",
            "3beb3fab771640a0ac1720c9d383798e",
            "d3d78cecb4cd41f59e197659d61135e1",
            "07340a6b878242f88200ee66d100af5b",
            "41629a2de0ac427eb8b461fda0ca1170",
            "1d48448610d0474a8067868617ef074a",
            "abe11602ca084af196c476f3cf50c1cd",
            "a47713dbdff14c3ca7e87917d0cecf91",
            "9bf1b7ee1ba3419bb005ba8b4aa5bc8f",
            "db174e0f7d724cd0825c3fb6d7d6c976",
            "7996c149e19b4e308973d6abd8980e99",
            "0218ffc1bbf7454b8a6e8fc11a1119a0",
            "610df534a09c4ea8acca5bd208bf6ffa",
            "b97109099a7a4d189da9824212b647c4",
            "b904f8468e5341489bc495ace16d2db6",
            "dfb3689d407344e7a8c00229f75980f7",
            "8a5f95eb7fb749789e6e1bfb86d7c166",
            "838b1f4718fe4cc0b12170a24980a513",
            "6c405c18011b4e0a921b26804bc450b4",
            "ad18ecdd2b734c07822cd16c247da365",
            "1736b5f930c847c78c1b501a3fdbbe3b",
            "936d79b6c5f6429482d031d494ab2961",
            "a2c3d034ab3f4fa4b84023e45054bb37",
            "b85103561b294927b10b31dacbbccff7",
            "396e533776cb4077a39d058076a0f273",
            "a6f3bf664fed46bdafdc822f9ed32aee",
            "78bcc09396ba4b4e90c57a13ce0b5b93",
            "60feec27d42c4d28b9624f7e154d13e9",
            "529e83433aec48baa2d224f18e7f09c6",
            "de6f782e22014a63b844437ba875d10b",
            "951cd121fecb484fab0420b95ef6d38a",
            "30ea0a982e78476c99df3d71fdda56ff",
            "b176a4d2e1fe4536a4fee4e69ba7bb0d",
            "ad41084ecb1f48a7bb0c2cf9bdc90c91",
            "ac16cef18b3047e8b2b9d1835474e4cf",
            "61a8233455c3484ea855cf870177d6e8",
            "826353cd707f4e76a6fee4bb16ac881c",
            "394ac921a4054a869dee9fbe92ef5468",
            "9906dea00e9d48eda2ca8129f5a3046b",
            "c60ec5300ec34af69cbec8c2b340f84a",
            "a6adf9f29c66407d97d63d6cfa1bc93a",
            "5a5e3e60cb2e42c394570c6bc8ad698b",
            "1df7d49870744fefa745d464551c9d54",
            "1c1125fd1b5f4b22a6bc11b38e566103"
          ]
        },
        "outputId": "5d8eeb8c-147d-485c-a9f1-e14b93d40bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4cad422b16d44dfeaa82caff8fe7fc29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc44be96362546559b8f2e71fd06e160"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4093614e2a204e7189b0123003430940"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be0c311c77064d44be0c8a85c1cb0a80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1152f2475ce43948c9b249f8f8f3af1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aede343f6eee4183aa627aaa5e480922"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f25d88626abc4136a45011f8357b4e01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8979076ffd004c89bc55056a507bbe63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0218ffc1bbf7454b8a6e8fc11a1119a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2c3d034ab3f4fa4b84023e45054bb37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad41084ecb1f48a7bb0c2cf9bdc90c91"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "# Insert correct checkpoint index, double check the path\n",
        "ft_model = PeftModel.from_pretrained(base_model, \"mixtral-viggo-finetune/checkpoint-1000\")"
      ],
      "metadata": {
        "id": "Csyz7wZYO9fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's run the model and see if it learnt to abide the required format:"
      ],
      "metadata": {
        "id": "K6cTbanrPZMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_prompt = \"\"\"Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
        "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
        "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
        "\n",
        "### Target sentence:\n",
        "Earlier, we stated that we didn't have strong feelings about PlayStation's Little Big Adventure. Is our opinion true for all games which don't have multiplayer?\n",
        "\n",
        "### Meaning representation:\n",
        "\"\"\"\n",
        "\n",
        "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=50)[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "CRFY-lXkPoLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf2e3f4-d5e3-4808-8d34-b3301af25205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
            "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
            "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
            "\n",
            "### Target sentence:\n",
            "Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
            "\n",
            "### Meaning representation:\n",
            " /******/ /***/ /***/ ###### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ### ###\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=128)[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojknzmwVfOgL",
        "outputId": "454eaf7b-c0ca-451b-8377-4acc53d9ab35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
            "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
            "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
            "\n",
            "### Target sentence:\n",
            "Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
            "\n",
            "### Meaning representation:\n",
            "verify_attribute(name[Little Big Adventure], rating[average], has_multiplayer[no], platforms[PlayStation])\n",
            "\n",
            "### Target sentence:\n",
            "I'm curious, have you ever played a game that you thought was just average?\n",
            "\n",
            "### Meaning representation:\n",
            "request(specifier[average])\n",
            "\n",
            "### Target sentence:\n",
            "Have you ever played a game that you thought was just average?\n",
            "\n",
            "### Meaning representation:\n",
            "request(specifier[average])\n",
            "\n",
            "### Target sentence:\n",
            "Have you ever played a game that you thought was just average?\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations and reflections\n",
        "\n",
        "From the results, it appears that fine-tuning the Mixtral model has led to more detailed and potentially more accurate meaning representations.\n",
        "\n",
        "Without fine-tuning, the model seems to generate simpler meaning representations. For example, in response to the sentence about \"Little Big Adventure\", it generates \"inform(name(Little Big Adventure), has_multiplayer(Little Big Adventure))\". This representation is quite basic and may not fully capture the nuances of the input sentence.\n",
        "\n",
        "With fine-tuning, the model generates more complex meaning representations. For the same sentence about \"Little Big Adventure\", it generates \"verify_attribute(name[Little Big Adventure], rating[average], has_multiplayer[no], platforms[PlayStation])\". This representation includes more attributes and seems to better capture the nuances of the input sentence.\n",
        "\n",
        "For the sentence \"I'm curious, have we ever played a game that we thought was just average?\", both the fine-tuned and non-fine-tuned model generate the same representation: \"request(specifier[average])\". This suggests that for some sentences, fine-tuning may not make a significant difference.\n",
        "\n",
        "Overall, it seems that fine-tuning the Mixtral model can lead to more detailed and potentially more accurate meaning representations. However, the effectiveness of fine-tuning may depend on the specific sentences and the complexity of their meaning."
      ],
      "metadata": {
        "id": "S6j_bk8fj1F7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do this instead of Task 3 if Mixtral doesn't fit on our GPU\n",
        "\n",
        "If we can't approach Mixtral, we will do almost the same with Mistral. Mistral is much less compute intensive and fits well on V100.\n",
        "\n",
        "In what concerns fine tuning, the only thing we need is to change `model_id` to `\"mistralai/Mistral-7B-v0.1\"`. All the code should work without trouble. Just **please indicate in bold in the beginning of Task 3 that we're using Mistral instead of Mixtral**.\n",
        "\n",
        "**Tasks 3.1, 3.2, 3.4, and 3.5** stay the same. Moreover, the answers won't change much, because Mixtral inherits Mistral's architectural ideas.\n",
        "\n",
        "Task 3.3 doean't make sense with Mistral, so instead we'll do the following:\n",
        "\n",
        "**Task 4.3.** Fine tuning Mistral is faster than fine tuning Mixtral, so we can run several experiments (but try to reach at least 500 steps). Train only attention layers with QLoRA. How will the number of trainable parameters change? Compare the quality of the resulting model."
      ],
      "metadata": {
        "id": "QZkuhFYqQL7c"
      }
    }
  ]
}