{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIAlchemy1/Generative-AI/blob/main/02_LangChain/LCEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The world of LLM and LLM related tools changes very fast.\n",
        "\n",
        "For example, while I was writing this code, one of most widely used libraries for LLM-related tasks deprecated their main interface.\n",
        "\n",
        "More precisely they went from `Chain` interface to `LCEL` - Lang Chain Expression Language.\n",
        "\n",
        "This change does not change the fundamental materials so much. But we wanted to show you the difference between the two, as you might see case studies in LCEL and I want you to be prepared"
      ],
      "metadata": {
        "id": "WELtFNpZJPt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai langchain_openai --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Of1C0V1KaXK",
        "outputId": "fc8a38af-b1ed-49af-e333-57a47e946161"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = open(\"/content/drive/MyDrive/.open-ai-api-key.txt\").read().strip()"
      ],
      "metadata": {
        "id": "fjm9ShP0Lh7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8a70a19-e563-4322-8e40-ddbfa9c5201f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A short demonstration of how the new interface looks:"
      ],
      "metadata": {
        "id": "8sNm-rtxrkOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
        "model = ChatOpenAI(model=\"gpt-4\")\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "print(chain.invoke({\"topic\": \"beavers and elves\"}))"
      ],
      "metadata": {
        "id": "Uufyd-ocrrIi",
        "outputId": "c005963a-cdec-4586-d442-355a9648f60d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why don't beavers work with elves?\n",
            "\n",
            "Because they can't stand the elf and safety regulations!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will have a demonstration of all the concepts introduced in the previous code and how (or if) they changed with the new version."
      ],
      "metadata": {
        "id": "5MXRqMMlsPn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a model\n",
        "\n",
        "Before we were using a method `predict` and now the correct one is `invoke`"
      ],
      "metadata": {
        "id": "xQ-K9bBAtNqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classic LLM"
      ],
      "metadata": {
        "id": "GDReW5NYvGh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI()\n",
        "\n",
        "llm.invoke(\"Hello \")"
      ],
      "metadata": {
        "id": "piMM6hsms4Ne",
        "outputId": "48f20949-936f-430d-d683-1ef244d1db52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nHello, how can I assist you?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"One {object} a day keeps who away?\")\n",
        "\n",
        "prompt_value = prompt.invoke({\"object\": \"apple\"})\n",
        "\n",
        "llm.invoke(prompt_value.to_string())"
      ],
      "metadata": {
        "id": "enkkoYegt_sY",
        "outputId": "252ed079-dc6e-475e-9d6f-46eaa6a7be0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nDoctor\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat model"
      ],
      "metadata": {
        "id": "uuhi23_ateis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI()\n",
        "\n",
        "chat_model.invoke(prompt_value.to_messages())"
      ],
      "metadata": {
        "id": "pdRL4pIYtgrS",
        "outputId": "e176558d-2433-4027-8695-1799a23a7ad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The saying goes \"An apple a day keeps the doctor away.\"')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chains\n",
        "\n",
        "What it looked like before\n",
        "\n",
        "```\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "chain.run(\"Australia\"\n",
        "```\n",
        "\n",
        "Now the interface is the following"
      ],
      "metadata": {
        "id": "PzOgtl2_vLkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model\n",
        "chain.invoke({\"object\": \"Banana\"})"
      ],
      "metadata": {
        "id": "rAreoZKXvhoC",
        "outputId": "bb75aaf6-2586-46f0-b893-f01b5398f7ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='There isn\\'t a specific person or thing that a banana a day keeps away. This might be a misinterpretation of the saying \"An apple a day keeps the doctor away.\" Eating a banana a day can contribute to a healthy diet due to its high potassium and vitamin C content.')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequential chains\n",
        "\n",
        "Before it looked like this:\n",
        "\n",
        "```\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "first_prompt = PromptTemplate.from_template(\n",
        "    \"What is the capital of {country}?\"\n",
        ")\n",
        "first_chain = LLMChain(llm=llm, prompt=first_prompt)\n",
        "\n",
        "second_prompt = PromptTemplate.from_template(\n",
        "    \"{city} is the capital of which country?\"\n",
        ")\n",
        "second_chain = LLMChain(llm=llm, prompt=second_prompt)\n",
        "\n",
        "simple_sequential_chain = SimpleSequentialChain(\n",
        "    chains=[first_chain, second_chain],\n",
        "    verbose=True\n",
        ")\n",
        "```\n",
        "And the new interface is the following:\n"
      ],
      "metadata": {
        "id": "bCwyVU8EwOI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "pie_prompt = ChatPromptTemplate.from_template(\"I want to bake a {pie}. Give me a list of ingredients.\")\n",
        "\n",
        "looking_in_the_fridge_prompt = ChatPromptTemplate.from_template(\n",
        "    \"I have {in_the_fridge}, repeat {recipe} adding to each ingredient if I need to buy it\"\n",
        ")\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "recipe_chain = pie_prompt | model | output_parser\n",
        "\n",
        "ingredients_chain = (\n",
        "   {\"in_the_fridge\": itemgetter(\"in_the_fridge\"), \"recipe\": recipe_chain}\n",
        "   | looking_in_the_fridge_prompt\n",
        "   | model\n",
        "   | output_parser\n",
        ")\n",
        "\n",
        "print(\n",
        "    ingredients_chain.invoke(\n",
        "        {\"pie\": \"cheescake\", \"in_the_fridge\": \"milk\"},\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "_9MqxLOqwdEN",
        "outputId": "009c72b1-11a8-4c9e-aa38-3677626f26e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You will need to buy the following ingredients:\n",
            "\n",
            "- Graham cracker crumbs\n",
            "- Unsalted butter\n",
            "- Granulated sugar\n",
            "- Cream cheese\n",
            "- Eggs\n",
            "- Vanilla extract\n",
            "- Sour cream\n",
            "- Fresh berries or fruit compote (if desired)\n",
            "- Springform pan (if you don't already have one)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debugging"
      ],
      "metadata": {
        "id": "LnBhZvJG4I5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
        "\n",
        "print(\n",
        "    ingredients_chain.invoke(\n",
        "        {\"pie\": \"cheescake\", \"in_the_fridge\": \"milk\"},\n",
        "        config={'callbacks': [ConsoleCallbackHandler()]}\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "smZc_oWj4K-b",
        "outputId": "d2300d54-8aee-4c83-caf1-4e234a6fd0d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"pie\": \"cheescake\",\n",
            "  \"in_the_fridge\": \"milk\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"pie\": \"cheescake\",\n",
            "  \"in_the_fridge\": \"milk\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe> > 3:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"pie\": \"cheescake\",\n",
            "  \"in_the_fridge\": \"milk\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe> > 3:chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"milk\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe> > 4:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"pie\": \"cheescake\",\n",
            "  \"in_the_fridge\": \"milk\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe> > 4:chain:RunnableSequence > 5:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"pie\": \"cheescake\",\n",
            "  \"in_the_fridge\": \"milk\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe> > 4:chain:RunnableSequence > 5:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"I want to bake a cheescake. Give me a list of ingredients.\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe> > 4:chain:RunnableSequence > 6:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: I want to bake a cheescake. Give me a list of ingredients.\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe> > 4:chain:RunnableSequence > 6:llm:ChatOpenAI] [10.85s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"To bake a cheesecake, here is a list of ingredients you'll typically need:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs (about 10-12 full sheets)\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese, softened\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nNote: You can also add any desired toppings like fresh fruits, fruit preserves, or chocolate ganache to further enhance the flavor and presentation.\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nPlease note that this is a general list, and variations can be made depending on your preferences.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"To bake a cheesecake, here is a list of ingredients you'll typically need:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs (about 10-12 full sheets)\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese, softened\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nNote: You can also add any desired toppings like fresh fruits, fruit preserves, or chocolate ganache to further enhance the flavor and presentation.\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nPlease note that this is a general list, and variations can be made depending on your preferences.\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 220,\n",
            "      \"prompt_tokens\": 23,\n",
            "      \"total_tokens\": 243\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\",\n",
            "    \"system_fingerprint\": null\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe> > 4:chain:RunnableSequence > 7:parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe> > 4:chain:RunnableSequence > 7:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"To bake a cheesecake, here is a list of ingredients you'll typically need:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs (about 10-12 full sheets)\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese, softened\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nNote: You can also add any desired toppings like fresh fruits, fruit preserves, or chocolate ganache to further enhance the flavor and presentation.\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nPlease note that this is a general list, and variations can be made depending on your preferences.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe> > 4:chain:RunnableSequence] [10.85s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"To bake a cheesecake, here is a list of ingredients you'll typically need:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs (about 10-12 full sheets)\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese, softened\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nNote: You can also add any desired toppings like fresh fruits, fruit preserves, or chocolate ganache to further enhance the flavor and presentation.\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nPlease note that this is a general list, and variations can be made depending on your preferences.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel<in_the_fridge,recipe>] [10.86s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"in_the_fridge\": \"milk\",\n",
            "  \"recipe\": \"To bake a cheesecake, here is a list of ingredients you'll typically need:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs (about 10-12 full sheets)\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese, softened\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nNote: You can also add any desired toppings like fresh fruits, fruit preserves, or chocolate ganache to further enhance the flavor and presentation.\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nPlease note that this is a general list, and variations can be made depending on your preferences.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"in_the_fridge\": \"milk\",\n",
            "  \"recipe\": \"To bake a cheesecake, here is a list of ingredients you'll typically need:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs (about 10-12 full sheets)\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese, softened\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nNote: You can also add any desired toppings like fresh fruits, fruit preserves, or chocolate ganache to further enhance the flavor and presentation.\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nPlease note that this is a general list, and variations can be made depending on your preferences.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"chat\",\n",
            "    \"ChatPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"messages\": [\n",
            "      {\n",
            "        \"lc\": 1,\n",
            "        \"type\": \"constructor\",\n",
            "        \"id\": [\n",
            "          \"langchain\",\n",
            "          \"schema\",\n",
            "          \"messages\",\n",
            "          \"HumanMessage\"\n",
            "        ],\n",
            "        \"kwargs\": {\n",
            "          \"content\": \"I have milk, repeat To bake a cheesecake, here is a list of ingredients you'll typically need:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs (about 10-12 full sheets)\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese, softened\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nNote: You can also add any desired toppings like fresh fruits, fruit preserves, or chocolate ganache to further enhance the flavor and presentation.\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nPlease note that this is a general list, and variations can be made depending on your preferences. adding to each ingredient if I need to buy it\",\n",
            "          \"additional_kwargs\": {}\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: I have milk, repeat To bake a cheesecake, here is a list of ingredients you'll typically need:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs (about 10-12 full sheets)\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese, softened\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nNote: You can also add any desired toppings like fresh fruits, fruit preserves, or chocolate ganache to further enhance the flavor and presentation.\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nPlease note that this is a general list, and variations can be made depending on your preferences. adding to each ingredient if I need to buy it\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:llm:ChatOpenAI] [9.82s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"If you need to buy each ingredient, here is a breakdown:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nNote: These quantities are based on the original recipe. Adjustments can be made depending on your preferences.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"ChatGeneration\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"If you need to buy each ingredient, here is a breakdown:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nNote: These quantities are based on the original recipe. Adjustments can be made depending on your preferences.\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 180,\n",
            "      \"prompt_tokens\": 242,\n",
            "      \"total_tokens\": 422\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\",\n",
            "    \"system_fingerprint\": null\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 10:parser:StrOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 10:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"If you need to buy each ingredient, here is a breakdown:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nNote: These quantities are based on the original recipe. Adjustments can be made depending on your preferences.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [20.68s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"If you need to buy each ingredient, here is a breakdown:\\n\\nCrust:\\n- 1 ½ cups graham cracker crumbs\\n- ⅓ cup melted unsalted butter\\n- 2 tablespoons granulated sugar\\n\\nCheesecake Filling:\\n- 32 oz (900g) cream cheese\\n- 1 ½ cups granulated sugar\\n- 4 large eggs\\n- 1 cup sour cream\\n- 2 teaspoons vanilla extract\\n- ¼ cup all-purpose flour\\n\\nTopping:\\n- 1 cup sour cream\\n- 2 tablespoons granulated sugar\\n- 1 teaspoon vanilla extract\\n\\nOptional Garnishes:\\n- Fresh fruits (e.g., berries, sliced peaches, etc.)\\n- Whipped cream\\n- Chocolate shavings\\n- Mint leaves\\n\\nNote: These quantities are based on the original recipe. Adjustments can be made depending on your preferences.\"\n",
            "}\n",
            "If you need to buy each ingredient, here is a breakdown:\n",
            "\n",
            "Crust:\n",
            "- 1 ½ cups graham cracker crumbs\n",
            "- ⅓ cup melted unsalted butter\n",
            "- 2 tablespoons granulated sugar\n",
            "\n",
            "Cheesecake Filling:\n",
            "- 32 oz (900g) cream cheese\n",
            "- 1 ½ cups granulated sugar\n",
            "- 4 large eggs\n",
            "- 1 cup sour cream\n",
            "- 2 teaspoons vanilla extract\n",
            "- ¼ cup all-purpose flour\n",
            "\n",
            "Topping:\n",
            "- 1 cup sour cream\n",
            "- 2 tablespoons granulated sugar\n",
            "- 1 teaspoon vanilla extract\n",
            "\n",
            "Optional Garnishes:\n",
            "- Fresh fruits (e.g., berries, sliced peaches, etc.)\n",
            "- Whipped cream\n",
            "- Chocolate shavings\n",
            "- Mint leaves\n",
            "\n",
            "Note: These quantities are based on the original recipe. Adjustments can be made depending on your preferences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using tools\n",
        "\n",
        "Before it looked like this:\n",
        "\n",
        "```\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "tools = [DuckDuckGoSearchRun()]\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "F-454Ok_1HbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  langchain langchain-openai duckduckgo-search"
      ],
      "metadata": {
        "id": "6jlynjZS1IG5",
        "outputId": "0177192f-7486-4591-8a02-0767c763f55c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the new version it looks like this:\n"
      ],
      "metadata": {
        "id": "01UR4uZs1YCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "template = \"\"\"turn the following user input into a search query for a search engine:\n",
        "\n",
        "{input}\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "chain = prompt | model | StrOutputParser() | search\n",
        "\n",
        "chain.invoke({\"input\": \"What are the most famous K-pop bands?\"})"
      ],
      "metadata": {
        "id": "aCdaxuFD1Nbn",
        "outputId": "8689331b-78fb-4cd4-f7a4-08f2663b8945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"This group took the world by storm which make them the most famous k-pop bands in the world. Their sense of music, their up-beats, choreography of each and every music album makes a den in heart of their fans. This group started in June 12, 2013 with seven members named RM, Jin, Suga, J-Hope, Jimin, V, and Jungkook. Since then they are unstoppable. The band comprising Jennie Kim, Lisa, Jisoo, and Rose is one of the most famous K-pop bands, and not just that, the members are equally successful individually. BIGBANG: One of the most famous K-pop bands formed by YG Entertainment. EXO: A famous South Korean K-pop group. Jungkook: A famous singer best known for his work in the boy band group, BTS. Moon Jae-in: The 12 th and current President of South Korea. Onew: A well-known K-Pop singer and actor. BTS is one of the most famous K-pop bands worldwide. The South Korean boy band debuted in 2013. Known BTS members are Jungkook, Jimin, Jin, RM, V, J-Hope, and Suga. They sing, rap, and dance. The management cut off the eighth member, Kim Ji-hun, shortly before the band's official debut. Find out the wealthiest BTS member from the post. Source ...\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using memory\n",
        "\n",
        "Before\n",
        "\n",
        "```\n",
        "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import OpenAI, LLMChain\n",
        "\n",
        "\n",
        "prefix = \"\"\"Have a conversation with a human, answering the following \"\"\"\\\n",
        "    \"\"\"questions as best you can. You have access to the following tools:\"\"\"\n",
        "suffix = \"\"\"Begin!\"\n",
        "\n",
        "{chat_history}\n",
        "Question: {input}\n",
        "{agent_scratchpad}\"\"\"\n",
        "\n",
        "prompt = ZeroShotAgent.create_prompt(\n",
        "    tools,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
        ")\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "llm_chain = LLMChain(llm=OpenAI(), prompt=prompt)\n",
        "agent = ZeroShotAgent(\n",
        "    llm_chain=llm_chain,\n",
        "    tools=tools,\n",
        "    verbose=True\n",
        ")\n",
        "agent_chain = AgentExecutor.from_agent_and_tools(\n",
        "    agent=agent, tools=tools, verbose=True, memory=memory\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "d7NwlpOb2S7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI()\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful chatbot\"),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
        "    )\n",
        "    | prompt\n",
        "    | model\n",
        ")"
      ],
      "metadata": {
        "id": "KM_VRa4B2I2M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"I want to get a cat, do you think it's a good idea?\"}\n",
        "response = chain.invoke(inputs)\n",
        "response"
      ],
      "metadata": {
        "id": "qYlde-Y223nc",
        "outputId": "c42dd414-db00-47a5-cfc2-b632a206277e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"As an AI, I don't have personal opinions, but I can provide you with some information to help you make your decision. Getting a cat can be a wonderful and rewarding experience for many people. Cats can provide companionship, reduce stress, and bring joy to your life. However, it's important to consider a few factors before getting a cat. \\n\\n1. Time and Commitment: Cats require time and attention. They need to be fed, groomed, and played with regularly. Make sure you have enough time to devote to your cat's needs.\\n\\n2. Financial Responsibility: Owning a cat comes with expenses such as food, litter, veterinary care, and toys. Consider if you are financially prepared to provide for a cat's needs.\\n\\n3. Allergies: If you or someone in your household is allergic to cats, it may not be the best idea to get one unless you're willing to explore hypoallergenic breeds or take other measures to manage allergies.\\n\\n4. Living Situation: Ensure that your living situation allows for having a cat. Some rental agreements or shared living spaces may have restrictions on pet ownership.\\n\\n5. Long-term Commitment: Cats can live for 15 years or more, so it's essential to consider the long-term commitment and whether you're ready for that responsibility.\\n\\nUltimately, the decision to get a cat depends on your lifestyle, preferences, and ability to provide a loving and caring home. Consider these factors and if you feel ready and able to meet a cat's needs, then it might be a good idea for you.\")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.save_context(inputs, {\"output\": response.content})"
      ],
      "metadata": {
        "id": "TKRQKlEx2997"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"input\": \"I want it, what would be a good name for it?\"}\n",
        "response = chain.invoke(inputs)\n",
        "response"
      ],
      "metadata": {
        "id": "cvpn4xjF4s3X",
        "outputId": "53d3d7d7-82aa-4342-8e9a-fec317843dfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Choosing a name for your cat can be a fun and personal decision. Here are a few suggestions, but remember, the best name is the one that feels right for you and your cat:\\n\\n1. Whiskers\\n2. Luna\\n3. Oliver\\n4. Bella\\n5. Charlie\\n6. Simba\\n7. Lily\\n8. Max\\n9. Chloe\\n10. Leo\\n\\nConsider your cat's personality, appearance, or even your favorite book, movie, or TV show for inspiration. Take your time, and you'll find the perfect name that suits your new furry friend!\")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}